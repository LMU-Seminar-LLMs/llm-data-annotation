{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:09:18.852742200Z",
     "start_time": "2023-08-30T14:09:07.197024300Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, AdamW\n",
    "from sklearn.base import BaseEstimator\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from cleanlab.classification import CleanLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, targets, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, device, scheduler=None):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for d in tqdm(data_loader):\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=targets)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:09:18.865876Z",
     "start_time": "2023-08-30T14:09:18.858751300Z"
    }
   },
   "id": "d7f8ca33ebed311d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class BertSentimentClassifier(BaseEstimator):\n",
    "    def __init__(self, model_path='bert-base-uncased', device=None):\n",
    "        self.model_path = model_path\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
    "        self.model = BertForSequenceClassification.from_pretrained(model_path, num_labels=3)\n",
    "        self.device = device if device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "        self.max_len=128\n",
    "\n",
    "    def fit(self, X, y, epochs=3):\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        train_data = SentimentDataset(X, y, self.tokenizer, max_len=self.max_len)\n",
    "        train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "        \n",
    "        optimizer = AdamW(self.model.parameters(), lr=2e-5)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            train_acc, train_loss = train_epoch(self.model, train_loader, optimizer, self.device)\n",
    "            print(f'Epoch {epoch + 1}/{epochs} - Train loss: {train_loss}, accuracy: {train_acc}')\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_list = X.tolist()\n",
    "        encoding = self.tokenizer.batch_encode_plus(\n",
    "            X_list,\n",
    "            add_special_tokens=True,\n",
    "            max_length=128,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        input_ids = encoding['input_ids'].to(self.device)\n",
    "        attention_mask = encoding['attention_mask'].to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "        \n",
    "        return self.classes_[preds.cpu().numpy()]\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X_list = X.tolist()  # Convert to list\n",
    "        encoding = self.tokenizer.batch_encode_plus(\n",
    "            X_list,  # Updated this line\n",
    "            add_special_tokens=True,\n",
    "            max_length=128,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        input_ids = encoding['input_ids'].to(self.device)\n",
    "        attention_mask = encoding['attention_mask'].to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Convert logits to probabilities\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "        \n",
    "        return probs.cpu().numpy()\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        accuracy = (y_pred == y).mean()\n",
    "        return accuracy\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:09:18.900572300Z",
     "start_time": "2023-08-30T14:09:18.878411500Z"
    }
   },
   "id": "f2843a668f597507"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/merged/merged_8.csv', encoding='unicode_escape')[0:1500]\n",
    "\n",
    "#data.drop(columns=['textID', 'selected_text', 'Time of Tweet', 'Age of User', 'Country', 'Population -2020', 'Land Area (Km²)', 'Density (P/Km²)'], inplace=True)\n",
    "\n",
    "data = data.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:09:18.949422400Z",
     "start_time": "2023-08-30T14:09:18.916574700Z"
    }
   },
   "id": "109ce8b792b915ca"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  text  confidence_scores  \\\n0                  I`d have responded, if I were going                1.0   \n1        Sooo SAD I will miss you here in San Diego!!!                1.0   \n2                            my boss is bullying me...                1.0   \n3                       what interview! leave me alone                1.0   \n4     Sons of ****, why couldn`t they put them on t...                1.0   \n..                                                 ...                ...   \n195                                      i talk to you                1.0   \n196  im soo bored...im deffo missing my music channels                1.0   \n197           nite nite bday girl  have fun at concert                1.0   \n198  Had nicotine replacement patch on for 4 hours....                1.0   \n199  _Sanderson What`s with Twatter lately?  Either...                1.0   \n\n    predicted_labels  \n0            neutral  \n1           negative  \n2           negative  \n3           negative  \n4           negative  \n..               ...  \n195          neutral  \n196         negative  \n197         positive  \n198         negative  \n199         negative  \n\n[200 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>confidence_scores</th>\n      <th>predicted_labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I`d have responded, if I were going</td>\n      <td>1.0</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>1.0</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>my boss is bullying me...</td>\n      <td>1.0</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what interview! leave me alone</td>\n      <td>1.0</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>1.0</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>i talk to you</td>\n      <td>1.0</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>im soo bored...im deffo missing my music channels</td>\n      <td>1.0</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>nite nite bday girl  have fun at concert</td>\n      <td>1.0</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>Had nicotine replacement patch on for 4 hours....</td>\n      <td>1.0</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>_Sanderson What`s with Twatter lately?  Either...</td>\n      <td>1.0</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:09:19.001627300Z",
     "start_time": "2023-08-30T14:09:18.945419900Z"
    }
   },
   "id": "5f9507ae14d2af30"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "clf = BertSentimentClassifier() "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:10:20.072100900Z",
     "start_time": "2023-08-30T14:10:17.493930100Z"
    }
   },
   "id": "57c1bccde4f474ff"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "raw_texts, raw_labels = data[\"text\"].values, data[\"predicted_labels\"].values\n",
    "raw_train_texts, raw_test_texts, raw_train_labels, raw_test_labels = train_test_split(raw_texts, raw_labels, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:10:20.087713300Z",
     "start_time": "2023-08-30T14:10:20.076187600Z"
    }
   },
   "id": "aed194597e45af54"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "predicted_labels\npositive    76\nnegative    75\nneutral     49\nName: count, dtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.predicted_labels.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:10:21.665637200Z",
     "start_time": "2023-08-30T14:10:21.645602900Z"
    }
   },
   "id": "bcc122de56c87d80"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 3 classes.\n",
      "Classes: {'negative', 'neutral', 'positive'}\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(set(raw_train_labels))\n",
    "\n",
    "print(f\"This dataset has {num_classes} classes.\")\n",
    "print(f\"Classes: {set(raw_train_labels)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:10:22.397860300Z",
     "start_time": "2023-08-30T14:10:22.361775400Z"
    }
   },
   "id": "dfc7a14d56e940d5"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#Label encoding the labels\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(raw_train_labels)\n",
    "\n",
    "train_labels = encoder.transform(raw_train_labels)\n",
    "test_labels = encoder.transform(raw_test_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:10:23.169088900Z",
     "start_time": "2023-08-30T14:10:23.151920500Z"
    }
   },
   "id": "ab5e9d39280dfd9d"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saran\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "100%|██████████| 10/10 [00:51<00:00,  5.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Train loss: 1.1396486163139343, accuracy: 0.325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:42<00:00,  4.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Train loss: 0.9907938301563263, accuracy: 0.51875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:46<00:00,  4.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Train loss: 0.8983046293258667, accuracy: 0.61875\n",
      "Accuracy: 0.5750\n"
     ]
    }
   ],
   "source": [
    "clf.fit(raw_train_texts, train_labels, 3) # Initial model prediction , without removing noisy labels\n",
    "accuracy = clf.score(raw_test_texts, test_labels) # This gives the baseline accuracy without acting on noisy labels\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:12:49.501129200Z",
     "start_time": "2023-08-30T14:10:24.903617100Z"
    }
   },
   "id": "476c0e3863a52d79"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "cv_n_folds = 3  # values like 5 or 10 will generally work better\n",
    "cl = CleanLearning(clf, cv_n_folds=cv_n_folds) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:12:49.543197300Z",
     "start_time": "2023-08-30T14:12:49.505649700Z"
    }
   },
   "id": "8c93cc0ba4da5518"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\saran\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "100%|██████████| 7/7 [00:26<00:00,  3.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Train loss: 1.126502479825701, accuracy: 0.2830188679245283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:27<00:00,  3.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Train loss: 1.0170882259096419, accuracy: 0.5377358490566038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:29<00:00,  4.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Train loss: 0.9128633056368146, accuracy: 0.6792452830188679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 7/7 [00:29<00:00,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Train loss: 1.1038631541388375, accuracy: 0.3364485981308411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:30<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Train loss: 1.0303674169949122, accuracy: 0.4579439252336448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:36<00:00,  5.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Train loss: 0.9966505255017962, accuracy: 0.5700934579439252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 7/7 [00:31<00:00,  4.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Train loss: 1.0884945392608643, accuracy: 0.34579439252336447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:25<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Train loss: 1.0137472919055395, accuracy: 0.5327102803738317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:26<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Train loss: 0.9488757848739624, accuracy: 0.5700934579439252\n"
     ]
    }
   ],
   "source": [
    "label_issues = cl.find_label_issues(X=raw_train_texts, labels=train_labels) # Finding label issues in dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:17:39.856213Z",
     "start_time": "2023-08-30T14:12:49.533681500Z"
    }
   },
   "id": "5fe1c7ae4880c4c6"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "identified_issues = label_issues[label_issues[\"is_label_issue\"] == True] \n",
    "lowest_quality_labels = label_issues[\"label_quality\"].argsort().to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:17:39.899518700Z",
     "start_time": "2023-08-30T14:17:39.866732100Z"
    }
   },
   "id": "71d89b8a869b5d29"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 68, 142,  18,  76, 139,   7,  13, 154,  90,  89, 140,   3,  66,\n        60,  41, 101,  97,  54,  85, 106,  24, 112, 147,  23, 153,  57,\n       128, 103,   2,  43,  69,  28,  15,  82, 108, 151,  88,  22,  36,\n        63, 155, 137, 123, 124, 114,  16,   0, 111,  61,  75, 121,  17,\n        91, 138,  47, 148, 132, 104,  31,  49,  95,  37,  79, 105, 136,\n       159,  67,  92,  27,  45,   9,  51, 113,  81, 100,  33,   5, 158,\n        21, 127, 116,  72,  99,  83,  71,  25,  39, 115,  78, 120, 134,\n       107, 133, 145,  73,   1, 109,  11,  19, 144,   8, 156, 110,  52,\n        87, 130,  86, 143,  84,  74, 146, 135,  53, 152,  62,  80,  40,\n        14, 126,  50, 119,  55,  77,   4,  12, 122,  26,  64,  59,  65,\n        48, 125,   6, 157, 149,  58,  46,  56, 131,  98,  94, 117, 118,\n        38, 141, 102,  34,  20,  32,  10,  44,  96, 129,  93,  35,  30,\n        42, 150,  29,  70], dtype=int64)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowest_quality_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:17:39.914089100Z",
     "start_time": "2023-08-30T14:17:39.890004700Z"
    }
   },
   "id": "4681f4344310a897"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def get_dataframe_by_index(index):\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"text\": raw_train_texts,\n",
    "            \"given_label\": raw_train_labels,\n",
    "            \"predicted_label\": encoder.inverse_transform(label_issues[\"predicted_label\"]),\n",
    "            \"quality\": label_issues[\"label_quality\"]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return df.iloc[index]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:20:15.753677600Z",
     "start_time": "2023-08-30T14:20:15.739667900Z"
    }
   },
   "id": "f225fe751eaff9fb"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "top_20_error_rows = get_dataframe_by_index(lowest_quality_labels[:20]) # 20 labels with the least quality "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:20:15.956569500Z",
     "start_time": "2023-08-30T14:20:15.941534900Z"
    }
   },
   "id": "f8709d87b14b6af1"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  text given_label  \\\n68   graduation is done  im a little sad.. anyone w...     neutral   \n142   Hi  how are you doing ???  *just joined twitt...     neutral   \n18   if u have a friendster add me!!!!!!!!!        ...     neutral   \n76                 I`d have responded, if I were going     neutral   \n139  http://www.dothebouncy.com/smf - some shameles...     neutral   \n7                                             MAYDAY?!     neutral   \n13   i realy wanted to go out cause its so nice but...     neutral   \n154   Ahhh, I slept through the game.  I`m gonna tr...     neutral   \n90    also bored at school, its my third freelesson...     neutral   \n89   Thats it, its the end. Tears for Fears vs Eric...     neutral   \n\n    predicted_label   quality  \n68         negative  0.141265  \n142        negative  0.163042  \n18         negative  0.163777  \n76         negative  0.164550  \n139        positive  0.172663  \n7          positive  0.185510  \n13         negative  0.191149  \n154        positive  0.191231  \n90         negative  0.191403  \n89         positive  0.192056  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>given_label</th>\n      <th>predicted_label</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>68</th>\n      <td>graduation is done  im a little sad.. anyone w...</td>\n      <td>neutral</td>\n      <td>negative</td>\n      <td>0.141265</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>Hi  how are you doing ???  *just joined twitt...</td>\n      <td>neutral</td>\n      <td>negative</td>\n      <td>0.163042</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>if u have a friendster add me!!!!!!!!!        ...</td>\n      <td>neutral</td>\n      <td>negative</td>\n      <td>0.163777</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n      <td>negative</td>\n      <td>0.164550</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n      <td>neutral</td>\n      <td>positive</td>\n      <td>0.172663</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>MAYDAY?!</td>\n      <td>neutral</td>\n      <td>positive</td>\n      <td>0.185510</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>i realy wanted to go out cause its so nice but...</td>\n      <td>neutral</td>\n      <td>negative</td>\n      <td>0.191149</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>Ahhh, I slept through the game.  I`m gonna tr...</td>\n      <td>neutral</td>\n      <td>positive</td>\n      <td>0.191231</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>also bored at school, its my third freelesson...</td>\n      <td>neutral</td>\n      <td>negative</td>\n      <td>0.191403</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>Thats it, its the end. Tears for Fears vs Eric...</td>\n      <td>neutral</td>\n      <td>positive</td>\n      <td>0.192056</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rows"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:20:20.418028300Z",
     "start_time": "2023-08-30T14:20:20.394498700Z"
    }
   },
   "id": "9f1a77760dabc97"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saran\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "100%|██████████| 56/56 [00:22<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Train loss: 0.031053377356978933, accuracy: 0.988826815642458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:21<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Train loss: 0.03172345966491515, accuracy: 0.994413407821229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:25<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Train loss: 0.024068544668677663, accuracy: 0.9955307262569831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "updated_clf = cl.fit(X=raw_train_texts, labels=train_labels, label_issues=cl.get_label_issues()) #New model fitting by pruning error labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T03:23:08.663929300Z",
     "start_time": "2023-08-28T03:21:58.974795700Z"
    }
   },
   "id": "21c47bbb0acb9aff"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7400\n"
     ]
    }
   ],
   "source": [
    "accuracy = updated_clf.score(raw_test_texts, test_labels)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T03:23:26.226938800Z",
     "start_time": "2023-08-28T03:23:08.670832400Z"
    }
   },
   "id": "27c01b3ab497ff39"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "'def iterative_cleanlab_training(raw_train_texts, train_labels, raw_test_texts, test_labels, max_iterations=3, tolerance=10):\\n    clf = BertSentimentClassifier()\\n    prev_accuracy = 0\\n    for iteration in range(max_iterations):\\n        print(f\"Starting Iteration {iteration + 1}\")\\n        \\n        # 1. Train the model on the current labeled data\\n        clf.fit(raw_train_texts, train_labels, epochs=3)\\n        accuracy = clf.score(raw_test_texts, test_labels)\\n        print(f\\'Accuracy in Iteration {iteration + 1}: {accuracy:.4f}\\')\\n        \\n        # Stopping condition based on performance change\\n        #if abs(accuracy - prev_accuracy) < tolerance:\\n        #    break\\n        prev_accuracy = accuracy\\n\\n        # 2. Use CleanLab to detect noisy labels\\n        cl = CleanLearning(clf, cv_n_folds=cv_n_folds)\\n        label_issues = cl.find_label_issues(X=raw_train_texts, labels=train_labels)\\n\\n        # 3. Remove or correct the identified noisy labels (here, I\\'m just removing them)\\n        noisy_indices = label_issues[label_issues[\"is_label_issue\"] == True].index\\n        raw_train_texts = np.delete(raw_train_texts, noisy_indices)\\n        train_labels = np.delete(train_labels, noisy_indices)\\n        \\n    return clf'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def iterative_cleanlab_training(raw_train_texts, train_labels, raw_test_texts, test_labels, max_iterations=3, tolerance=10):\n",
    "    clf = BertSentimentClassifier()\n",
    "    prev_accuracy = 0\n",
    "    for iteration in range(max_iterations):\n",
    "        print(f\"Starting Iteration {iteration + 1}\")\n",
    "        \n",
    "        # 1. Train the model on the current labeled data\n",
    "        clf.fit(raw_train_texts, train_labels, epochs=3)\n",
    "        accuracy = clf.score(raw_test_texts, test_labels)\n",
    "        print(f'Accuracy in Iteration {iteration + 1}: {accuracy:.4f}')\n",
    "        \n",
    "        # Stopping condition based on performance change\n",
    "        #if abs(accuracy - prev_accuracy) < tolerance:\n",
    "        #    break\n",
    "        prev_accuracy = accuracy\n",
    "\n",
    "        # 2. Use CleanLab to detect noisy labels\n",
    "        cl = CleanLearning(clf, cv_n_folds=cv_n_folds)\n",
    "        label_issues = cl.find_label_issues(X=raw_train_texts, labels=train_labels)\n",
    "\n",
    "        # 3. Remove or correct the identified noisy labels (here, I'm just removing them)\n",
    "        noisy_indices = label_issues[label_issues[\"is_label_issue\"] == True].index\n",
    "        raw_train_texts = np.delete(raw_train_texts, noisy_indices)\n",
    "        train_labels = np.delete(train_labels, noisy_indices)\n",
    "        \n",
    "    return clf'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:00:42.418685600Z",
     "start_time": "2023-08-28T05:00:42.348361400Z"
    }
   },
   "id": "3150dee8608e9d8a"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "\"# Calling the function\\nclf_final = iterative_cleanlab_training(raw_train_texts, train_labels, raw_test_texts, test_labels)\\nfinal_accuracy = clf_final.score(raw_test_texts, test_labels)\\nprint(f'Final Accuracy: {final_accuracy:.4f}')\\n\""
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Calling the function\n",
    "clf_final = iterative_cleanlab_training(raw_train_texts, train_labels, raw_test_texts, test_labels)\n",
    "final_accuracy = clf_final.score(raw_test_texts, test_labels)\n",
    "print(f'Final Accuracy: {final_accuracy:.4f}')\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:00:42.419686500Z",
     "start_time": "2023-08-28T05:00:42.374605100Z"
    }
   },
   "id": "41d59c7e4bef50ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "accab24bd7c2112e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
