{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-14T00:13:55.126966200Z",
     "start_time": "2023-08-14T00:13:53.645409Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import openai\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tenacity import (\n",
    "retry,\n",
    "stop_after_attempt,\n",
    "wait_random_exponential,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\saran\\\\Desktop\\\\LLM Seminar\\\\Apps Phase\\\\LLM_Data_Annotation\\\\notebooks'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T00:13:55.149968200Z",
     "start_time": "2023-08-14T00:13:55.122969400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T00:13:55.224498200Z",
     "start_time": "2023-08-14T00:13:55.138965Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "unannotated = pd.read_csv('data/unannotated/unannotated_sentiment_dataset.csv', encoding= 'unicode_escape', index_col=[0])\n",
    "original_dataset = pd.read_csv('data/original/train.csv', encoding= 'unicode_escape')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T00:13:55.383456800Z",
     "start_time": "2023-08-14T00:13:55.167502Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "with open('openai/organization.txt', 'r') as file:\n",
    "    openai.organization = file.read().strip()\n",
    "\n",
    "with open('openai/key.txt', 'r') as file:\n",
    "    openai.api_key = file.read().strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T00:13:55.399842400Z",
     "start_time": "2023-08-14T00:13:55.387154700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "accumulated_tokens_method1 = 0\n",
    "accumulated_cost_method1 = 0\n",
    "cost_per_token = 0.0035 / 1000  # The total cost per token, input and output\n",
    "index = 0\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def analyze_ada(text):\n",
    "    global index\n",
    "    global accumulated_tokens_method1\n",
    "    global accumulated_cost_method1\n",
    "\n",
    "    prompt = f\"Sentiment analysis for the following text in a single number: 1 for positive, 0 for neutral, 2 for negative: \\\"{text}\\\"\"\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-ada-001\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=3,\n",
    "        temperature=0.2\n",
    "    )\n",
    "\n",
    "    total_tokens_used = response['usage']['total_tokens']\n",
    "    print(f\"Total tokens used for this call: {total_tokens_used}\")\n",
    "\n",
    "    call_cost = total_tokens_used * cost_per_token\n",
    "    accumulated_cost_method1 += call_cost\n",
    "    accumulated_tokens_method1 += total_tokens_used\n",
    "    index += 1\n",
    "    print('\\nIndex: ', index)\n",
    "    print(f\"Cost for this call: {call_cost}\")\n",
    "    print(f\"Accumulated tokens so far: {accumulated_tokens_method1}\")\n",
    "    print(f\"Accumulated cost so far: {accumulated_cost_method1}\")\n",
    "\n",
    "    response_text = response.choices[0].text.strip().lower()\n",
    "    print('response: ', response_text)\n",
    "    return response_text\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T17:17:00.498747500Z",
     "start_time": "2023-08-12T17:17:00.468231Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=120), stop=stop_after_attempt(6))\n",
    "def analyze_gpt35(text):\n",
    "    global index\n",
    "    global accumulated_cost\n",
    "    global accumulated_tokens\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Your task is to analyze text and classify its sentiment as either 'positive', 'negative', or 'neutral' in a single word.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Classify the sentiment of: '{text}'.\"}\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        max_tokens=3,\n",
    "        n=3,\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    total_tokens_used = response['usage']['total_tokens']\n",
    "    print(f\"Total tokens used for this call: {total_tokens_used}\")\n",
    "\n",
    "    call_cost = total_tokens_used * cost_per_token\n",
    "    accumulated_cost += call_cost\n",
    "    accumulated_tokens += total_tokens_used\n",
    "    index += 1\n",
    "    print('Index: ', index)\n",
    "    print(f\"Cost for this call: {call_cost}\")\n",
    "    print(f\"Accumulated tokens so far: {accumulated_tokens}\")\n",
    "    print(f\"Accumulated cost so far: {accumulated_cost}\\n\")\n",
    "\n",
    "    response_texts = [choice.message.content.strip().lower() for choice in response.choices]\n",
    "    primary_response = response_texts[0]\n",
    "    confidence_score = response_texts.count(primary_response) / 3\n",
    "\n",
    "    return primary_response, confidence_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T00:13:57.453737200Z",
     "start_time": "2023-08-14T00:13:57.416726500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "llm_annotated_data = unannotated.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T00:13:58.614448100Z",
     "start_time": "2023-08-14T00:13:58.600447800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "num_rows = 50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T00:14:17.550463100Z",
     "start_time": "2023-08-14T00:14:17.525334100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#llm_annotated_data['predicted_gpt35'] = llm_annotated_data['text'].iloc[0:num_rows].apply(analyze_gpt35)\n",
    "#llm_annotated_data['predicted_label'] = llm_annotated_data['text'].iloc[0:num_rows].apply(analyze_ada)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T00:14:18.285979900Z",
     "start_time": "2023-08-14T00:14:18.267767Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    text\n0                    I`d have responded, if I were going\n1          Sooo SAD I will miss you here in San Diego!!!\n2                              my boss is bullying me...\n3                         what interview! leave me alone\n4       Sons of ****, why couldn`t they put them on t...\n...                                                  ...\n27476   wish we could come see u on Denver  husband l...\n27477   I`ve wondered about rake to.  The client has ...\n27478   Yay good for both of you. Enjoy the break - y...\n27479                         But it was worth it  ****.\n27480     All this flirting going on - The ATG smiles...\n\n[27481 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I`d have responded, if I were going</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>my boss is bullying me...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what interview! leave me alone</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27476</th>\n      <td>wish we could come see u on Denver  husband l...</td>\n    </tr>\n    <tr>\n      <th>27477</th>\n      <td>I`ve wondered about rake to.  The client has ...</td>\n    </tr>\n    <tr>\n      <th>27478</th>\n      <td>Yay good for both of you. Enjoy the break - y...</td>\n    </tr>\n    <tr>\n      <th>27479</th>\n      <td>But it was worth it  ****.</td>\n    </tr>\n    <tr>\n      <th>27480</th>\n      <td>All this flirting going on - The ATG smiles...</td>\n    </tr>\n  </tbody>\n</table>\n<p>27481 rows Ã— 1 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_annotated_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T00:14:18.674459Z",
     "start_time": "2023-08-14T00:14:18.653449900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens used for this call: 59\n",
      "Total tokens used for this call: 59\n",
      "Total tokens used for this call: 59\n",
      "Total tokens used for this call: 59\n",
      "Total tokens used for this call: 59\n",
      "Total tokens used for this call: 59\n"
     ]
    },
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x167e10973d0 state=finished raised NameError>]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\tenacity\\__init__.py:382\u001B[0m, in \u001B[0;36mRetrying.__call__\u001B[1;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m    381\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 382\u001B[0m     result \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    383\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m:  \u001B[38;5;66;03m# noqa: B902\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[6], line 22\u001B[0m, in \u001B[0;36manalyze_gpt35\u001B[1;34m(text)\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTotal tokens used for this call: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtotal_tokens_used\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 22\u001B[0m call_cost \u001B[38;5;241m=\u001B[39m total_tokens_used \u001B[38;5;241m*\u001B[39m \u001B[43mcost_per_token\u001B[49m\n\u001B[0;32m     23\u001B[0m accumulated_cost \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m call_cost\n",
      "\u001B[1;31mNameError\u001B[0m: name 'cost_per_token' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mRetryError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m sentiments_and_scores \u001B[38;5;241m=\u001B[39m \u001B[43mllm_annotated_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtext\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43mnum_rows\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43manalyze_gpt35\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\core\\series.py:4630\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[0;32m   4520\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4521\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4522\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4525\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4526\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4527\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4528\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4529\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4628\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4629\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4630\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\core\\apply.py:1025\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1022\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[0;32m   1024\u001B[0m \u001B[38;5;66;03m# self.f is Callable\u001B[39;00m\n\u001B[1;32m-> 1025\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\core\\apply.py:1076\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1074\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1075\u001B[0m         values \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;241m.\u001B[39m_values\n\u001B[1;32m-> 1076\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1077\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1078\u001B[0m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1079\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1080\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1082\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m   1083\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[0;32m   1084\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[0;32m   1085\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\tenacity\\__init__.py:289\u001B[0m, in \u001B[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001B[1;34m(*args, **kw)\u001B[0m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_f\u001B[39m(\u001B[38;5;241m*\u001B[39margs: t\u001B[38;5;241m.\u001B[39mAny, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: t\u001B[38;5;241m.\u001B[39mAny) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m t\u001B[38;5;241m.\u001B[39mAny:\n\u001B[1;32m--> 289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m(f, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\tenacity\\__init__.py:379\u001B[0m, in \u001B[0;36mRetrying.__call__\u001B[1;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m    377\u001B[0m retry_state \u001B[38;5;241m=\u001B[39m RetryCallState(retry_object\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, fn\u001B[38;5;241m=\u001B[39mfn, args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m    378\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 379\u001B[0m     do \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    380\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n\u001B[0;32m    381\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\tenacity\\__init__.py:326\u001B[0m, in \u001B[0;36mBaseRetrying.iter\u001B[1;34m(self, retry_state)\u001B[0m\n\u001B[0;32m    324\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreraise:\n\u001B[0;32m    325\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m retry_exc\u001B[38;5;241m.\u001B[39mreraise()\n\u001B[1;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m retry_exc \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mfut\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexception\u001B[39;00m()\n\u001B[0;32m    328\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwait:\n\u001B[0;32m    329\u001B[0m     sleep \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwait(retry_state)\n",
      "\u001B[1;31mRetryError\u001B[0m: RetryError[<Future at 0x167e10973d0 state=finished raised NameError>]"
     ]
    }
   ],
   "source": [
    "sentiments_and_scores = llm_annotated_data['text'].iloc[0:num_rows].apply(analyze_gpt35)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T00:14:42.627281600Z",
     "start_time": "2023-08-14T00:14:23.350300200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens used for this call: 59\n",
      "Index:  96\n",
      "Cost for this call: 0.0002065\n",
      "Accumulated tokens so far: 5371\n",
      "Accumulated cost so far: 0.018798499999999996\n",
      "Total tokens used for this call: 62\n",
      "Index:  97\n",
      "Cost for this call: 0.000217\n",
      "Accumulated tokens so far: 5433\n",
      "Accumulated cost so far: 0.019015499999999994\n",
      "Total tokens used for this call: 55\n",
      "Index:  98\n",
      "Cost for this call: 0.0001925\n",
      "Accumulated tokens so far: 5488\n",
      "Accumulated cost so far: 0.019207999999999996\n",
      "Total tokens used for this call: 55\n",
      "Index:  99\n",
      "Cost for this call: 0.0001925\n",
      "Accumulated tokens so far: 5543\n",
      "Accumulated cost so far: 0.019400499999999998\n",
      "Total tokens used for this call: 65\n",
      "Index:  100\n",
      "Cost for this call: 0.0002275\n",
      "Accumulated tokens so far: 5608\n",
      "Accumulated cost so far: 0.019627999999999996\n",
      "Total tokens used for this call: 72\n",
      "Index:  101\n",
      "Cost for this call: 0.000252\n",
      "Accumulated tokens so far: 5680\n",
      "Accumulated cost so far: 0.019879999999999995\n",
      "Total tokens used for this call: 66\n",
      "Index:  102\n",
      "Cost for this call: 0.000231\n",
      "Accumulated tokens so far: 5746\n",
      "Accumulated cost so far: 0.020110999999999993\n",
      "Total tokens used for this call: 52\n",
      "Index:  103\n",
      "Cost for this call: 0.000182\n",
      "Accumulated tokens so far: 5798\n",
      "Accumulated cost so far: 0.020292999999999995\n",
      "Total tokens used for this call: 52\n",
      "Index:  104\n",
      "Cost for this call: 0.000182\n",
      "Accumulated tokens so far: 5850\n",
      "Accumulated cost so far: 0.020474999999999997\n",
      "Total tokens used for this call: 68\n",
      "Index:  105\n",
      "Cost for this call: 0.00023799999999999998\n",
      "Accumulated tokens so far: 5918\n",
      "Accumulated cost so far: 0.020712999999999995\n",
      "Total tokens used for this call: 76\n",
      "Index:  106\n",
      "Cost for this call: 0.000266\n",
      "Accumulated tokens so far: 5994\n",
      "Accumulated cost so far: 0.020978999999999994\n",
      "Total tokens used for this call: 60\n",
      "Index:  107\n",
      "Cost for this call: 0.00021\n",
      "Accumulated tokens so far: 6054\n",
      "Accumulated cost so far: 0.021188999999999993\n",
      "Total tokens used for this call: 60\n",
      "Index:  108\n",
      "Cost for this call: 0.00021\n",
      "Accumulated tokens so far: 6114\n",
      "Accumulated cost so far: 0.02139899999999999\n",
      "Total tokens used for this call: 61\n",
      "Index:  109\n",
      "Cost for this call: 0.00021349999999999999\n",
      "Accumulated tokens so far: 6175\n",
      "Accumulated cost so far: 0.02161249999999999\n",
      "Total tokens used for this call: 57\n",
      "Index:  110\n",
      "Cost for this call: 0.0001995\n",
      "Accumulated tokens so far: 6232\n",
      "Accumulated cost so far: 0.021811999999999988\n",
      "Total tokens used for this call: 57\n",
      "Index:  111\n",
      "Cost for this call: 0.0001995\n",
      "Accumulated tokens so far: 6289\n",
      "Accumulated cost so far: 0.022011499999999986\n",
      "Total tokens used for this call: 64\n",
      "Index:  112\n",
      "Cost for this call: 0.000224\n",
      "Accumulated tokens so far: 6353\n",
      "Accumulated cost so far: 0.022235499999999984\n",
      "Total tokens used for this call: 91\n",
      "Index:  113\n",
      "Cost for this call: 0.0003185\n",
      "Accumulated tokens so far: 6444\n",
      "Accumulated cost so far: 0.022553999999999984\n",
      "Total tokens used for this call: 58\n",
      "Index:  114\n",
      "Cost for this call: 0.000203\n",
      "Accumulated tokens so far: 6502\n",
      "Accumulated cost so far: 0.022756999999999982\n",
      "Total tokens used for this call: 56\n",
      "Index:  115\n",
      "Cost for this call: 0.000196\n",
      "Accumulated tokens so far: 6558\n",
      "Accumulated cost so far: 0.02295299999999998\n",
      "Total tokens used for this call: 71\n",
      "Index:  116\n",
      "Cost for this call: 0.0002485\n",
      "Accumulated tokens so far: 6629\n",
      "Accumulated cost so far: 0.02320149999999998\n",
      "Total tokens used for this call: 80\n",
      "Index:  117\n",
      "Cost for this call: 0.00028\n",
      "Accumulated tokens so far: 6709\n",
      "Accumulated cost so far: 0.023481499999999978\n",
      "Total tokens used for this call: 63\n",
      "Index:  118\n",
      "Cost for this call: 0.0002205\n",
      "Accumulated tokens so far: 6772\n",
      "Accumulated cost so far: 0.023701999999999977\n",
      "Total tokens used for this call: 70\n",
      "Index:  119\n",
      "Cost for this call: 0.000245\n",
      "Accumulated tokens so far: 6842\n",
      "Accumulated cost so far: 0.023946999999999975\n",
      "Total tokens used for this call: 89\n",
      "Index:  120\n",
      "Cost for this call: 0.0003115\n",
      "Accumulated tokens so far: 6931\n",
      "Accumulated cost so far: 0.024258499999999975\n",
      "Total tokens used for this call: 64\n",
      "Index:  121\n",
      "Cost for this call: 0.000224\n",
      "Accumulated tokens so far: 6995\n",
      "Accumulated cost so far: 0.024482499999999973\n",
      "Total tokens used for this call: 54\n",
      "Index:  122\n",
      "Cost for this call: 0.00018899999999999999\n",
      "Accumulated tokens so far: 7049\n",
      "Accumulated cost so far: 0.024671499999999975\n",
      "Total tokens used for this call: 61\n",
      "Index:  123\n",
      "Cost for this call: 0.00021349999999999999\n",
      "Accumulated tokens so far: 7110\n",
      "Accumulated cost so far: 0.024884999999999973\n",
      "Total tokens used for this call: 82\n",
      "Index:  124\n",
      "Cost for this call: 0.000287\n",
      "Accumulated tokens so far: 7192\n",
      "Accumulated cost so far: 0.025171999999999972\n",
      "Total tokens used for this call: 70\n",
      "Index:  125\n",
      "Cost for this call: 0.000245\n",
      "Accumulated tokens so far: 7262\n",
      "Accumulated cost so far: 0.02541699999999997\n",
      "Total tokens used for this call: 73\n",
      "Index:  126\n",
      "Cost for this call: 0.0002555\n",
      "Accumulated tokens so far: 7335\n",
      "Accumulated cost so far: 0.02567249999999997\n",
      "Total tokens used for this call: 64\n",
      "Index:  127\n",
      "Cost for this call: 0.000224\n",
      "Accumulated tokens so far: 7399\n",
      "Accumulated cost so far: 0.025896499999999968\n",
      "Total tokens used for this call: 80\n",
      "Index:  128\n",
      "Cost for this call: 0.00028\n",
      "Accumulated tokens so far: 7479\n",
      "Accumulated cost so far: 0.026176499999999967\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[62], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m sentiments_and_scores \u001B[38;5;241m=\u001B[39m \u001B[43mllm_annotated_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtext\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43mnum_rows\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43manalyze_gpt35\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m llm_annotated_data\u001B[38;5;241m.\u001B[39mloc[llm_annotated_data\u001B[38;5;241m.\u001B[39mindex[\u001B[38;5;241m0\u001B[39m:num_rows], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredicted_labels\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m [x[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m sentiments_and_scores]\n\u001B[0;32m      3\u001B[0m llm_annotated_data\u001B[38;5;241m.\u001B[39mloc[llm_annotated_data\u001B[38;5;241m.\u001B[39mindex[\u001B[38;5;241m0\u001B[39m:num_rows], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconfidence_score\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m [x[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m sentiments_and_scores]\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\core\\series.py:4630\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[0;32m   4520\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4521\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4522\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4525\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4526\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4527\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4528\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4529\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4628\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4629\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4630\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\core\\apply.py:1025\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1022\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[0;32m   1024\u001B[0m \u001B[38;5;66;03m# self.f is Callable\u001B[39;00m\n\u001B[1;32m-> 1025\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\core\\apply.py:1076\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1074\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1075\u001B[0m         values \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;241m.\u001B[39m_values\n\u001B[1;32m-> 1076\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1077\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1078\u001B[0m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1079\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1080\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1082\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m   1083\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[0;32m   1084\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[0;32m   1085\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\tenacity\\__init__.py:289\u001B[0m, in \u001B[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001B[1;34m(*args, **kw)\u001B[0m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_f\u001B[39m(\u001B[38;5;241m*\u001B[39margs: t\u001B[38;5;241m.\u001B[39mAny, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: t\u001B[38;5;241m.\u001B[39mAny) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m t\u001B[38;5;241m.\u001B[39mAny:\n\u001B[1;32m--> 289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m(f, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\tenacity\\__init__.py:379\u001B[0m, in \u001B[0;36mRetrying.__call__\u001B[1;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m    377\u001B[0m retry_state \u001B[38;5;241m=\u001B[39m RetryCallState(retry_object\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, fn\u001B[38;5;241m=\u001B[39mfn, args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m    378\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 379\u001B[0m     do \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    380\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n\u001B[0;32m    381\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\tenacity\\__init__.py:314\u001B[0m, in \u001B[0;36mBaseRetrying.iter\u001B[1;34m(self, retry_state)\u001B[0m\n\u001B[0;32m    312\u001B[0m is_explicit_retry \u001B[38;5;241m=\u001B[39m fut\u001B[38;5;241m.\u001B[39mfailed \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(fut\u001B[38;5;241m.\u001B[39mexception(), TryAgain)\n\u001B[0;32m    313\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (is_explicit_retry \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretry(retry_state)):\n\u001B[1;32m--> 314\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfut\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    316\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mafter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mafter(retry_state)\n",
      "File \u001B[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\concurrent\\futures\\_base.py:439\u001B[0m, in \u001B[0;36mFuture.result\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    437\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[0;32m    438\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m--> 439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    441\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_condition\u001B[38;5;241m.\u001B[39mwait(timeout)\n\u001B[0;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001B[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\concurrent\\futures\\_base.py:391\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    389\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[0;32m    390\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 391\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[0;32m    392\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    393\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[0;32m    394\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\tenacity\\__init__.py:382\u001B[0m, in \u001B[0;36mRetrying.__call__\u001B[1;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m    380\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n\u001B[0;32m    381\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 382\u001B[0m         result \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    383\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m:  \u001B[38;5;66;03m# noqa: B902\u001B[39;00m\n\u001B[0;32m    384\u001B[0m         retry_state\u001B[38;5;241m.\u001B[39mset_exception(sys\u001B[38;5;241m.\u001B[39mexc_info())  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[19], line 16\u001B[0m, in \u001B[0;36manalyze_gpt35\u001B[1;34m(text)\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mglobal\u001B[39;00m accumulated_tokens\n\u001B[0;32m     11\u001B[0m messages \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     12\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msystem\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYour task is to analyze text and classify its sentiment as either \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpositive\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnegative\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mneutral\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m in a single word.\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[0;32m     13\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClassify the sentiment of: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtext\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[0;32m     14\u001B[0m ]\n\u001B[1;32m---> 16\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mopenai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgpt-3.5-turbo\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.5\u001B[39;49m\n\u001B[0;32m     22\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m total_tokens_used \u001B[38;5;241m=\u001B[39m response[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124musage\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtotal_tokens\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTotal tokens used for this call: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtotal_tokens_used\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001B[0m, in \u001B[0;36mChatCompletion.create\u001B[1;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 25\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mcreate(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m TryAgain \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     27\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m>\u001B[39m start \u001B[38;5;241m+\u001B[39m timeout:\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001B[0m, in \u001B[0;36mEngineAPIResource.create\u001B[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001B[0m\n\u001B[0;32m    127\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[0;32m    128\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[0;32m    129\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    136\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[0;32m    137\u001B[0m ):\n\u001B[0;32m    138\u001B[0m     (\n\u001B[0;32m    139\u001B[0m         deployment_id,\n\u001B[0;32m    140\u001B[0m         engine,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    150\u001B[0m         api_key, api_base, api_type, api_version, organization, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\n\u001B[0;32m    151\u001B[0m     )\n\u001B[1;32m--> 153\u001B[0m     response, _, api_key \u001B[38;5;241m=\u001B[39m \u001B[43mrequestor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    161\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stream:\n\u001B[0;32m    164\u001B[0m         \u001B[38;5;66;03m# must be an iterator\u001B[39;00m\n\u001B[0;32m    165\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, OpenAIResponse)\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\openai\\api_requestor.py:288\u001B[0m, in \u001B[0;36mAPIRequestor.request\u001B[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[0;32m    277\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[0;32m    278\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    279\u001B[0m     method,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    286\u001B[0m     request_timeout: Optional[Union[\u001B[38;5;28mfloat\u001B[39m, Tuple[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    287\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m--> 288\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest_raw\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    289\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlower\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    290\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    291\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    292\u001B[0m \u001B[43m        \u001B[49m\u001B[43msupplied_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    293\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    294\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    295\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    296\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    297\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    298\u001B[0m     resp, got_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interpret_response(result, stream)\n\u001B[0;32m    299\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m resp, got_stream, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\openai\\api_requestor.py:596\u001B[0m, in \u001B[0;36mAPIRequestor.request_raw\u001B[1;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[0;32m    594\u001B[0m     _thread_context\u001B[38;5;241m.\u001B[39msession_create_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m    595\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 596\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_thread_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    597\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    598\u001B[0m \u001B[43m        \u001B[49m\u001B[43mabs_url\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    599\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    600\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    601\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    602\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    603\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mTIMEOUT_SECS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    604\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_thread_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    605\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    606\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m requests\u001B[38;5;241m.\u001B[39mexceptions\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    607\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m error\u001B[38;5;241m.\u001B[39mTimeout(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRequest timed out: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(e)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\requests\\sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[0;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[0;32m    587\u001B[0m }\n\u001B[0;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[1;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msend(prep, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msend_kwargs)\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\requests\\sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[0;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[1;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m adapter\u001B[38;5;241m.\u001B[39msend(request, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[0;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\requests\\adapters.py:486\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    483\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m TimeoutSauce(connect\u001B[38;5;241m=\u001B[39mtimeout, read\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[0;32m    485\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 486\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    487\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    492\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    495\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    501\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:714\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[0;32m    711\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_proxy(conn)\n\u001B[0;32m    713\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n\u001B[1;32m--> 714\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    715\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    716\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    717\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    718\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    719\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    720\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    721\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    722\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    724\u001B[0m \u001B[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001B[39;00m\n\u001B[0;32m    725\u001B[0m \u001B[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001B[39;00m\n\u001B[0;32m    726\u001B[0m \u001B[38;5;66;03m# it will also try to release it and we'll have a double-release\u001B[39;00m\n\u001B[0;32m    727\u001B[0m \u001B[38;5;66;03m# mess.\u001B[39;00m\n\u001B[0;32m    728\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:466\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[0;32m    461\u001B[0m             httplib_response \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39mgetresponse()\n\u001B[0;32m    462\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    463\u001B[0m             \u001B[38;5;66;03m# Remove the TypeError from the exception chain in\u001B[39;00m\n\u001B[0;32m    464\u001B[0m             \u001B[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001B[39;00m\n\u001B[0;32m    465\u001B[0m             \u001B[38;5;66;03m# Otherwise it looks like a bug in the code.\u001B[39;00m\n\u001B[1;32m--> 466\u001B[0m             \u001B[43msix\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    467\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    468\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mread_timeout)\n",
      "File \u001B[1;32m<string>:3\u001B[0m, in \u001B[0;36mraise_from\u001B[1;34m(value, from_value)\u001B[0m\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:461\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[0;32m    458\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    459\u001B[0m     \u001B[38;5;66;03m# Python 3\u001B[39;00m\n\u001B[0;32m    460\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 461\u001B[0m         httplib_response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    462\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    463\u001B[0m         \u001B[38;5;66;03m# Remove the TypeError from the exception chain in\u001B[39;00m\n\u001B[0;32m    464\u001B[0m         \u001B[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001B[39;00m\n\u001B[0;32m    465\u001B[0m         \u001B[38;5;66;03m# Otherwise it looks like a bug in the code.\u001B[39;00m\n\u001B[0;32m    466\u001B[0m         six\u001B[38;5;241m.\u001B[39mraise_from(e, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\http\\client.py:1377\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1375\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1376\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1377\u001B[0m         \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1378\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[0;32m   1379\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\http\\client.py:320\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[0;32m    319\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 320\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    321\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n\u001B[0;32m    322\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\http\\client.py:281\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    280\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 281\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_MAXLINE\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    282\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[0;32m    283\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\socket.py:704\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    703\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 704\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[0;32m    706\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\ssl.py:1242\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[1;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[0;32m   1238\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1239\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1240\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   1241\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[1;32m-> 1242\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1243\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1244\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\ssl.py:1100\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[1;34m(self, len, buffer)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1099\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1100\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1101\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1102\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "llm_annotated_data.loc[llm_annotated_data.index[0:num_rows], 'predicted_labels'] = [x[0] for x in sentiments_and_scores]\n",
    "llm_annotated_data.loc[llm_annotated_data.index[0:num_rows], 'confidence_score'] = [x[1] for x in sentiments_and_scores]\n",
    "llm_annotated_data['annotation_correct'] = (llm_annotated_data['predicted_labels'] == original_dataset['sentiment']).astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T17:18:56.149667400Z",
     "start_time": "2023-08-12T17:18:42.262326900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm_annotated_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-12T17:18:56.137149600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "#llm_annotated_data.to_csv('data/sentiment/annotated/ada/ada_500.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T23:57:47.719165900Z",
     "start_time": "2023-08-07T23:57:47.643635200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "#original_dataset.loc[0:num_rows - 1, 'sentiment'] = original_dataset['sentiment'].iloc[0:num_rows].map(sentiments)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T00:10:25.654119100Z",
     "start_time": "2023-08-08T00:10:25.618418100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "#original_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T00:11:06.196784700Z",
     "start_time": "2023-08-08T00:11:06.175249200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 text predicted_labels  \\\n0                 I`d have responded, if I were going          neutral   \n1       Sooo SAD I will miss you here in San Diego!!!         negative   \n2                           my boss is bullying me...         negative   \n3                      what interview! leave me alone         negative   \n4    Sons of ****, why couldn`t they put them on t...         negative   \n5   http://www.dothebouncy.com/smf - some shameles...         positive   \n6   2am feedings for the baby are fun when he is a...         positive   \n7                                          Soooo high         positive   \n8                                         Both of you          neutral   \n9    Journey!? Wow... u just became cooler.  hehe....         positive   \n10   as much as i love to be hopeful, i reckon the...         negative   \n11  I really really like the song Love Story by Ta...         positive   \n12       My Sharpie is running DANGERously low on ink         negative   \n13  i want to go to music tonight but i lost my vo...         negative   \n14                         test test from the LG enV2          neutral   \n15                              Uh oh, I am sunburned         negative   \n16   S`ok, trying to plot alternatives as we speak...         negative   \n17  i`ve been sick for the past few days  and thus...         negative   \n18         is back home now      gonna miss every one         positive   \n19                         Hes just not that into you         negative   \n20   oh Marly, I`m so sorry!!  I hope you find her...         positive   \n21  Playing Ghost Online is really interesting. Th...         positive   \n22  is cleaning the house for her family who is co...         positive   \n23  gotta restart my computer .. I thought Win7 wa...         negative   \n24  SEe waT I Mean bOuT FoLL0w fRiiDaYs... It`S cA...         negative   \n25  the free fillin` app on my ipod is fun, im add...         positive   \n26                                         I`m sorry.         negative   \n27  On the way to Malaysia...no internet access to...         negative   \n28  juss came backk from Berkeleyy ; omg its madd ...         positive   \n29  Went to sleep and there is a power cut in Noid...         negative   \n30  I`m going home now. Have you seen my new twitt...         positive   \n31  i hope unni will make the audition . fighting ...         positive   \n32   If it is any consolation I got my BMI tested ...         negative   \n33                     That`s very funny.  Cute kids.         positive   \n34   Ahhh, I slept through the game.  I`m gonna tr...          neutral   \n35  Thats it, its the end. Tears for Fears vs Eric...          neutral   \n36  Born and raised in NYC and living in Texas for...         negative   \n37  just in case you wonder, we are really busy to...         positive   \n38  i`m soooooo sleeeeepy!!! the last day o` schoo...         negative   \n39  A little happy for the wine jeje ok it`sm my f...         positive   \n\n    confidence_score  annotation_correct  \n0           1.000000                   1  \n1           1.000000                   1  \n2           1.000000                   1  \n3           1.000000                   1  \n4           1.000000                   1  \n5           1.000000                   0  \n6           1.000000                   1  \n7           1.000000                   0  \n8           1.000000                   1  \n9           1.000000                   1  \n10          1.000000                   0  \n11          1.000000                   1  \n12          1.000000                   1  \n13          1.000000                   1  \n14          1.000000                   1  \n15          1.000000                   1  \n16          1.000000                   1  \n17          1.000000                   1  \n18          1.000000                   0  \n19          1.000000                   0  \n20          1.000000                   0  \n21          1.000000                   1  \n22          1.000000                   0  \n23          1.000000                   0  \n24          1.000000                   0  \n25          1.000000                   1  \n26          0.666667                   1  \n27          0.666667                   1  \n28          1.000000                   1  \n29          1.000000                   1  \n30          1.000000                   1  \n31          1.000000                   1  \n32          1.000000                   1  \n33          1.000000                   1  \n34          0.666667                   1  \n35          1.000000                   1  \n36          1.000000                   1  \n37          1.000000                   0  \n38          1.000000                   1  \n39          1.000000                   1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>predicted_labels</th>\n      <th>confidence_score</th>\n      <th>annotation_correct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>my boss is bullying me...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what interview! leave me alone</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2am feedings for the baby are fun when he is a...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Soooo high</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Both of you</td>\n      <td>neutral</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>as much as i love to be hopeful, i reckon the...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>I really really like the song Love Story by Ta...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>My Sharpie is running DANGERously low on ink</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>i want to go to music tonight but i lost my vo...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>test test from the LG enV2</td>\n      <td>neutral</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Uh oh, I am sunburned</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>S`ok, trying to plot alternatives as we speak...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>i`ve been sick for the past few days  and thus...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>is back home now      gonna miss every one</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Hes just not that into you</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>oh Marly, I`m so sorry!!  I hope you find her...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Playing Ghost Online is really interesting. Th...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>is cleaning the house for her family who is co...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>gotta restart my computer .. I thought Win7 wa...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>SEe waT I Mean bOuT FoLL0w fRiiDaYs... It`S cA...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>the free fillin` app on my ipod is fun, im add...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>I`m sorry.</td>\n      <td>negative</td>\n      <td>0.666667</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>On the way to Malaysia...no internet access to...</td>\n      <td>negative</td>\n      <td>0.666667</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>juss came backk from Berkeleyy ; omg its madd ...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Went to sleep and there is a power cut in Noid...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>I`m going home now. Have you seen my new twitt...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>i hope unni will make the audition . fighting ...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>If it is any consolation I got my BMI tested ...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>That`s very funny.  Cute kids.</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Ahhh, I slept through the game.  I`m gonna tr...</td>\n      <td>neutral</td>\n      <td>0.666667</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Thats it, its the end. Tears for Fears vs Eric...</td>\n      <td>neutral</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Born and raised in NYC and living in Texas for...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>just in case you wonder, we are really busy to...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>i`m soooooo sleeeeepy!!! the last day o` schoo...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>A little happy for the wine jeje ok it`sm my f...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_annotated_data.iloc[0:num_rows]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T00:10:37.639809300Z",
     "start_time": "2023-08-08T00:10:37.602948400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'neutral'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[59], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#llm_annotated_data['annotation_correct'] = (llm_annotated_data['predicted_gpt35'].iloc[0:num_rows] == original_dataset['sentiment'].iloc[0:num_rows]).astype(int)\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m llm_annotated_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mannotation_correct\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m (\u001B[43mllm_annotated_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpredicted_labels\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43mnum_rows\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;241m==\u001B[39m original_dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msentiment\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m:num_rows]\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m))\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m)\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\core\\generic.py:6324\u001B[0m, in \u001B[0;36mNDFrame.astype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m   6317\u001B[0m     results \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m   6318\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miloc[:, i]\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[0;32m   6319\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns))\n\u001B[0;32m   6320\u001B[0m     ]\n\u001B[0;32m   6322\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6323\u001B[0m     \u001B[38;5;66;03m# else, only a single dtype is given\u001B[39;00m\n\u001B[1;32m-> 6324\u001B[0m     new_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mgr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6325\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor(new_data)\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mastype\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6327\u001B[0m \u001B[38;5;66;03m# GH 33113: handle empty frame or series\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:451\u001B[0m, in \u001B[0;36mBaseBlockManager.astype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    448\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m using_copy_on_write():\n\u001B[0;32m    449\u001B[0m     copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m--> 451\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    452\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mastype\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    453\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    454\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    455\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    456\u001B[0m \u001B[43m    \u001B[49m\u001B[43musing_cow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43musing_copy_on_write\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001B[0m, in \u001B[0;36mBaseBlockManager.apply\u001B[1;34m(self, f, align_keys, **kwargs)\u001B[0m\n\u001B[0;32m    350\u001B[0m         applied \u001B[38;5;241m=\u001B[39m b\u001B[38;5;241m.\u001B[39mapply(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    351\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 352\u001B[0m         applied \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(b, f)(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    353\u001B[0m     result_blocks \u001B[38;5;241m=\u001B[39m extend_blocks(applied, result_blocks)\n\u001B[0;32m    355\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mfrom_blocks(result_blocks, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes)\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:511\u001B[0m, in \u001B[0;36mBlock.astype\u001B[1;34m(self, dtype, copy, errors, using_cow)\u001B[0m\n\u001B[0;32m    491\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    492\u001B[0m \u001B[38;5;124;03mCoerce to the new dtype.\u001B[39;00m\n\u001B[0;32m    493\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    507\u001B[0m \u001B[38;5;124;03mBlock\u001B[39;00m\n\u001B[0;32m    508\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    509\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m--> 511\u001B[0m new_values \u001B[38;5;241m=\u001B[39m \u001B[43mastype_array_safe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    513\u001B[0m new_values \u001B[38;5;241m=\u001B[39m maybe_coerce_values(new_values)\n\u001B[0;32m    515\u001B[0m refs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:242\u001B[0m, in \u001B[0;36mastype_array_safe\u001B[1;34m(values, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    239\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtype\u001B[38;5;241m.\u001B[39mnumpy_dtype\n\u001B[0;32m    241\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 242\u001B[0m     new_values \u001B[38;5;241m=\u001B[39m \u001B[43mastype_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    243\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mValueError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m):\n\u001B[0;32m    244\u001B[0m     \u001B[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001B[39;00m\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;66;03m#  trying to convert to float\u001B[39;00m\n\u001B[0;32m    246\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:187\u001B[0m, in \u001B[0;36mastype_array\u001B[1;34m(values, dtype, copy)\u001B[0m\n\u001B[0;32m    184\u001B[0m     values \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 187\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[43m_astype_nansafe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001B[39;00m\n\u001B[0;32m    190\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dtype, np\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(values\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mtype, \u001B[38;5;28mstr\u001B[39m):\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138\u001B[0m, in \u001B[0;36m_astype_nansafe\u001B[1;34m(arr, dtype, copy, skipna)\u001B[0m\n\u001B[0;32m    134\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copy \u001B[38;5;129;01mor\u001B[39;00m is_object_dtype(arr\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mor\u001B[39;00m is_object_dtype(dtype):\n\u001B[0;32m    137\u001B[0m     \u001B[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001B[39;00m\n\u001B[1;32m--> 138\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n",
      "\u001B[1;31mValueError\u001B[0m: invalid literal for int() with base 10: 'neutral'"
     ]
    }
   ],
   "source": [
    "#llm_annotated_data['annotation_correct'] = (llm_annotated_data['predicted_gpt35'].iloc[0:num_rows] == original_dataset['sentiment'].iloc[0:num_rows]).astype(int)\n",
    "\n",
    "llm_annotated_data['annotation_correct'] = (llm_annotated_data['predicted_labels'].iloc[0:num_rows].astype(int) == original_dataset['sentiment'].iloc[0:num_rows].astype(int)).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T00:10:45.721592900Z",
     "start_time": "2023-08-08T00:10:45.240680800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm_annotated_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm_annotated_data.iloc[0:num_rows].to_csv('data/sentiment/gpt35_annotated.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#llm_annotated_data['predicted_gpt35'] = llm_annotated_data['text'].iloc[0:num_rows].apply(analyze_gpt35)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print(f\"Accuracy of GPT3.5's annotations: {accuracy_score(original_dataset['sentiment'].iloc[0:num_rows].astype('str').values, llm_annotated_data['predicted_gpt35'].iloc[0:num_rows].astype('str').values)}\")\n",
    "\n",
    "print(f\"Accuracy of Davinci 003's annotations: {accuracy_score(original_dataset['sentiment'].iloc[0:num_rows].astype('str').values, llm_annotated_data['predicted_davinci'].iloc[0:num_rows].astype('str').values)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#llm_annotated_data.iloc[0:num_rows].to_csv('data/sentiment/gpt35_annotated.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/sentiment/davinci003_annotated_300.csv', index_col=[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset['predicted_davinci'] = dataset['predicted_davinci'].apply(lambda x: x.replace('.', ''))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset['predicted_davinci'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MODEL_NAME = 'bert-base-uncased'\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = dataset.copy()\n",
    "sentiments = {'positive': 0, 'neutral': 1, 'negative': 2}\n",
    "data['predicted_davinci'] = data['predicted_davinci'].map(sentiments)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['predicted_davinci']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, targets, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, device, scheduler=None):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for d in tqdm(data_loader):\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=targets)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, device, sentiments):\n",
    "    model = model.eval()\n",
    "\n",
    "    correct_predictions = 0\n",
    "    predictions = []\n",
    "    real_values = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in tqdm(data_loader):\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=targets)\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            real_values.extend(targets)\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "\n",
    "    predictions = torch.stack(predictions).cpu()\n",
    "    real_values = torch.stack(real_values).cpu()\n",
    "    return correct_predictions.double() / len(data_loader.dataset), classification_report(real_values, predictions, target_names=sentiments.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T00:15:11.955042300Z",
     "start_time": "2023-08-14T00:15:08.035195500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def train_bert(model_path, data_path):\n",
    "\n",
    "    experiment_name = \"llm_seminar_data_annotation\"\n",
    "    client = MlflowClient()\n",
    "    experiment_id = client.get_experiment_by_name(experiment_name)\n",
    "    if experiment_id is None:\n",
    "        experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    else:\n",
    "        experiment_id = experiment_id.experiment_id\n",
    "\n",
    "    model_name = \"_\".join(model_path.split(\"/\")[-1].split(\"_\")[:-2]) # 'bert_sentiment_gpt35_1000' for your example path\n",
    "    with mlflow.start_run(experiment_id=experiment_id):\n",
    "        DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        MODEL_NAME = 'bert-base-uncased'\n",
    "        BATCH_SIZE = 16\n",
    "        EPOCHS = 1\n",
    "\n",
    "        mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "        mlflow.log_param(\"epochs\", EPOCHS)\n",
    "        mlflow.log_param(\"model_name\", MODEL_NAME)\n",
    "\n",
    "        sentiments = {'positive': 0, 'neutral': 1, 'negative': 2}\n",
    "\n",
    "        data = pd.read_csv(data_path, index_col=[0]) #LLM Annotated Dataset\n",
    "        data['predicted_labels'] = data['predicted_labels'].map(sentiments)\n",
    "\n",
    "        train_texts, val_texts, train_targets, val_targets = train_test_split(data['text'], data['predicted_labels'], test_size=0.2)\n",
    "\n",
    "        train_texts = train_texts.reset_index(drop=True)\n",
    "        val_texts = val_texts.reset_index(drop=True)\n",
    "        train_targets = train_targets.reset_index(drop=True)\n",
    "        val_targets = val_targets.reset_index(drop=True)\n",
    "\n",
    "        tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "\n",
    "        train_data = SentimentDataset(train_texts, train_targets, tokenizer, max_len=128)\n",
    "        val_data = SentimentDataset(val_texts, val_targets, tokenizer, max_len=128)\n",
    "        train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(sentiments)).to(DEVICE)\n",
    "\n",
    "        # Train\n",
    "        optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "        for epoch in range(EPOCHS):\n",
    "            print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            train_acc, train_loss = train_epoch(model, train_loader, optimizer, DEVICE)\n",
    "            mlflow.log_metric(\"train_acc\", train_acc)\n",
    "            mlflow.log_metric(\"train_loss\", train_loss)\n",
    "\n",
    "            print(f'Train loss: {train_loss}, accuracy: {train_acc}')\n",
    "\n",
    "            val_acc, val_report = eval_model(model, val_loader, DEVICE, sentiments)\n",
    "            mlflow.log_metric(\"val_acc\", val_acc)\n",
    "\n",
    "            print(f'Val accuracy: {val_acc}\\n')\n",
    "            #print(val_report)\n",
    "\n",
    "        torch.save(model, model_path)\n",
    "        result = mlflow.pytorch.log_model(model, \"model\")\n",
    "\n",
    "        mlflow.pytorch.log_model(model, \"model\")\n",
    "        mlflow.register_model(\n",
    "            model_uri=f\"runs:/{mlflow.active_run().info.run_id}/model\",\n",
    "            name=model_name\n",
    "        )\n",
    "        ALL_RUNS_INFO = client.list_run_infos(experiment_id)\n",
    "        ALL_RUNS_ID = [run.run_id for run in ALL_RUNS_INFO]\n",
    "        ALL_METRIC = [client.get_run(run_id).data.metrics[\"val_acc\"] for run_id in ALL_RUNS_ID]\n",
    "        \n",
    "        runs = pd.DataFrame({\"Run ID\": ALL_RUNS_ID, \"Metrics\": ALL_METRIC})\n",
    "        print(runs.columns)\n",
    "\n",
    "        if runs.empty:\n",
    "            print(\"No runs found.\")\n",
    "            return\n",
    "        \n",
    "        best_run_id = runs.sort_values(\"Metrics\", ascending=False).iloc[0][\"Run ID\"]\n",
    "        best_val_acc = runs.sort_values(\"Metrics\", ascending=False).iloc[0][\"Metrics\"]\n",
    "\n",
    "\n",
    "        # Fetch and load the best model\n",
    "        try:\n",
    "            model_version = client.get_latest_versions(model_name, stages=[\"None\", \"Staging\", \"Production\"])[0].version\n",
    "            model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "            model = mlflow.pytorch.load_model(model_uri)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching model: {e}\")\n",
    "            return\n",
    "\n",
    "        # Print the model details\n",
    "        print(f\"Model Name: {model_name}\")\n",
    "        print(f\"Model Version: {model_version}\")\n",
    "        print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "\n",
    "\n",
    "    mlflow.end_run()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T00:15:12.010752400Z",
     "start_time": "2023-08-14T00:15:11.952043500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Invalid experiment id: <Experiment: artifact_location='file:///C:/Users/saran/Desktop/LLM%20Seminar/Apps%20Phase/LLM_Data_Annotation/mlruns/683353613349867381', creation_time=1691947396178, experiment_id='683353613349867381', last_update_time=1691947396178, lifecycle_stage='active', name='llm_seminar_data_annotation', tags={}> of type <class 'mlflow.entities.experiment.Experiment'>. Must be one of str, int, or None.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMlflowException\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain_bert\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodels/bert_sentiment_gpt35_1000_model2.pt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata/annotated/gpt35_conf_scores_1000_preproc.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[13], line 10\u001B[0m, in \u001B[0;36mtrain_bert\u001B[1;34m(model_path, data_path)\u001B[0m\n\u001B[0;32m      7\u001B[0m     experiment_id \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mcreate_experiment(experiment_name)\n\u001B[0;32m      9\u001B[0m model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(model_path\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m)[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m]) \u001B[38;5;66;03m# 'bert_sentiment_gpt35_1000' for your example path\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mmlflow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexperiment_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexperiment_id\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m     11\u001B[0m     DEVICE \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     12\u001B[0m     MODEL_NAME \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbert-base-uncased\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\mlflow\\tracking\\fluent.py:283\u001B[0m, in \u001B[0;36mstart_run\u001B[1;34m(run_id, experiment_id, run_name, nested, tags, description)\u001B[0m\n\u001B[0;32m    196\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    197\u001B[0m \u001B[38;5;124;03mStart a new MLflow run, setting it as the active run under which metrics and parameters\u001B[39;00m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;124;03mwill be logged. The return value can be used as a context manager within a ``with`` block;\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    280\u001B[0m \u001B[38;5;124;03m    0  7d175204675e40328e46d9a6a5a7ee6a          yes           CHILD_RUN\u001B[39;00m\n\u001B[0;32m    281\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    282\u001B[0m \u001B[38;5;28;01mglobal\u001B[39;00m _active_run_stack\n\u001B[1;32m--> 283\u001B[0m \u001B[43m_validate_experiment_id_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexperiment_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;66;03m# back compat for int experiment_id\u001B[39;00m\n\u001B[0;32m    285\u001B[0m experiment_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(experiment_id) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(experiment_id, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m experiment_id\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\mlflow\\utils\\validation.py:360\u001B[0m, in \u001B[0;36m_validate_experiment_id_type\u001B[1;34m(experiment_id)\u001B[0m\n\u001B[0;32m    355\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    356\u001B[0m \u001B[38;5;124;03mCheck that a user-provided experiment_id is either a string, int, or None and raise an\u001B[39;00m\n\u001B[0;32m    357\u001B[0m \u001B[38;5;124;03mexception if it isn't.\u001B[39;00m\n\u001B[0;32m    358\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    359\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m experiment_id \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(experiment_id, (\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mint\u001B[39m)):\n\u001B[1;32m--> 360\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n\u001B[0;32m    361\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid experiment id: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexperiment_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(experiment_id)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    362\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMust be one of str, int, or None.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    363\u001B[0m         error_code\u001B[38;5;241m=\u001B[39mINVALID_PARAMETER_VALUE,\n\u001B[0;32m    364\u001B[0m     )\n",
      "\u001B[1;31mMlflowException\u001B[0m: Invalid experiment id: <Experiment: artifact_location='file:///C:/Users/saran/Desktop/LLM%20Seminar/Apps%20Phase/LLM_Data_Annotation/mlruns/683353613349867381', creation_time=1691947396178, experiment_id='683353613349867381', last_update_time=1691947396178, lifecycle_stage='active', name='llm_seminar_data_annotation', tags={}> of type <class 'mlflow.entities.experiment.Experiment'>. Must be one of str, int, or None."
     ]
    }
   ],
   "source": [
    "train_bert('models/bert_sentiment_gpt35_1000_model2.pt', 'data/annotated/gpt35_conf_scores_1000_preproc.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T00:34:51.354862100Z",
     "start_time": "2023-08-14T00:34:51.274337800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/sentiment/test.csv', encoding= 'unicode_escape')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test.drop(columns=[x for x in test.columns if x != 'text' and x != 'sentiment'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test.dropna(subset=['sentiment'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test.sentiment.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in test.columns:\n",
    "    test[i] = test[i].astype('str')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_texts = test['text'].reset_index(drop=True)\n",
    "test_targets = test['sentiment'].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if isinstance(test_targets[0], str):\n",
    "    label_encoder = LabelEncoder()\n",
    "    test_targets = label_encoder.fit_transform(test_targets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data = SentimentDataset(test_texts, test_targets, tokenizer, max_len=128)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_acc, test_report = eval_model(model, test_loader, DEVICE)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "print(test_report)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
