{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import openai\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tenacity import (\n",
    "retry,\n",
    "stop_after_attempt,\n",
    "wait_random_exponential,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/sentiment/annotated/gpt35/gpt35_annotated_400.csv', index_col = 0 )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unannotated = pd.read_csv('data/sentiment/unannotated/unannotated_sentiment_dataset.csv', encoding= 'unicode_escape', index_col=[0])\n",
    "original_dataset = pd.read_csv('data/sentiment/original/train.csv', encoding= 'unicode_escape')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('openai/organization.txt', 'r') as file:\n",
    "    openai.organization = file.read().strip()\n",
    "\n",
    "with open('openai/key.txt', 'r') as file:\n",
    "    openai.api_key = file.read().strip()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accumulated_tokens_method1 = 0\n",
    "accumulated_cost_method1 = 0\n",
    "cost_per_token = 0.0035 / 1000  # The total cost per token, input and output\n",
    "index = 0\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def analyze_davinci(text):\n",
    "    global index\n",
    "    global accumulated_tokens_method1\n",
    "    global accumulated_cost_method1\n",
    "\n",
    "    prompt = f\"Sentiment analysis for the following text in a single number: 1 for positive, 0 for neutral, 2 for negative: \\\"{text}\\\"\"\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=10,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    total_tokens_used = response['usage']['total_tokens']\n",
    "    print(f\"Total tokens used for this call: {total_tokens_used}\")\n",
    "\n",
    "    call_cost = total_tokens_used * cost_per_token\n",
    "    accumulated_cost_method1 += call_cost\n",
    "    accumulated_tokens_method1 += total_tokens_used\n",
    "    index += 1\n",
    "    print('\\nIndex: ', index)\n",
    "    print(f\"Cost for this call: {call_cost}\")\n",
    "    print(f\"Accumulated tokens so far: {accumulated_tokens_method1}\")\n",
    "    print(f\"Accumulated cost so far: {accumulated_cost_method1}\")\n",
    "\n",
    "    response_text = response.choices[0].text.strip().lower()\n",
    "\n",
    "    return response_text\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accumulated_tokens = 0\n",
    "accumulated_cost = 0\n",
    "cost_per_token = 0.0035 / 1000  # The total cost per token, input and output\n",
    "index = 0 \n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def analyze_gpt35(text):\n",
    "    global index\n",
    "    global accumulated_cost\n",
    "    global accumulated_tokens\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"You are trained to analyze and detect the sentiment of given text. Here are some examples:\n",
    "                                            User: 'I love this!'; You: 'positive'\n",
    "                                            User: 'I hate this!'; You: 'negative'\n",
    "                                            User: 'I don't feel strongly about this.'; You: 'neutral' \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"Analyze the following texts and determine if the sentiment is: positive, negative, or neutral.\n",
    "                                        Return answer in a single word as either 'positive', 'negative', or 'neutral': '{text}'\"\"\"}\n",
    "        ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "                      model=\"gpt-3.5-turbo\",\n",
    "                      messages=messages,\n",
    "                      max_tokens=10,\n",
    "                      n=1,\n",
    "                      stop=None,\n",
    "                      temperature=0)\n",
    "\n",
    "    total_tokens_used = response['usage']['total_tokens']\n",
    "    print(f\"Total tokens used for this call: {total_tokens_used}\")\n",
    "\n",
    "    call_cost = total_tokens_used * cost_per_token\n",
    "    accumulated_cost += call_cost\n",
    "    accumulated_tokens += total_tokens_used\n",
    "    index+=1\n",
    "    print('Index: ', index)\n",
    "    print(f\"Cost for this call: {call_cost}\")\n",
    "    print(f\"Accumulated tokens so far: {accumulated_tokens}\")\n",
    "    print(f\"Accumulated cost so far: {accumulated_cost}\\n\")\n",
    "\n",
    "    response_text = response.choices[0].message.content.strip().lower()\n",
    "\n",
    "    return response_text\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm_annotated_data = unannotated.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm_annotated_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_rows = 1000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#llm_annotated_data['predicted_gpt35'] = llm_annotated_data['text'].iloc[0:num_rows].apply(analyze_gpt35)\n",
    "llm_annotated_data['predicted_davinci'] = llm_annotated_data['text'].iloc[0:num_rows].apply(analyze_davinci)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sentiments = {'positive': 1, 'neutral': 0, 'negative': 2}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "original_dataset.loc[0:num_rows - 1, 'sentiment'] = original_dataset['sentiment'].iloc[0:num_rows].map(sentiments)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "original_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_rows"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm_annotated_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm_annotated_data.iloc[0:num_rows]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#llm_annotated_data['annotation_correct'] = (llm_annotated_data['predicted_gpt35'].iloc[0:num_rows] == original_dataset['sentiment'].iloc[0:num_rows]).astype(int)\n",
    "\n",
    "llm_annotated_data['annotation_correct'] = (llm_annotated_data['predicted_davinci'].iloc[0:num_rows].astype(int) == original_dataset['sentiment'].iloc[0:num_rows].astype(int)).astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm_annotated_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm_annotated_data.iloc[0:num_rows].to_csv('data/sentiment/gpt35_annotated.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#llm_annotated_data['predicted_gpt35'] = llm_annotated_data['text'].iloc[0:num_rows].apply(analyze_gpt35)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print(f\"Accuracy of GPT3.5's annotations: {accuracy_score(original_dataset['sentiment'].iloc[0:num_rows].astype('str').values, llm_annotated_data['predicted_gpt35'].iloc[0:num_rows].astype('str').values)}\")\n",
    "\n",
    "print(f\"Accuracy of Davinci 003's annotations: {accuracy_score(original_dataset['sentiment'].iloc[0:num_rows].astype('str').values, llm_annotated_data['predicted_davinci'].iloc[0:num_rows].astype('str').values)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#llm_annotated_data.iloc[0:num_rows].to_csv('data/sentiment/gpt35_annotated.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/sentiment/davinci003_annotated_300.csv', index_col=[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset['predicted_davinci'] = dataset['predicted_davinci'].apply(lambda x: x.replace('.', ''))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset['predicted_davinci'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MODEL_NAME = 'bert-base-uncased'\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = dataset.copy()\n",
    "sentiments = {'positive': 0, 'neutral': 1, 'negative': 2}\n",
    "data['predicted_davinci'] = data['predicted_davinci'].map(sentiments)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['predicted_davinci']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, targets, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_targets, val_targets = train_test_split(data['text'], data['predicted_davinci'], test_size=0.1)\n",
    "\n",
    "train_texts = train_texts.reset_index(drop=True)\n",
    "val_texts = val_texts.reset_index(drop=True)\n",
    "train_targets = train_targets.reset_index(drop=True)\n",
    "val_targets = val_targets.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "\n",
    "train_data = SentimentDataset(train_texts, train_targets, tokenizer, max_len=128)\n",
    "val_data = SentimentDataset(val_texts, val_targets, tokenizer, max_len=128)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(sentiments)).to(DEVICE)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, device, scheduler=None):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for d in tqdm(data_loader):\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=targets)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "\n",
    "    correct_predictions = 0\n",
    "    predictions = []\n",
    "    real_values = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in tqdm(data_loader):\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=targets)\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            real_values.extend(targets)\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "\n",
    "    predictions = torch.stack(predictions).cpu()\n",
    "    real_values = torch.stack(real_values).cpu()\n",
    "    return correct_predictions.double() / len(data_loader.dataset), classification_report(real_values, predictions, target_names=sentiments.keys())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(model, train_loader, optimizer, DEVICE)\n",
    "    print(f'Train loss: {train_loss}, accuracy: {train_acc}')\n",
    "\n",
    "    val_acc, val_report = eval_model(model, val_loader, DEVICE)\n",
    "    print(f'Val accuracy: {val_acc}\\n')\n",
    "    print(val_report)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/davinci/bert_sentiment_davinci003_300_model.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/sentiment/test.csv', encoding= 'unicode_escape')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test.drop(columns=[x for x in test.columns if x != 'text' and x != 'sentiment'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test.dropna(subset=['sentiment'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test.sentiment.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in test.columns:\n",
    "    test[i] = test[i].astype('str')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_texts = test['text'].reset_index(drop=True)\n",
    "test_targets = test['sentiment'].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if isinstance(test_targets[0], str):\n",
    "    label_encoder = LabelEncoder()\n",
    "    test_targets = label_encoder.fit_transform(test_targets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data = SentimentDataset(test_texts, test_targets, tokenizer, max_len=128)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_acc, test_report = eval_model(model, test_loader, DEVICE)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "print(test_report)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
