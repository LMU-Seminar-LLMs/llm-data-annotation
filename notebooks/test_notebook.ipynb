{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-08T01:34:00.879650300Z",
     "start_time": "2023-08-08T01:34:00.869090Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import openai\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tenacity import (\n",
    "retry,\n",
    "stop_after_attempt,\n",
    "wait_random_exponential,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\saran\\\\Desktop\\\\LLM Seminar\\\\Apps Phase\\\\LLM_Data_Annotation'"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T23:27:09.618198800Z",
     "start_time": "2023-08-07T23:27:09.603200700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/sentiment/annotated/gpt35/conf_scores_1000.csv', index_col = 0 )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T01:34:10.290152500Z",
     "start_time": "2023-08-08T01:34:10.211855900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "data[data.predicted_labels != \"the sentiment of the text is 'positive'.\"].iloc[0:999].reset_index(drop = True, inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T01:37:27.052178300Z",
     "start_time": "2023-08-08T01:37:27.011077400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "data[data.predicted_labels != \"the sentiment of the text is 'positive'.\"].iloc[0:999].to_csv('data/sentiment/annotated/gpt35/conf_scores_1000_preproc.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T01:38:18.312602400Z",
     "start_time": "2023-08-08T01:38:18.235718600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  text  \\\n5    http://www.dothebouncy.com/smf - some shameles...   \n16    S`ok, trying to plot alternatives as we speak...   \n22   is cleaning the house for her family who is co...   \n27   On the way to Malaysia...no internet access to...   \n34    Ahhh, I slept through the game.  I`m gonna tr...   \n..                                                 ...   \n913  has broken off the fb wedding so sadly no long...   \n923  cavs got lucky 2night  lol but lebron took ove...   \n933  Buried under more web changes. Going to make l...   \n978   Ha! Thanks Bryan! And don`t remind me about t...   \n981                    haha i will remember that  ****   \n\n                             predicted_labels  confidence_score  \n5                                    positive          0.666667  \n16                                   negative          0.666667  \n22                                   positive          0.333333  \n27                                    neutral          0.333333  \n34                                   positive          0.666667  \n..                                        ...               ...  \n913                                  negative          0.666667  \n923  the sentiment of the text is 'positive'.          0.333333  \n933                                  negative          0.666667  \n978                                  positive          0.333333  \n981                                  positive          0.666667  \n\n[93 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>predicted_labels</th>\n      <th>confidence_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n      <td>positive</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>S`ok, trying to plot alternatives as we speak...</td>\n      <td>negative</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>is cleaning the house for her family who is co...</td>\n      <td>positive</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>On the way to Malaysia...no internet access to...</td>\n      <td>neutral</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Ahhh, I slept through the game.  I`m gonna tr...</td>\n      <td>positive</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>913</th>\n      <td>has broken off the fb wedding so sadly no long...</td>\n      <td>negative</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>923</th>\n      <td>cavs got lucky 2night  lol but lebron took ove...</td>\n      <td>the sentiment of the text is 'positive'.</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>933</th>\n      <td>Buried under more web changes. Going to make l...</td>\n      <td>negative</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>978</th>\n      <td>Ha! Thanks Bryan! And don`t remind me about t...</td>\n      <td>positive</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>981</th>\n      <td>haha i will remember that  ****</td>\n      <td>positive</td>\n      <td>0.666667</td>\n    </tr>\n  </tbody>\n</table>\n<p>93 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.confidence_score <1 ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T01:36:26.132085800Z",
     "start_time": "2023-08-08T01:36:26.088041200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('data/sentiment/annotated/gpt35/conf_scores_1000_preproc.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T01:38:38.017838100Z",
     "start_time": "2023-08-08T01:38:37.979812200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "unannotated = pd.read_csv('data/sentiment/unannotated/unannotated_sentiment_dataset.csv', encoding= 'unicode_escape', index_col=[0])\n",
    "original_dataset = pd.read_csv('data/sentiment/original/train.csv', encoding= 'unicode_escape')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T00:15:30.893623700Z",
     "start_time": "2023-08-08T00:15:30.717647400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "with open('openai/organization.txt', 'r') as file:\n",
    "    openai.organization = file.read().strip()\n",
    "\n",
    "with open('openai/key.txt', 'r') as file:\n",
    "    openai.api_key = file.read().strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T00:15:30.923183500Z",
     "start_time": "2023-08-08T00:15:30.890627100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "accumulated_tokens_method1 = 0\n",
    "accumulated_cost_method1 = 0\n",
    "cost_per_token = 0.0035 / 1000  # The total cost per token, input and output\n",
    "index = 0\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def analyze_ada(text):\n",
    "    global index\n",
    "    global accumulated_tokens_method1\n",
    "    global accumulated_cost_method1\n",
    "\n",
    "    prompt = f\"Sentiment analysis for the following text in a single number: 1 for positive, 0 for neutral, 2 for negative: \\\"{text}\\\"\"\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-ada-001\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=10,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    total_tokens_used = response['usage']['total_tokens']\n",
    "    print(f\"Total tokens used for this call: {total_tokens_used}\")\n",
    "\n",
    "    call_cost = total_tokens_used * cost_per_token\n",
    "    accumulated_cost_method1 += call_cost\n",
    "    accumulated_tokens_method1 += total_tokens_used\n",
    "    index += 1\n",
    "    print('\\nIndex: ', index)\n",
    "    print(f\"Cost for this call: {call_cost}\")\n",
    "    print(f\"Accumulated tokens so far: {accumulated_tokens_method1}\")\n",
    "    print(f\"Accumulated cost so far: {accumulated_cost_method1}\")\n",
    "\n",
    "    response_text = response.choices[0].text.strip().lower()\n",
    "\n",
    "    return response_text\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T23:53:51.232616100Z",
     "start_time": "2023-08-07T23:53:51.209062400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "accumulated_tokens = 0\n",
    "accumulated_cost = 0\n",
    "cost_per_token = 0.0035 / 1000  # The total cost per token, input and output\n",
    "index = 0\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def analyze_gpt35(text):\n",
    "    global index\n",
    "    global accumulated_cost\n",
    "    global accumulated_tokens\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Your task is to analyze text and classify its sentiment as either 'positive', 'negative', or 'neutral' in a single word.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Classify the sentiment of: '{text}'.\"}\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        max_tokens=10,\n",
    "        n=3,\n",
    "        stop=None,\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    total_tokens_used = response['usage']['total_tokens']\n",
    "    print(f\"Total tokens used for this call: {total_tokens_used}\")\n",
    "\n",
    "    call_cost = total_tokens_used * cost_per_token\n",
    "    accumulated_cost += call_cost\n",
    "    accumulated_tokens += total_tokens_used\n",
    "    index += 1\n",
    "    print('Index: ', index)\n",
    "    print(f\"Cost for this call: {call_cost}\")\n",
    "    print(f\"Accumulated tokens so far: {accumulated_tokens}\")\n",
    "    print(f\"Accumulated cost so far: {accumulated_cost}\\n\")\n",
    "\n",
    "    response_texts = [choice.message.content.strip().lower() for choice in response.choices]\n",
    "    primary_response = response_texts[0]\n",
    "    confidence_score = response_texts.count(primary_response) / 3\n",
    "\n",
    "    return primary_response, confidence_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T00:15:33.500025300Z",
     "start_time": "2023-08-08T00:15:33.483452800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "llm_annotated_data = unannotated.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T00:15:34.941606800Z",
     "start_time": "2023-08-08T00:15:34.915037700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "num_rows = 20"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T00:15:43.249810200Z",
     "start_time": "2023-08-08T00:15:43.214399500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  1\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 46\n",
      "Accumulated cost so far: 0.000161\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  2\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 88\n",
      "Accumulated cost so far: 0.000308\n",
      "Total tokens used for this call: 34\n",
      "\n",
      "Index:  3\n",
      "Cost for this call: 0.00011899999999999999\n",
      "Accumulated tokens so far: 122\n",
      "Accumulated cost so far: 0.00042699999999999997\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  4\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 164\n",
      "Accumulated cost so far: 0.000574\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  5\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 210\n",
      "Accumulated cost so far: 0.000735\n",
      "Total tokens used for this call: 55\n",
      "\n",
      "Index:  6\n",
      "Cost for this call: 0.0001925\n",
      "Accumulated tokens so far: 265\n",
      "Accumulated cost so far: 0.0009274999999999999\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  7\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 311\n",
      "Accumulated cost so far: 0.0010885\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  8\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 350\n",
      "Accumulated cost so far: 0.001225\n",
      "Total tokens used for this call: 35\n",
      "\n",
      "Index:  9\n",
      "Cost for this call: 0.0001225\n",
      "Accumulated tokens so far: 385\n",
      "Accumulated cost so far: 0.0013475\n",
      "Total tokens used for this call: 48\n",
      "\n",
      "Index:  10\n",
      "Cost for this call: 0.000168\n",
      "Accumulated tokens so far: 433\n",
      "Accumulated cost so far: 0.0015155\n",
      "Total tokens used for this call: 56\n",
      "\n",
      "Index:  11\n",
      "Cost for this call: 0.000196\n",
      "Accumulated tokens so far: 489\n",
      "Accumulated cost so far: 0.0017115\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  12\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 529\n",
      "Accumulated cost so far: 0.0018514999999999998\n",
      "Total tokens used for this call: 48\n",
      "\n",
      "Index:  13\n",
      "Cost for this call: 0.000168\n",
      "Accumulated tokens so far: 577\n",
      "Accumulated cost so far: 0.0020195\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  14\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 618\n",
      "Accumulated cost so far: 0.002163\n",
      "Total tokens used for this call: 43\n",
      "\n",
      "Index:  15\n",
      "Cost for this call: 0.0001505\n",
      "Accumulated tokens so far: 661\n",
      "Accumulated cost so far: 0.0023135\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  16\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 705\n",
      "Accumulated cost so far: 0.0024675\n",
      "Total tokens used for this call: 51\n",
      "\n",
      "Index:  17\n",
      "Cost for this call: 0.0001785\n",
      "Accumulated tokens so far: 756\n",
      "Accumulated cost so far: 0.002646\n",
      "Total tokens used for this call: 80\n",
      "\n",
      "Index:  18\n",
      "Cost for this call: 0.00028\n",
      "Accumulated tokens so far: 836\n",
      "Accumulated cost so far: 0.0029259999999999998\n",
      "Total tokens used for this call: 49\n",
      "\n",
      "Index:  19\n",
      "Cost for this call: 0.0001715\n",
      "Accumulated tokens so far: 885\n",
      "Accumulated cost so far: 0.0030974999999999996\n",
      "Total tokens used for this call: 43\n",
      "\n",
      "Index:  20\n",
      "Cost for this call: 0.0001505\n",
      "Accumulated tokens so far: 928\n",
      "Accumulated cost so far: 0.0032479999999999996\n",
      "Total tokens used for this call: 51\n",
      "\n",
      "Index:  21\n",
      "Cost for this call: 0.0001785\n",
      "Accumulated tokens so far: 979\n",
      "Accumulated cost so far: 0.0034264999999999994\n",
      "Total tokens used for this call: 60\n",
      "\n",
      "Index:  22\n",
      "Cost for this call: 0.00021\n",
      "Accumulated tokens so far: 1039\n",
      "Accumulated cost so far: 0.0036364999999999995\n",
      "Total tokens used for this call: 50\n",
      "\n",
      "Index:  23\n",
      "Cost for this call: 0.000175\n",
      "Accumulated tokens so far: 1089\n",
      "Accumulated cost so far: 0.0038114999999999994\n",
      "Total tokens used for this call: 50\n",
      "\n",
      "Index:  24\n",
      "Cost for this call: 0.000175\n",
      "Accumulated tokens so far: 1139\n",
      "Accumulated cost so far: 0.0039865\n",
      "Total tokens used for this call: 73\n",
      "\n",
      "Index:  25\n",
      "Cost for this call: 0.0002555\n",
      "Accumulated tokens so far: 1212\n",
      "Accumulated cost so far: 0.004241999999999999\n",
      "Total tokens used for this call: 51\n",
      "\n",
      "Index:  26\n",
      "Cost for this call: 0.0001785\n",
      "Accumulated tokens so far: 1263\n",
      "Accumulated cost so far: 0.004420499999999999\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  27\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 1302\n",
      "Accumulated cost so far: 0.004556999999999999\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  28\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 1343\n",
      "Accumulated cost so far: 0.0047005\n",
      "Total tokens used for this call: 62\n",
      "\n",
      "Index:  29\n",
      "Cost for this call: 0.000217\n",
      "Accumulated tokens so far: 1405\n",
      "Accumulated cost so far: 0.0049175\n",
      "Total tokens used for this call: 49\n",
      "\n",
      "Index:  30\n",
      "Cost for this call: 0.0001715\n",
      "Accumulated tokens so far: 1454\n",
      "Accumulated cost so far: 0.005089\n",
      "Total tokens used for this call: 52\n",
      "\n",
      "Index:  31\n",
      "Cost for this call: 0.000182\n",
      "Accumulated tokens so far: 1506\n",
      "Accumulated cost so far: 0.005271\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  32\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 1551\n",
      "Accumulated cost so far: 0.005428499999999999\n",
      "Total tokens used for this call: 60\n",
      "\n",
      "Index:  33\n",
      "Cost for this call: 0.00021\n",
      "Accumulated tokens so far: 1611\n",
      "Accumulated cost so far: 0.005638499999999999\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  34\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 1650\n",
      "Accumulated cost so far: 0.005775\n",
      "Total tokens used for this call: 56\n",
      "\n",
      "Index:  35\n",
      "Cost for this call: 0.000196\n",
      "Accumulated tokens so far: 1706\n",
      "Accumulated cost so far: 0.005971\n",
      "Total tokens used for this call: 62\n",
      "\n",
      "Index:  36\n",
      "Cost for this call: 0.000217\n",
      "Accumulated tokens so far: 1768\n",
      "Accumulated cost so far: 0.006188\n",
      "Total tokens used for this call: 49\n",
      "\n",
      "Index:  37\n",
      "Cost for this call: 0.0001715\n",
      "Accumulated tokens so far: 1817\n",
      "Accumulated cost so far: 0.0063595\n",
      "Total tokens used for this call: 54\n",
      "\n",
      "Index:  38\n",
      "Cost for this call: 0.00018899999999999999\n",
      "Accumulated tokens so far: 1871\n",
      "Accumulated cost so far: 0.0065485\n",
      "Total tokens used for this call: 54\n",
      "\n",
      "Index:  39\n",
      "Cost for this call: 0.00018899999999999999\n",
      "Accumulated tokens so far: 1925\n",
      "Accumulated cost so far: 0.0067374999999999996\n",
      "Total tokens used for this call: 54\n",
      "\n",
      "Index:  40\n",
      "Cost for this call: 0.00018899999999999999\n",
      "Accumulated tokens so far: 1979\n",
      "Accumulated cost so far: 0.0069264999999999995\n",
      "Total tokens used for this call: 54\n",
      "\n",
      "Index:  41\n",
      "Cost for this call: 0.00018899999999999999\n",
      "Accumulated tokens so far: 2033\n",
      "Accumulated cost so far: 0.007115499999999999\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  42\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 2074\n",
      "Accumulated cost so far: 0.007259\n",
      "Total tokens used for this call: 32\n",
      "\n",
      "Index:  43\n",
      "Cost for this call: 0.000112\n",
      "Accumulated tokens so far: 2106\n",
      "Accumulated cost so far: 0.007371\n",
      "Total tokens used for this call: 79\n",
      "\n",
      "Index:  44\n",
      "Cost for this call: 0.0002765\n",
      "Accumulated tokens so far: 2185\n",
      "Accumulated cost so far: 0.0076475\n",
      "Total tokens used for this call: 74\n",
      "\n",
      "Index:  45\n",
      "Cost for this call: 0.000259\n",
      "Accumulated tokens so far: 2259\n",
      "Accumulated cost so far: 0.0079065\n",
      "Total tokens used for this call: 57\n",
      "\n",
      "Index:  46\n",
      "Cost for this call: 0.0001995\n",
      "Accumulated tokens so far: 2316\n",
      "Accumulated cost so far: 0.008106\n",
      "Total tokens used for this call: 56\n",
      "\n",
      "Index:  47\n",
      "Cost for this call: 0.000196\n",
      "Accumulated tokens so far: 2372\n",
      "Accumulated cost so far: 0.008302\n",
      "Total tokens used for this call: 37\n",
      "\n",
      "Index:  48\n",
      "Cost for this call: 0.0001295\n",
      "Accumulated tokens so far: 2409\n",
      "Accumulated cost so far: 0.0084315\n",
      "Total tokens used for this call: 58\n",
      "\n",
      "Index:  49\n",
      "Cost for this call: 0.000203\n",
      "Accumulated tokens so far: 2467\n",
      "Accumulated cost so far: 0.0086345\n",
      "Total tokens used for this call: 56\n",
      "\n",
      "Index:  50\n",
      "Cost for this call: 0.000196\n",
      "Accumulated tokens so far: 2523\n",
      "Accumulated cost so far: 0.0088305\n",
      "Total tokens used for this call: 51\n",
      "\n",
      "Index:  51\n",
      "Cost for this call: 0.0001785\n",
      "Accumulated tokens so far: 2574\n",
      "Accumulated cost so far: 0.009009\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  52\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 2620\n",
      "Accumulated cost so far: 0.00917\n",
      "Total tokens used for this call: 37\n",
      "\n",
      "Index:  53\n",
      "Cost for this call: 0.0001295\n",
      "Accumulated tokens so far: 2657\n",
      "Accumulated cost so far: 0.009299499999999999\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  54\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 2699\n",
      "Accumulated cost so far: 0.009446499999999998\n",
      "Total tokens used for this call: 33\n",
      "\n",
      "Index:  55\n",
      "Cost for this call: 0.0001155\n",
      "Accumulated tokens so far: 2732\n",
      "Accumulated cost so far: 0.009561999999999998\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  56\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 2776\n",
      "Accumulated cost so far: 0.009715999999999997\n",
      "Total tokens used for this call: 50\n",
      "\n",
      "Index:  57\n",
      "Cost for this call: 0.000175\n",
      "Accumulated tokens so far: 2826\n",
      "Accumulated cost so far: 0.009890999999999997\n",
      "Total tokens used for this call: 56\n",
      "\n",
      "Index:  58\n",
      "Cost for this call: 0.000196\n",
      "Accumulated tokens so far: 2882\n",
      "Accumulated cost so far: 0.010086999999999997\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  59\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 2922\n",
      "Accumulated cost so far: 0.010226999999999997\n",
      "Total tokens used for this call: 37\n",
      "\n",
      "Index:  60\n",
      "Cost for this call: 0.0001295\n",
      "Accumulated tokens so far: 2959\n",
      "Accumulated cost so far: 0.010356499999999996\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  61\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 3005\n",
      "Accumulated cost so far: 0.010517499999999996\n",
      "Total tokens used for this call: 38\n",
      "\n",
      "Index:  62\n",
      "Cost for this call: 0.000133\n",
      "Accumulated tokens so far: 3043\n",
      "Accumulated cost so far: 0.010650499999999995\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  63\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 3084\n",
      "Accumulated cost so far: 0.010793999999999995\n",
      "Total tokens used for this call: 60\n",
      "\n",
      "Index:  64\n",
      "Cost for this call: 0.00021\n",
      "Accumulated tokens so far: 3144\n",
      "Accumulated cost so far: 0.011003999999999995\n",
      "Total tokens used for this call: 53\n",
      "\n",
      "Index:  65\n",
      "Cost for this call: 0.0001855\n",
      "Accumulated tokens so far: 3197\n",
      "Accumulated cost so far: 0.011189499999999995\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  66\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 3239\n",
      "Accumulated cost so far: 0.011336499999999994\n",
      "Total tokens used for this call: 48\n",
      "\n",
      "Index:  67\n",
      "Cost for this call: 0.000168\n",
      "Accumulated tokens so far: 3287\n",
      "Accumulated cost so far: 0.011504499999999994\n",
      "Total tokens used for this call: 53\n",
      "\n",
      "Index:  68\n",
      "Cost for this call: 0.0001855\n",
      "Accumulated tokens so far: 3340\n",
      "Accumulated cost so far: 0.011689999999999994\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  69\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 3379\n",
      "Accumulated cost so far: 0.011826499999999993\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  70\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 3418\n",
      "Accumulated cost so far: 0.011962999999999993\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  71\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 3457\n",
      "Accumulated cost so far: 0.012099499999999992\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  72\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 3503\n",
      "Accumulated cost so far: 0.012260499999999992\n",
      "Total tokens used for this call: 56\n",
      "\n",
      "Index:  73\n",
      "Cost for this call: 0.000196\n",
      "Accumulated tokens so far: 3559\n",
      "Accumulated cost so far: 0.012456499999999992\n",
      "Total tokens used for this call: 51\n",
      "\n",
      "Index:  74\n",
      "Cost for this call: 0.0001785\n",
      "Accumulated tokens so far: 3610\n",
      "Accumulated cost so far: 0.012634999999999992\n",
      "Total tokens used for this call: 61\n",
      "\n",
      "Index:  75\n",
      "Cost for this call: 0.00021349999999999999\n",
      "Accumulated tokens so far: 3671\n",
      "Accumulated cost so far: 0.012848499999999992\n",
      "Total tokens used for this call: 64\n",
      "\n",
      "Index:  76\n",
      "Cost for this call: 0.000224\n",
      "Accumulated tokens so far: 3735\n",
      "Accumulated cost so far: 0.013072499999999992\n",
      "Total tokens used for this call: 49\n",
      "\n",
      "Index:  77\n",
      "Cost for this call: 0.0001715\n",
      "Accumulated tokens so far: 3784\n",
      "Accumulated cost so far: 0.013243999999999992\n",
      "Total tokens used for this call: 33\n",
      "\n",
      "Index:  78\n",
      "Cost for this call: 0.0001155\n",
      "Accumulated tokens so far: 3817\n",
      "Accumulated cost so far: 0.013359499999999991\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  79\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 3858\n",
      "Accumulated cost so far: 0.01350299999999999\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  80\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 3904\n",
      "Accumulated cost so far: 0.01366399999999999\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  81\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 3944\n",
      "Accumulated cost so far: 0.01380399999999999\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  82\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 3990\n",
      "Accumulated cost so far: 0.01396499999999999\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  83\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 4032\n",
      "Accumulated cost so far: 0.01411199999999999\n",
      "Total tokens used for this call: 37\n",
      "\n",
      "Index:  84\n",
      "Cost for this call: 0.0001295\n",
      "Accumulated tokens so far: 4069\n",
      "Accumulated cost so far: 0.014241499999999989\n",
      "Total tokens used for this call: 56\n",
      "\n",
      "Index:  85\n",
      "Cost for this call: 0.000196\n",
      "Accumulated tokens so far: 4125\n",
      "Accumulated cost so far: 0.014437499999999989\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  86\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 4166\n",
      "Accumulated cost so far: 0.014580999999999988\n",
      "Total tokens used for this call: 60\n",
      "\n",
      "Index:  87\n",
      "Cost for this call: 0.00021\n",
      "Accumulated tokens so far: 4226\n",
      "Accumulated cost so far: 0.014790999999999988\n",
      "Total tokens used for this call: 64\n",
      "\n",
      "Index:  88\n",
      "Cost for this call: 0.000224\n",
      "Accumulated tokens so far: 4290\n",
      "Accumulated cost so far: 0.015014999999999988\n",
      "Total tokens used for this call: 49\n",
      "\n",
      "Index:  89\n",
      "Cost for this call: 0.0001715\n",
      "Accumulated tokens so far: 4339\n",
      "Accumulated cost so far: 0.015186499999999988\n",
      "Total tokens used for this call: 64\n",
      "\n",
      "Index:  90\n",
      "Cost for this call: 0.000224\n",
      "Accumulated tokens so far: 4403\n",
      "Accumulated cost so far: 0.015410499999999988\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  91\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 4445\n",
      "Accumulated cost so far: 0.015557499999999988\n",
      "Total tokens used for this call: 47\n",
      "\n",
      "Index:  92\n",
      "Cost for this call: 0.0001645\n",
      "Accumulated tokens so far: 4492\n",
      "Accumulated cost so far: 0.01572199999999999\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  93\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 4536\n",
      "Accumulated cost so far: 0.01587599999999999\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  94\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 4581\n",
      "Accumulated cost so far: 0.016033499999999992\n",
      "Total tokens used for this call: 38\n",
      "\n",
      "Index:  95\n",
      "Cost for this call: 0.000133\n",
      "Accumulated tokens so far: 4619\n",
      "Accumulated cost so far: 0.016166499999999993\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  96\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 4658\n",
      "Accumulated cost so far: 0.016302999999999995\n",
      "Total tokens used for this call: 76\n",
      "\n",
      "Index:  97\n",
      "Cost for this call: 0.000266\n",
      "Accumulated tokens so far: 4734\n",
      "Accumulated cost so far: 0.016568999999999993\n",
      "Total tokens used for this call: 43\n",
      "\n",
      "Index:  98\n",
      "Cost for this call: 0.0001505\n",
      "Accumulated tokens so far: 4777\n",
      "Accumulated cost so far: 0.016719499999999995\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  99\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 4822\n",
      "Accumulated cost so far: 0.016876999999999996\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  100\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 4866\n",
      "Accumulated cost so far: 0.017030999999999998\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  101\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 4912\n",
      "Accumulated cost so far: 0.017192\n",
      "Total tokens used for this call: 36\n",
      "\n",
      "Index:  102\n",
      "Cost for this call: 0.000126\n",
      "Accumulated tokens so far: 4948\n",
      "Accumulated cost so far: 0.017318\n",
      "Total tokens used for this call: 70\n",
      "\n",
      "Index:  103\n",
      "Cost for this call: 0.000245\n",
      "Accumulated tokens so far: 5018\n",
      "Accumulated cost so far: 0.017563\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  104\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 5064\n",
      "Accumulated cost so far: 0.017724\n",
      "Total tokens used for this call: 70\n",
      "\n",
      "Index:  105\n",
      "Cost for this call: 0.000245\n",
      "Accumulated tokens so far: 5134\n",
      "Accumulated cost so far: 0.017969\n",
      "Total tokens used for this call: 50\n",
      "\n",
      "Index:  106\n",
      "Cost for this call: 0.000175\n",
      "Accumulated tokens so far: 5184\n",
      "Accumulated cost so far: 0.018144\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  107\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 5225\n",
      "Accumulated cost so far: 0.0182875\n",
      "Total tokens used for this call: 57\n",
      "\n",
      "Index:  108\n",
      "Cost for this call: 0.0001995\n",
      "Accumulated tokens so far: 5282\n",
      "Accumulated cost so far: 0.018487\n",
      "Total tokens used for this call: 55\n",
      "\n",
      "Index:  109\n",
      "Cost for this call: 0.0001925\n",
      "Accumulated tokens so far: 5337\n",
      "Accumulated cost so far: 0.0186795\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  110\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 5383\n",
      "Accumulated cost so far: 0.018840500000000003\n",
      "Total tokens used for this call: 79\n",
      "\n",
      "Index:  111\n",
      "Cost for this call: 0.0002765\n",
      "Accumulated tokens so far: 5462\n",
      "Accumulated cost so far: 0.019117000000000002\n",
      "Total tokens used for this call: 33\n",
      "\n",
      "Index:  112\n",
      "Cost for this call: 0.0001155\n",
      "Accumulated tokens so far: 5495\n",
      "Accumulated cost so far: 0.019232500000000003\n",
      "Total tokens used for this call: 49\n",
      "\n",
      "Index:  113\n",
      "Cost for this call: 0.0001715\n",
      "Accumulated tokens so far: 5544\n",
      "Accumulated cost so far: 0.019404000000000005\n",
      "Total tokens used for this call: 70\n",
      "\n",
      "Index:  114\n",
      "Cost for this call: 0.000245\n",
      "Accumulated tokens so far: 5614\n",
      "Accumulated cost so far: 0.019649000000000003\n",
      "Total tokens used for this call: 57\n",
      "\n",
      "Index:  115\n",
      "Cost for this call: 0.0001995\n",
      "Accumulated tokens so far: 5671\n",
      "Accumulated cost so far: 0.0198485\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  116\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 5715\n",
      "Accumulated cost so far: 0.020002500000000003\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  117\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 5760\n",
      "Accumulated cost so far: 0.020160000000000004\n",
      "Total tokens used for this call: 35\n",
      "\n",
      "Index:  118\n",
      "Cost for this call: 0.0001225\n",
      "Accumulated tokens so far: 5795\n",
      "Accumulated cost so far: 0.020282500000000005\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  119\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 5834\n",
      "Accumulated cost so far: 0.020419000000000007\n",
      "Total tokens used for this call: 63\n",
      "\n",
      "Index:  120\n",
      "Cost for this call: 0.0002205\n",
      "Accumulated tokens so far: 5897\n",
      "Accumulated cost so far: 0.020639500000000005\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  121\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 5943\n",
      "Accumulated cost so far: 0.020800500000000006\n",
      "Total tokens used for this call: 59\n",
      "\n",
      "Index:  122\n",
      "Cost for this call: 0.0002065\n",
      "Accumulated tokens so far: 6002\n",
      "Accumulated cost so far: 0.021007000000000005\n",
      "Total tokens used for this call: 51\n",
      "\n",
      "Index:  123\n",
      "Cost for this call: 0.0001785\n",
      "Accumulated tokens so far: 6053\n",
      "Accumulated cost so far: 0.021185500000000006\n",
      "Total tokens used for this call: 55\n",
      "\n",
      "Index:  124\n",
      "Cost for this call: 0.0001925\n",
      "Accumulated tokens so far: 6108\n",
      "Accumulated cost so far: 0.021378000000000008\n",
      "Total tokens used for this call: 38\n",
      "\n",
      "Index:  125\n",
      "Cost for this call: 0.000133\n",
      "Accumulated tokens so far: 6146\n",
      "Accumulated cost so far: 0.02151100000000001\n",
      "Total tokens used for this call: 33\n",
      "\n",
      "Index:  126\n",
      "Cost for this call: 0.0001155\n",
      "Accumulated tokens so far: 6179\n",
      "Accumulated cost so far: 0.02162650000000001\n",
      "Total tokens used for this call: 47\n",
      "\n",
      "Index:  127\n",
      "Cost for this call: 0.0001645\n",
      "Accumulated tokens so far: 6226\n",
      "Accumulated cost so far: 0.021791000000000012\n",
      "Total tokens used for this call: 37\n",
      "\n",
      "Index:  128\n",
      "Cost for this call: 0.0001295\n",
      "Accumulated tokens so far: 6263\n",
      "Accumulated cost so far: 0.021920500000000013\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  129\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 6307\n",
      "Accumulated cost so far: 0.022074500000000014\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  130\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 6353\n",
      "Accumulated cost so far: 0.022235500000000016\n",
      "Total tokens used for this call: 57\n",
      "\n",
      "Index:  131\n",
      "Cost for this call: 0.0001995\n",
      "Accumulated tokens so far: 6410\n",
      "Accumulated cost so far: 0.022435000000000014\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  132\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 6455\n",
      "Accumulated cost so far: 0.022592500000000015\n",
      "Total tokens used for this call: 48\n",
      "\n",
      "Index:  133\n",
      "Cost for this call: 0.000168\n",
      "Accumulated tokens so far: 6503\n",
      "Accumulated cost so far: 0.022760500000000017\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  134\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 6543\n",
      "Accumulated cost so far: 0.022900500000000018\n",
      "Total tokens used for this call: 62\n",
      "\n",
      "Index:  135\n",
      "Cost for this call: 0.000217\n",
      "Accumulated tokens so far: 6605\n",
      "Accumulated cost so far: 0.023117500000000017\n",
      "Total tokens used for this call: 64\n",
      "\n",
      "Index:  136\n",
      "Cost for this call: 0.000224\n",
      "Accumulated tokens so far: 6669\n",
      "Accumulated cost so far: 0.023341500000000015\n",
      "Total tokens used for this call: 69\n",
      "\n",
      "Index:  137\n",
      "Cost for this call: 0.0002415\n",
      "Accumulated tokens so far: 6738\n",
      "Accumulated cost so far: 0.023583000000000014\n",
      "Total tokens used for this call: 57\n",
      "\n",
      "Index:  138\n",
      "Cost for this call: 0.0001995\n",
      "Accumulated tokens so far: 6795\n",
      "Accumulated cost so far: 0.023782500000000012\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  139\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 6834\n",
      "Accumulated cost so far: 0.023919000000000013\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  140\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 6876\n",
      "Accumulated cost so far: 0.024066000000000014\n",
      "Total tokens used for this call: 61\n",
      "\n",
      "Index:  141\n",
      "Cost for this call: 0.00021349999999999999\n",
      "Accumulated tokens so far: 6937\n",
      "Accumulated cost so far: 0.024279500000000013\n",
      "Total tokens used for this call: 47\n",
      "\n",
      "Index:  142\n",
      "Cost for this call: 0.0001645\n",
      "Accumulated tokens so far: 6984\n",
      "Accumulated cost so far: 0.024444000000000014\n",
      "Total tokens used for this call: 65\n",
      "\n",
      "Index:  143\n",
      "Cost for this call: 0.0002275\n",
      "Accumulated tokens so far: 7049\n",
      "Accumulated cost so far: 0.024671500000000013\n",
      "Total tokens used for this call: 47\n",
      "\n",
      "Index:  144\n",
      "Cost for this call: 0.0001645\n",
      "Accumulated tokens so far: 7096\n",
      "Accumulated cost so far: 0.024836000000000014\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  145\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 7135\n",
      "Accumulated cost so far: 0.024972500000000016\n",
      "Total tokens used for this call: 50\n",
      "\n",
      "Index:  146\n",
      "Cost for this call: 0.000175\n",
      "Accumulated tokens so far: 7185\n",
      "Accumulated cost so far: 0.025147500000000017\n",
      "Total tokens used for this call: 38\n",
      "\n",
      "Index:  147\n",
      "Cost for this call: 0.000133\n",
      "Accumulated tokens so far: 7223\n",
      "Accumulated cost so far: 0.025280500000000018\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  148\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 7263\n",
      "Accumulated cost so far: 0.02542050000000002\n",
      "Total tokens used for this call: 35\n",
      "\n",
      "Index:  149\n",
      "Cost for this call: 0.0001225\n",
      "Accumulated tokens so far: 7298\n",
      "Accumulated cost so far: 0.02554300000000002\n",
      "Total tokens used for this call: 65\n",
      "\n",
      "Index:  150\n",
      "Cost for this call: 0.0002275\n",
      "Accumulated tokens so far: 7363\n",
      "Accumulated cost so far: 0.02577050000000002\n",
      "Total tokens used for this call: 62\n",
      "\n",
      "Index:  151\n",
      "Cost for this call: 0.000217\n",
      "Accumulated tokens so far: 7425\n",
      "Accumulated cost so far: 0.025987500000000018\n",
      "Total tokens used for this call: 53\n",
      "\n",
      "Index:  152\n",
      "Cost for this call: 0.0001855\n",
      "Accumulated tokens so far: 7478\n",
      "Accumulated cost so far: 0.02617300000000002\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  153\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 7517\n",
      "Accumulated cost so far: 0.02630950000000002\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  154\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 7561\n",
      "Accumulated cost so far: 0.02646350000000002\n",
      "Total tokens used for this call: 50\n",
      "\n",
      "Index:  155\n",
      "Cost for this call: 0.000175\n",
      "Accumulated tokens so far: 7611\n",
      "Accumulated cost so far: 0.026638500000000023\n",
      "Total tokens used for this call: 38\n",
      "\n",
      "Index:  156\n",
      "Cost for this call: 0.000133\n",
      "Accumulated tokens so far: 7649\n",
      "Accumulated cost so far: 0.026771500000000024\n",
      "Total tokens used for this call: 38\n",
      "\n",
      "Index:  157\n",
      "Cost for this call: 0.000133\n",
      "Accumulated tokens so far: 7687\n",
      "Accumulated cost so far: 0.026904500000000026\n",
      "Total tokens used for this call: 63\n",
      "\n",
      "Index:  158\n",
      "Cost for this call: 0.0002205\n",
      "Accumulated tokens so far: 7750\n",
      "Accumulated cost so far: 0.027125000000000024\n",
      "Total tokens used for this call: 47\n",
      "\n",
      "Index:  159\n",
      "Cost for this call: 0.0001645\n",
      "Accumulated tokens so far: 7797\n",
      "Accumulated cost so far: 0.027289500000000026\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  160\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 7842\n",
      "Accumulated cost so far: 0.027447000000000027\n",
      "Total tokens used for this call: 35\n",
      "\n",
      "Index:  161\n",
      "Cost for this call: 0.0001225\n",
      "Accumulated tokens so far: 7877\n",
      "Accumulated cost so far: 0.027569500000000028\n",
      "Total tokens used for this call: 36\n",
      "\n",
      "Index:  162\n",
      "Cost for this call: 0.000126\n",
      "Accumulated tokens so far: 7913\n",
      "Accumulated cost so far: 0.02769550000000003\n",
      "Total tokens used for this call: 37\n",
      "\n",
      "Index:  163\n",
      "Cost for this call: 0.0001295\n",
      "Accumulated tokens so far: 7950\n",
      "Accumulated cost so far: 0.02782500000000003\n",
      "Total tokens used for this call: 64\n",
      "\n",
      "Index:  164\n",
      "Cost for this call: 0.000224\n",
      "Accumulated tokens so far: 8014\n",
      "Accumulated cost so far: 0.02804900000000003\n",
      "Total tokens used for this call: 36\n",
      "\n",
      "Index:  165\n",
      "Cost for this call: 0.000126\n",
      "Accumulated tokens so far: 8050\n",
      "Accumulated cost so far: 0.02817500000000003\n",
      "Total tokens used for this call: 47\n",
      "\n",
      "Index:  166\n",
      "Cost for this call: 0.0001645\n",
      "Accumulated tokens so far: 8097\n",
      "Accumulated cost so far: 0.02833950000000003\n",
      "Total tokens used for this call: 50\n",
      "\n",
      "Index:  167\n",
      "Cost for this call: 0.000175\n",
      "Accumulated tokens so far: 8147\n",
      "Accumulated cost so far: 0.028514500000000033\n",
      "Total tokens used for this call: 50\n",
      "\n",
      "Index:  168\n",
      "Cost for this call: 0.000175\n",
      "Accumulated tokens so far: 8197\n",
      "Accumulated cost so far: 0.028689500000000034\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  169\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 8241\n",
      "Accumulated cost so far: 0.028843500000000036\n",
      "Total tokens used for this call: 62\n",
      "\n",
      "Index:  170\n",
      "Cost for this call: 0.000217\n",
      "Accumulated tokens so far: 8303\n",
      "Accumulated cost so far: 0.029060500000000034\n",
      "Total tokens used for this call: 38\n",
      "\n",
      "Index:  171\n",
      "Cost for this call: 0.000133\n",
      "Accumulated tokens so far: 8341\n",
      "Accumulated cost so far: 0.029193500000000035\n",
      "Total tokens used for this call: 34\n",
      "\n",
      "Index:  172\n",
      "Cost for this call: 0.00011899999999999999\n",
      "Accumulated tokens so far: 8375\n",
      "Accumulated cost so far: 0.029312500000000036\n",
      "Total tokens used for this call: 71\n",
      "\n",
      "Index:  173\n",
      "Cost for this call: 0.0002485\n",
      "Accumulated tokens so far: 8446\n",
      "Accumulated cost so far: 0.029561000000000035\n",
      "Total tokens used for this call: 59\n",
      "\n",
      "Index:  174\n",
      "Cost for this call: 0.0002065\n",
      "Accumulated tokens so far: 8505\n",
      "Accumulated cost so far: 0.029767500000000034\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  175\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 8551\n",
      "Accumulated cost so far: 0.029928500000000035\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  176\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 8596\n",
      "Accumulated cost so far: 0.030086000000000036\n",
      "Total tokens used for this call: 48\n",
      "\n",
      "Index:  177\n",
      "Cost for this call: 0.000168\n",
      "Accumulated tokens so far: 8644\n",
      "Accumulated cost so far: 0.030254000000000038\n",
      "Total tokens used for this call: 43\n",
      "\n",
      "Index:  178\n",
      "Cost for this call: 0.0001505\n",
      "Accumulated tokens so far: 8687\n",
      "Accumulated cost so far: 0.03040450000000004\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  179\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 8726\n",
      "Accumulated cost so far: 0.03054100000000004\n",
      "Total tokens used for this call: 53\n",
      "\n",
      "Index:  180\n",
      "Cost for this call: 0.0001855\n",
      "Accumulated tokens so far: 8779\n",
      "Accumulated cost so far: 0.030726500000000042\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  181\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 8824\n",
      "Accumulated cost so far: 0.030884000000000043\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  182\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 8870\n",
      "Accumulated cost so far: 0.031045000000000045\n",
      "Total tokens used for this call: 71\n",
      "\n",
      "Index:  183\n",
      "Cost for this call: 0.0002485\n",
      "Accumulated tokens so far: 8941\n",
      "Accumulated cost so far: 0.031293500000000044\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  184\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 8981\n",
      "Accumulated cost so far: 0.031433500000000045\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  185\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 9021\n",
      "Accumulated cost so far: 0.031573500000000046\n",
      "Total tokens used for this call: 38\n",
      "\n",
      "Index:  186\n",
      "Cost for this call: 0.000133\n",
      "Accumulated tokens so far: 9059\n",
      "Accumulated cost so far: 0.03170650000000005\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  187\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 9098\n",
      "Accumulated cost so far: 0.031843000000000045\n",
      "Total tokens used for this call: 51\n",
      "\n",
      "Index:  188\n",
      "Cost for this call: 0.0001785\n",
      "Accumulated tokens so far: 9149\n",
      "Accumulated cost so far: 0.03202150000000004\n",
      "Total tokens used for this call: 56\n",
      "\n",
      "Index:  189\n",
      "Cost for this call: 0.000196\n",
      "Accumulated tokens so far: 9205\n",
      "Accumulated cost so far: 0.032217500000000045\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  190\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 9247\n",
      "Accumulated cost so far: 0.032364500000000046\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  191\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 9289\n",
      "Accumulated cost so far: 0.03251150000000005\n",
      "Total tokens used for this call: 65\n",
      "\n",
      "Index:  192\n",
      "Cost for this call: 0.0002275\n",
      "Accumulated tokens so far: 9354\n",
      "Accumulated cost so far: 0.032739000000000046\n",
      "Total tokens used for this call: 63\n",
      "\n",
      "Index:  193\n",
      "Cost for this call: 0.0002205\n",
      "Accumulated tokens so far: 9417\n",
      "Accumulated cost so far: 0.032959500000000044\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  194\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 9461\n",
      "Accumulated cost so far: 0.033113500000000046\n",
      "Total tokens used for this call: 48\n",
      "\n",
      "Index:  195\n",
      "Cost for this call: 0.000168\n",
      "Accumulated tokens so far: 9509\n",
      "Accumulated cost so far: 0.03328150000000005\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  196\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 9549\n",
      "Accumulated cost so far: 0.03342150000000005\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  197\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 9591\n",
      "Accumulated cost so far: 0.03356850000000005\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  198\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 9632\n",
      "Accumulated cost so far: 0.03371200000000005\n",
      "Total tokens used for this call: 61\n",
      "\n",
      "Index:  199\n",
      "Cost for this call: 0.00021349999999999999\n",
      "Accumulated tokens so far: 9693\n",
      "Accumulated cost so far: 0.033925500000000046\n",
      "Total tokens used for this call: 55\n",
      "\n",
      "Index:  200\n",
      "Cost for this call: 0.0001925\n",
      "Accumulated tokens so far: 9748\n",
      "Accumulated cost so far: 0.034118000000000044\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  201\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 9790\n",
      "Accumulated cost so far: 0.034265000000000045\n",
      "Total tokens used for this call: 51\n",
      "\n",
      "Index:  202\n",
      "Cost for this call: 0.0001785\n",
      "Accumulated tokens so far: 9841\n",
      "Accumulated cost so far: 0.034443500000000044\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  203\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 9882\n",
      "Accumulated cost so far: 0.03458700000000004\n",
      "Total tokens used for this call: 38\n",
      "\n",
      "Index:  204\n",
      "Cost for this call: 0.000133\n",
      "Accumulated tokens so far: 9920\n",
      "Accumulated cost so far: 0.03472000000000004\n",
      "Total tokens used for this call: 59\n",
      "\n",
      "Index:  205\n",
      "Cost for this call: 0.0002065\n",
      "Accumulated tokens so far: 9979\n",
      "Accumulated cost so far: 0.03492650000000004\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  206\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 10024\n",
      "Accumulated cost so far: 0.03508400000000004\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  207\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 10063\n",
      "Accumulated cost so far: 0.035220500000000037\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  208\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 10108\n",
      "Accumulated cost so far: 0.035378000000000034\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  209\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 10153\n",
      "Accumulated cost so far: 0.03553550000000003\n",
      "Total tokens used for this call: 35\n",
      "\n",
      "Index:  210\n",
      "Cost for this call: 0.0001225\n",
      "Accumulated tokens so far: 10188\n",
      "Accumulated cost so far: 0.03565800000000003\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  211\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 10232\n",
      "Accumulated cost so far: 0.03581200000000003\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  212\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 10276\n",
      "Accumulated cost so far: 0.03596600000000003\n",
      "Total tokens used for this call: 60\n",
      "\n",
      "Index:  213\n",
      "Cost for this call: 0.00021\n",
      "Accumulated tokens so far: 10336\n",
      "Accumulated cost so far: 0.036176000000000035\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  214\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 10380\n",
      "Accumulated cost so far: 0.036330000000000036\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  215\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 10425\n",
      "Accumulated cost so far: 0.036487500000000034\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  216\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 10471\n",
      "Accumulated cost so far: 0.036648500000000035\n",
      "Total tokens used for this call: 53\n",
      "\n",
      "Index:  217\n",
      "Cost for this call: 0.0001855\n",
      "Accumulated tokens so far: 10524\n",
      "Accumulated cost so far: 0.03683400000000003\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  218\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 10565\n",
      "Accumulated cost so far: 0.03697750000000003\n",
      "Total tokens used for this call: 34\n",
      "\n",
      "Index:  219\n",
      "Cost for this call: 0.00011899999999999999\n",
      "Accumulated tokens so far: 10599\n",
      "Accumulated cost so far: 0.03709650000000003\n",
      "Total tokens used for this call: 51\n",
      "\n",
      "Index:  220\n",
      "Cost for this call: 0.0001785\n",
      "Accumulated tokens so far: 10650\n",
      "Accumulated cost so far: 0.03727500000000003\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  221\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 10692\n",
      "Accumulated cost so far: 0.03742200000000003\n",
      "Total tokens used for this call: 32\n",
      "\n",
      "Index:  222\n",
      "Cost for this call: 0.000112\n",
      "Accumulated tokens so far: 10724\n",
      "Accumulated cost so far: 0.03753400000000003\n",
      "Total tokens used for this call: 61\n",
      "\n",
      "Index:  223\n",
      "Cost for this call: 0.00021349999999999999\n",
      "Accumulated tokens so far: 10785\n",
      "Accumulated cost so far: 0.03774750000000003\n",
      "Total tokens used for this call: 43\n",
      "\n",
      "Index:  224\n",
      "Cost for this call: 0.0001505\n",
      "Accumulated tokens so far: 10828\n",
      "Accumulated cost so far: 0.03789800000000003\n",
      "Total tokens used for this call: 38\n",
      "\n",
      "Index:  225\n",
      "Cost for this call: 0.000133\n",
      "Accumulated tokens so far: 10866\n",
      "Accumulated cost so far: 0.03803100000000003\n",
      "Total tokens used for this call: 71\n",
      "\n",
      "Index:  226\n",
      "Cost for this call: 0.0002485\n",
      "Accumulated tokens so far: 10937\n",
      "Accumulated cost so far: 0.03827950000000003\n",
      "Total tokens used for this call: 69\n",
      "\n",
      "Index:  227\n",
      "Cost for this call: 0.0002415\n",
      "Accumulated tokens so far: 11006\n",
      "Accumulated cost so far: 0.03852100000000003\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  228\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 11047\n",
      "Accumulated cost so far: 0.038664500000000025\n",
      "Total tokens used for this call: 73\n",
      "\n",
      "Index:  229\n",
      "Cost for this call: 0.0002555\n",
      "Accumulated tokens so far: 11120\n",
      "Accumulated cost so far: 0.038920000000000024\n",
      "Total tokens used for this call: 53\n",
      "\n",
      "Index:  230\n",
      "Cost for this call: 0.0001855\n",
      "Accumulated tokens so far: 11173\n",
      "Accumulated cost so far: 0.03910550000000002\n",
      "Total tokens used for this call: 51\n",
      "\n",
      "Index:  231\n",
      "Cost for this call: 0.0001785\n",
      "Accumulated tokens so far: 11224\n",
      "Accumulated cost so far: 0.03928400000000002\n",
      "Total tokens used for this call: 49\n",
      "\n",
      "Index:  232\n",
      "Cost for this call: 0.0001715\n",
      "Accumulated tokens so far: 11273\n",
      "Accumulated cost so far: 0.03945550000000002\n",
      "Total tokens used for this call: 61\n",
      "\n",
      "Index:  233\n",
      "Cost for this call: 0.00021349999999999999\n",
      "Accumulated tokens so far: 11334\n",
      "Accumulated cost so far: 0.03966900000000002\n",
      "Total tokens used for this call: 35\n",
      "\n",
      "Index:  234\n",
      "Cost for this call: 0.0001225\n",
      "Accumulated tokens so far: 11369\n",
      "Accumulated cost so far: 0.039791500000000014\n",
      "Total tokens used for this call: 54\n",
      "\n",
      "Index:  235\n",
      "Cost for this call: 0.00018899999999999999\n",
      "Accumulated tokens so far: 11423\n",
      "Accumulated cost so far: 0.039980500000000016\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  236\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 11465\n",
      "Accumulated cost so far: 0.04012750000000002\n",
      "Total tokens used for this call: 49\n",
      "\n",
      "Index:  237\n",
      "Cost for this call: 0.0001715\n",
      "Accumulated tokens so far: 11514\n",
      "Accumulated cost so far: 0.040299000000000015\n",
      "Total tokens used for this call: 43\n",
      "\n",
      "Index:  238\n",
      "Cost for this call: 0.0001505\n",
      "Accumulated tokens so far: 11557\n",
      "Accumulated cost so far: 0.04044950000000001\n",
      "Total tokens used for this call: 38\n",
      "\n",
      "Index:  239\n",
      "Cost for this call: 0.000133\n",
      "Accumulated tokens so far: 11595\n",
      "Accumulated cost so far: 0.040582500000000014\n",
      "Total tokens used for this call: 47\n",
      "\n",
      "Index:  240\n",
      "Cost for this call: 0.0001645\n",
      "Accumulated tokens so far: 11642\n",
      "Accumulated cost so far: 0.04074700000000001\n",
      "Total tokens used for this call: 52\n",
      "\n",
      "Index:  241\n",
      "Cost for this call: 0.000182\n",
      "Accumulated tokens so far: 11694\n",
      "Accumulated cost so far: 0.040929000000000014\n",
      "Total tokens used for this call: 62\n",
      "\n",
      "Index:  242\n",
      "Cost for this call: 0.000217\n",
      "Accumulated tokens so far: 11756\n",
      "Accumulated cost so far: 0.041146000000000016\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  243\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 11800\n",
      "Accumulated cost so far: 0.04130000000000002\n",
      "Total tokens used for this call: 36\n",
      "\n",
      "Index:  244\n",
      "Cost for this call: 0.000126\n",
      "Accumulated tokens so far: 11836\n",
      "Accumulated cost so far: 0.04142600000000002\n",
      "Total tokens used for this call: 50\n",
      "\n",
      "Index:  245\n",
      "Cost for this call: 0.000175\n",
      "Accumulated tokens so far: 11886\n",
      "Accumulated cost so far: 0.04160100000000002\n",
      "Total tokens used for this call: 38\n",
      "\n",
      "Index:  246\n",
      "Cost for this call: 0.000133\n",
      "Accumulated tokens so far: 11924\n",
      "Accumulated cost so far: 0.04173400000000002\n",
      "Total tokens used for this call: 71\n",
      "\n",
      "Index:  247\n",
      "Cost for this call: 0.0002485\n",
      "Accumulated tokens so far: 11995\n",
      "Accumulated cost so far: 0.04198250000000002\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  248\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 12037\n",
      "Accumulated cost so far: 0.04212950000000002\n",
      "Total tokens used for this call: 52\n",
      "\n",
      "Index:  249\n",
      "Cost for this call: 0.000182\n",
      "Accumulated tokens so far: 12089\n",
      "Accumulated cost so far: 0.04231150000000002\n",
      "Total tokens used for this call: 37\n",
      "\n",
      "Index:  250\n",
      "Cost for this call: 0.0001295\n",
      "Accumulated tokens so far: 12126\n",
      "Accumulated cost so far: 0.04244100000000002\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  251\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 12168\n",
      "Accumulated cost so far: 0.04258800000000002\n",
      "Total tokens used for this call: 52\n",
      "\n",
      "Index:  252\n",
      "Cost for this call: 0.000182\n",
      "Accumulated tokens so far: 12220\n",
      "Accumulated cost so far: 0.04277000000000002\n",
      "Total tokens used for this call: 66\n",
      "\n",
      "Index:  253\n",
      "Cost for this call: 0.000231\n",
      "Accumulated tokens so far: 12286\n",
      "Accumulated cost so far: 0.043001000000000025\n",
      "Total tokens used for this call: 58\n",
      "\n",
      "Index:  254\n",
      "Cost for this call: 0.000203\n",
      "Accumulated tokens so far: 12344\n",
      "Accumulated cost so far: 0.04320400000000003\n",
      "Total tokens used for this call: 74\n",
      "\n",
      "Index:  255\n",
      "Cost for this call: 0.000259\n",
      "Accumulated tokens so far: 12418\n",
      "Accumulated cost so far: 0.04346300000000003\n",
      "Total tokens used for this call: 43\n",
      "\n",
      "Index:  256\n",
      "Cost for this call: 0.0001505\n",
      "Accumulated tokens so far: 12461\n",
      "Accumulated cost so far: 0.04361350000000003\n",
      "Total tokens used for this call: 43\n",
      "\n",
      "Index:  257\n",
      "Cost for this call: 0.0001505\n",
      "Accumulated tokens so far: 12504\n",
      "Accumulated cost so far: 0.043764000000000025\n",
      "Total tokens used for this call: 62\n",
      "\n",
      "Index:  258\n",
      "Cost for this call: 0.000217\n",
      "Accumulated tokens so far: 12566\n",
      "Accumulated cost so far: 0.04398100000000003\n",
      "Total tokens used for this call: 83\n",
      "\n",
      "Index:  259\n",
      "Cost for this call: 0.0002905\n",
      "Accumulated tokens so far: 12649\n",
      "Accumulated cost so far: 0.044271500000000026\n",
      "Total tokens used for this call: 54\n",
      "\n",
      "Index:  260\n",
      "Cost for this call: 0.00018899999999999999\n",
      "Accumulated tokens so far: 12703\n",
      "Accumulated cost so far: 0.04446050000000003\n",
      "Total tokens used for this call: 53\n",
      "\n",
      "Index:  261\n",
      "Cost for this call: 0.0001855\n",
      "Accumulated tokens so far: 12756\n",
      "Accumulated cost so far: 0.044646000000000026\n",
      "Total tokens used for this call: 56\n",
      "\n",
      "Index:  262\n",
      "Cost for this call: 0.000196\n",
      "Accumulated tokens so far: 12812\n",
      "Accumulated cost so far: 0.04484200000000003\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  263\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 12856\n",
      "Accumulated cost so far: 0.04499600000000003\n",
      "Total tokens used for this call: 56\n",
      "\n",
      "Index:  264\n",
      "Cost for this call: 0.000196\n",
      "Accumulated tokens so far: 12912\n",
      "Accumulated cost so far: 0.04519200000000003\n",
      "Total tokens used for this call: 54\n",
      "\n",
      "Index:  265\n",
      "Cost for this call: 0.00018899999999999999\n",
      "Accumulated tokens so far: 12966\n",
      "Accumulated cost so far: 0.04538100000000003\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  266\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 13007\n",
      "Accumulated cost so far: 0.04552450000000003\n",
      "Total tokens used for this call: 34\n",
      "\n",
      "Index:  267\n",
      "Cost for this call: 0.00011899999999999999\n",
      "Accumulated tokens so far: 13041\n",
      "Accumulated cost so far: 0.04564350000000003\n",
      "Total tokens used for this call: 47\n",
      "\n",
      "Index:  268\n",
      "Cost for this call: 0.0001645\n",
      "Accumulated tokens so far: 13088\n",
      "Accumulated cost so far: 0.04580800000000003\n",
      "Total tokens used for this call: 60\n",
      "\n",
      "Index:  269\n",
      "Cost for this call: 0.00021\n",
      "Accumulated tokens so far: 13148\n",
      "Accumulated cost so far: 0.04601800000000003\n",
      "Total tokens used for this call: 31\n",
      "\n",
      "Index:  270\n",
      "Cost for this call: 0.0001085\n",
      "Accumulated tokens so far: 13179\n",
      "Accumulated cost so far: 0.04612650000000003\n",
      "Total tokens used for this call: 49\n",
      "\n",
      "Index:  271\n",
      "Cost for this call: 0.0001715\n",
      "Accumulated tokens so far: 13228\n",
      "Accumulated cost so far: 0.04629800000000003\n",
      "Total tokens used for this call: 38\n",
      "\n",
      "Index:  272\n",
      "Cost for this call: 0.000133\n",
      "Accumulated tokens so far: 13266\n",
      "Accumulated cost so far: 0.04643100000000003\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  273\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 13312\n",
      "Accumulated cost so far: 0.04659200000000003\n",
      "Total tokens used for this call: 65\n",
      "\n",
      "Index:  274\n",
      "Cost for this call: 0.0002275\n",
      "Accumulated tokens so far: 13377\n",
      "Accumulated cost so far: 0.04681950000000003\n",
      "Total tokens used for this call: 48\n",
      "\n",
      "Index:  275\n",
      "Cost for this call: 0.000168\n",
      "Accumulated tokens so far: 13425\n",
      "Accumulated cost so far: 0.04698750000000003\n",
      "Total tokens used for this call: 59\n",
      "\n",
      "Index:  276\n",
      "Cost for this call: 0.0002065\n",
      "Accumulated tokens so far: 13484\n",
      "Accumulated cost so far: 0.04719400000000003\n",
      "Total tokens used for this call: 37\n",
      "\n",
      "Index:  277\n",
      "Cost for this call: 0.0001295\n",
      "Accumulated tokens so far: 13521\n",
      "Accumulated cost so far: 0.047323500000000025\n",
      "Total tokens used for this call: 61\n",
      "\n",
      "Index:  278\n",
      "Cost for this call: 0.00021349999999999999\n",
      "Accumulated tokens so far: 13582\n",
      "Accumulated cost so far: 0.047537000000000024\n",
      "Total tokens used for this call: 31\n",
      "\n",
      "Index:  279\n",
      "Cost for this call: 0.0001085\n",
      "Accumulated tokens so far: 13613\n",
      "Accumulated cost so far: 0.04764550000000002\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  280\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 13654\n",
      "Accumulated cost so far: 0.04778900000000002\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  281\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 13698\n",
      "Accumulated cost so far: 0.04794300000000002\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  282\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 13739\n",
      "Accumulated cost so far: 0.04808650000000002\n",
      "Total tokens used for this call: 64\n",
      "\n",
      "Index:  283\n",
      "Cost for this call: 0.000224\n",
      "Accumulated tokens so far: 13803\n",
      "Accumulated cost so far: 0.04831050000000002\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  284\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 13844\n",
      "Accumulated cost so far: 0.04845400000000002\n",
      "Total tokens used for this call: 36\n",
      "\n",
      "Index:  285\n",
      "Cost for this call: 0.000126\n",
      "Accumulated tokens so far: 13880\n",
      "Accumulated cost so far: 0.04858000000000002\n",
      "Total tokens used for this call: 57\n",
      "\n",
      "Index:  286\n",
      "Cost for this call: 0.0001995\n",
      "Accumulated tokens so far: 13937\n",
      "Accumulated cost so far: 0.04877950000000002\n",
      "Total tokens used for this call: 57\n",
      "\n",
      "Index:  287\n",
      "Cost for this call: 0.0001995\n",
      "Accumulated tokens so far: 13994\n",
      "Accumulated cost so far: 0.048979000000000016\n",
      "Total tokens used for this call: 38\n",
      "\n",
      "Index:  288\n",
      "Cost for this call: 0.000133\n",
      "Accumulated tokens so far: 14032\n",
      "Accumulated cost so far: 0.04911200000000002\n",
      "Total tokens used for this call: 60\n",
      "\n",
      "Index:  289\n",
      "Cost for this call: 0.00021\n",
      "Accumulated tokens so far: 14092\n",
      "Accumulated cost so far: 0.04932200000000002\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  290\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 14137\n",
      "Accumulated cost so far: 0.049479500000000017\n",
      "Total tokens used for this call: 52\n",
      "\n",
      "Index:  291\n",
      "Cost for this call: 0.000182\n",
      "Accumulated tokens so far: 14189\n",
      "Accumulated cost so far: 0.04966150000000002\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  292\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 14231\n",
      "Accumulated cost so far: 0.04980850000000002\n",
      "Total tokens used for this call: 58\n",
      "\n",
      "Index:  293\n",
      "Cost for this call: 0.000203\n",
      "Accumulated tokens so far: 14289\n",
      "Accumulated cost so far: 0.05001150000000002\n",
      "Total tokens used for this call: 54\n",
      "\n",
      "Index:  294\n",
      "Cost for this call: 0.00018899999999999999\n",
      "Accumulated tokens so far: 14343\n",
      "Accumulated cost so far: 0.05020050000000002\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  295\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 14387\n",
      "Accumulated cost so far: 0.050354500000000024\n",
      "Total tokens used for this call: 49\n",
      "\n",
      "Index:  296\n",
      "Cost for this call: 0.0001715\n",
      "Accumulated tokens so far: 14436\n",
      "Accumulated cost so far: 0.05052600000000002\n",
      "Total tokens used for this call: 51\n",
      "\n",
      "Index:  297\n",
      "Cost for this call: 0.0001785\n",
      "Accumulated tokens so far: 14487\n",
      "Accumulated cost so far: 0.05070450000000002\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  298\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 14529\n",
      "Accumulated cost so far: 0.05085150000000002\n",
      "Total tokens used for this call: 56\n",
      "\n",
      "Index:  299\n",
      "Cost for this call: 0.000196\n",
      "Accumulated tokens so far: 14585\n",
      "Accumulated cost so far: 0.05104750000000002\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  300\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 14626\n",
      "Accumulated cost so far: 0.05119100000000002\n",
      "Total tokens used for this call: 48\n",
      "\n",
      "Index:  301\n",
      "Cost for this call: 0.000168\n",
      "Accumulated tokens so far: 14674\n",
      "Accumulated cost so far: 0.05135900000000002\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  302\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 14720\n",
      "Accumulated cost so far: 0.051520000000000024\n",
      "Total tokens used for this call: 37\n",
      "\n",
      "Index:  303\n",
      "Cost for this call: 0.0001295\n",
      "Accumulated tokens so far: 14757\n",
      "Accumulated cost so far: 0.05164950000000002\n",
      "Total tokens used for this call: 70\n",
      "\n",
      "Index:  304\n",
      "Cost for this call: 0.000245\n",
      "Accumulated tokens so far: 14827\n",
      "Accumulated cost so far: 0.051894500000000024\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  305\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 14868\n",
      "Accumulated cost so far: 0.05203800000000002\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  306\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 14909\n",
      "Accumulated cost so far: 0.05218150000000002\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  307\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 14948\n",
      "Accumulated cost so far: 0.05231800000000002\n",
      "Total tokens used for this call: 55\n",
      "\n",
      "Index:  308\n",
      "Cost for this call: 0.0001925\n",
      "Accumulated tokens so far: 15003\n",
      "Accumulated cost so far: 0.052510500000000015\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  309\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 15042\n",
      "Accumulated cost so far: 0.05264700000000001\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  310\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 15082\n",
      "Accumulated cost so far: 0.052787000000000014\n",
      "Total tokens used for this call: 53\n",
      "\n",
      "Index:  311\n",
      "Cost for this call: 0.0001855\n",
      "Accumulated tokens so far: 15135\n",
      "Accumulated cost so far: 0.05297250000000001\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  312\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 15177\n",
      "Accumulated cost so far: 0.053119500000000014\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  313\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 15222\n",
      "Accumulated cost so far: 0.05327700000000001\n",
      "Total tokens used for this call: 59\n",
      "\n",
      "Index:  314\n",
      "Cost for this call: 0.0002065\n",
      "Accumulated tokens so far: 15281\n",
      "Accumulated cost so far: 0.05348350000000001\n",
      "Total tokens used for this call: 37\n",
      "\n",
      "Index:  315\n",
      "Cost for this call: 0.0001295\n",
      "Accumulated tokens so far: 15318\n",
      "Accumulated cost so far: 0.05361300000000001\n",
      "Total tokens used for this call: 63\n",
      "\n",
      "Index:  316\n",
      "Cost for this call: 0.0002205\n",
      "Accumulated tokens so far: 15381\n",
      "Accumulated cost so far: 0.053833500000000006\n",
      "Total tokens used for this call: 53\n",
      "\n",
      "Index:  317\n",
      "Cost for this call: 0.0001855\n",
      "Accumulated tokens so far: 15434\n",
      "Accumulated cost so far: 0.054019000000000005\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  318\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 15480\n",
      "Accumulated cost so far: 0.054180000000000006\n",
      "Total tokens used for this call: 36\n",
      "\n",
      "Index:  319\n",
      "Cost for this call: 0.000126\n",
      "Accumulated tokens so far: 15516\n",
      "Accumulated cost so far: 0.05430600000000001\n",
      "Total tokens used for this call: 56\n",
      "\n",
      "Index:  320\n",
      "Cost for this call: 0.000196\n",
      "Accumulated tokens so far: 15572\n",
      "Accumulated cost so far: 0.05450200000000001\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  321\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 15612\n",
      "Accumulated cost so far: 0.05464200000000001\n",
      "Total tokens used for this call: 43\n",
      "\n",
      "Index:  322\n",
      "Cost for this call: 0.0001505\n",
      "Accumulated tokens so far: 15655\n",
      "Accumulated cost so far: 0.05479250000000001\n",
      "Total tokens used for this call: 61\n",
      "\n",
      "Index:  323\n",
      "Cost for this call: 0.00021349999999999999\n",
      "Accumulated tokens so far: 15716\n",
      "Accumulated cost so far: 0.055006000000000006\n",
      "Total tokens used for this call: 57\n",
      "\n",
      "Index:  324\n",
      "Cost for this call: 0.0001995\n",
      "Accumulated tokens so far: 15773\n",
      "Accumulated cost so far: 0.055205500000000005\n",
      "Total tokens used for this call: 63\n",
      "\n",
      "Index:  325\n",
      "Cost for this call: 0.0002205\n",
      "Accumulated tokens so far: 15836\n",
      "Accumulated cost so far: 0.055426\n",
      "Total tokens used for this call: 52\n",
      "\n",
      "Index:  326\n",
      "Cost for this call: 0.000182\n",
      "Accumulated tokens so far: 15888\n",
      "Accumulated cost so far: 0.055608000000000005\n",
      "Total tokens used for this call: 64\n",
      "\n",
      "Index:  327\n",
      "Cost for this call: 0.000224\n",
      "Accumulated tokens so far: 15952\n",
      "Accumulated cost so far: 0.05583200000000001\n",
      "Total tokens used for this call: 49\n",
      "\n",
      "Index:  328\n",
      "Cost for this call: 0.0001715\n",
      "Accumulated tokens so far: 16001\n",
      "Accumulated cost so far: 0.056003500000000005\n",
      "Total tokens used for this call: 30\n",
      "\n",
      "Index:  329\n",
      "Cost for this call: 0.000105\n",
      "Accumulated tokens so far: 16031\n",
      "Accumulated cost so far: 0.056108500000000006\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  330\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 16072\n",
      "Accumulated cost so far: 0.056252\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  331\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 16114\n",
      "Accumulated cost so far: 0.056399000000000005\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  332\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 16155\n",
      "Accumulated cost so far: 0.0565425\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  333\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 16199\n",
      "Accumulated cost so far: 0.056696500000000004\n",
      "Total tokens used for this call: 74\n",
      "\n",
      "Index:  334\n",
      "Cost for this call: 0.000259\n",
      "Accumulated tokens so far: 16273\n",
      "Accumulated cost so far: 0.056955500000000006\n",
      "Total tokens used for this call: 35\n",
      "\n",
      "Index:  335\n",
      "Cost for this call: 0.0001225\n",
      "Accumulated tokens so far: 16308\n",
      "Accumulated cost so far: 0.057078000000000004\n",
      "Total tokens used for this call: 61\n",
      "\n",
      "Index:  336\n",
      "Cost for this call: 0.00021349999999999999\n",
      "Accumulated tokens so far: 16369\n",
      "Accumulated cost so far: 0.0572915\n",
      "Total tokens used for this call: 51\n",
      "\n",
      "Index:  337\n",
      "Cost for this call: 0.0001785\n",
      "Accumulated tokens so far: 16420\n",
      "Accumulated cost so far: 0.05747\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  338\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 16465\n",
      "Accumulated cost so far: 0.0576275\n",
      "Total tokens used for this call: 67\n",
      "\n",
      "Index:  339\n",
      "Cost for this call: 0.0002345\n",
      "Accumulated tokens so far: 16532\n",
      "Accumulated cost so far: 0.057862\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  340\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 16576\n",
      "Accumulated cost so far: 0.058016\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  341\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 16617\n",
      "Accumulated cost so far: 0.058159499999999996\n",
      "Total tokens used for this call: 72\n",
      "\n",
      "Index:  342\n",
      "Cost for this call: 0.000252\n",
      "Accumulated tokens so far: 16689\n",
      "Accumulated cost so far: 0.0584115\n",
      "Total tokens used for this call: 54\n",
      "\n",
      "Index:  343\n",
      "Cost for this call: 0.00018899999999999999\n",
      "Accumulated tokens so far: 16743\n",
      "Accumulated cost so far: 0.0586005\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  344\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 16785\n",
      "Accumulated cost so far: 0.0587475\n",
      "Total tokens used for this call: 32\n",
      "\n",
      "Index:  345\n",
      "Cost for this call: 0.000112\n",
      "Accumulated tokens so far: 16817\n",
      "Accumulated cost so far: 0.0588595\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  346\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 16862\n",
      "Accumulated cost so far: 0.059017\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  347\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 16906\n",
      "Accumulated cost so far: 0.059171\n",
      "Total tokens used for this call: 33\n",
      "\n",
      "Index:  348\n",
      "Cost for this call: 0.0001155\n",
      "Accumulated tokens so far: 16939\n",
      "Accumulated cost so far: 0.0592865\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  349\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 16978\n",
      "Accumulated cost so far: 0.059423\n",
      "Total tokens used for this call: 53\n",
      "\n",
      "Index:  350\n",
      "Cost for this call: 0.0001855\n",
      "Accumulated tokens so far: 17031\n",
      "Accumulated cost so far: 0.059608499999999995\n",
      "Total tokens used for this call: 34\n",
      "\n",
      "Index:  351\n",
      "Cost for this call: 0.00011899999999999999\n",
      "Accumulated tokens so far: 17065\n",
      "Accumulated cost so far: 0.059727499999999996\n",
      "Total tokens used for this call: 37\n",
      "\n",
      "Index:  352\n",
      "Cost for this call: 0.0001295\n",
      "Accumulated tokens so far: 17102\n",
      "Accumulated cost so far: 0.059856999999999994\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  353\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 17143\n",
      "Accumulated cost so far: 0.06000049999999999\n",
      "Total tokens used for this call: 50\n",
      "\n",
      "Index:  354\n",
      "Cost for this call: 0.000175\n",
      "Accumulated tokens so far: 17193\n",
      "Accumulated cost so far: 0.06017549999999999\n",
      "Total tokens used for this call: 55\n",
      "\n",
      "Index:  355\n",
      "Cost for this call: 0.0001925\n",
      "Accumulated tokens so far: 17248\n",
      "Accumulated cost so far: 0.06036799999999999\n",
      "Total tokens used for this call: 54\n",
      "\n",
      "Index:  356\n",
      "Cost for this call: 0.00018899999999999999\n",
      "Accumulated tokens so far: 17302\n",
      "Accumulated cost so far: 0.06055699999999999\n",
      "Total tokens used for this call: 51\n",
      "\n",
      "Index:  357\n",
      "Cost for this call: 0.0001785\n",
      "Accumulated tokens so far: 17353\n",
      "Accumulated cost so far: 0.06073549999999999\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  358\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 17398\n",
      "Accumulated cost so far: 0.06089299999999999\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  359\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 17443\n",
      "Accumulated cost so far: 0.06105049999999999\n",
      "Total tokens used for this call: 54\n",
      "\n",
      "Index:  360\n",
      "Cost for this call: 0.00018899999999999999\n",
      "Accumulated tokens so far: 17497\n",
      "Accumulated cost so far: 0.06123949999999999\n",
      "Total tokens used for this call: 36\n",
      "\n",
      "Index:  361\n",
      "Cost for this call: 0.000126\n",
      "Accumulated tokens so far: 17533\n",
      "Accumulated cost so far: 0.06136549999999999\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  362\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 17574\n",
      "Accumulated cost so far: 0.06150899999999999\n",
      "Total tokens used for this call: 50\n",
      "\n",
      "Index:  363\n",
      "Cost for this call: 0.000175\n",
      "Accumulated tokens so far: 17624\n",
      "Accumulated cost so far: 0.06168399999999999\n",
      "Total tokens used for this call: 37\n",
      "\n",
      "Index:  364\n",
      "Cost for this call: 0.0001295\n",
      "Accumulated tokens so far: 17661\n",
      "Accumulated cost so far: 0.061813499999999987\n",
      "Total tokens used for this call: 48\n",
      "\n",
      "Index:  365\n",
      "Cost for this call: 0.000168\n",
      "Accumulated tokens so far: 17709\n",
      "Accumulated cost so far: 0.06198149999999999\n",
      "Total tokens used for this call: 35\n",
      "\n",
      "Index:  366\n",
      "Cost for this call: 0.0001225\n",
      "Accumulated tokens so far: 17744\n",
      "Accumulated cost so far: 0.062103999999999986\n",
      "Total tokens used for this call: 53\n",
      "\n",
      "Index:  367\n",
      "Cost for this call: 0.0001855\n",
      "Accumulated tokens so far: 17797\n",
      "Accumulated cost so far: 0.062289499999999984\n",
      "Total tokens used for this call: 38\n",
      "\n",
      "Index:  368\n",
      "Cost for this call: 0.000133\n",
      "Accumulated tokens so far: 17835\n",
      "Accumulated cost so far: 0.062422499999999985\n",
      "Total tokens used for this call: 59\n",
      "\n",
      "Index:  369\n",
      "Cost for this call: 0.0002065\n",
      "Accumulated tokens so far: 17894\n",
      "Accumulated cost so far: 0.06262899999999999\n",
      "Total tokens used for this call: 49\n",
      "\n",
      "Index:  370\n",
      "Cost for this call: 0.0001715\n",
      "Accumulated tokens so far: 17943\n",
      "Accumulated cost so far: 0.0628005\n",
      "Total tokens used for this call: 65\n",
      "\n",
      "Index:  371\n",
      "Cost for this call: 0.0002275\n",
      "Accumulated tokens so far: 18008\n",
      "Accumulated cost so far: 0.063028\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  372\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 18047\n",
      "Accumulated cost so far: 0.0631645\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  373\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 18088\n",
      "Accumulated cost so far: 0.063308\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  374\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 18134\n",
      "Accumulated cost so far: 0.063469\n",
      "Total tokens used for this call: 37\n",
      "\n",
      "Index:  375\n",
      "Cost for this call: 0.0001295\n",
      "Accumulated tokens so far: 18171\n",
      "Accumulated cost so far: 0.0635985\n",
      "Total tokens used for this call: 62\n",
      "\n",
      "Index:  376\n",
      "Cost for this call: 0.000217\n",
      "Accumulated tokens so far: 18233\n",
      "Accumulated cost so far: 0.0638155\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  377\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 18277\n",
      "Accumulated cost so far: 0.0639695\n",
      "Total tokens used for this call: 47\n",
      "\n",
      "Index:  378\n",
      "Cost for this call: 0.0001645\n",
      "Accumulated tokens so far: 18324\n",
      "Accumulated cost so far: 0.064134\n",
      "Total tokens used for this call: 62\n",
      "\n",
      "Index:  379\n",
      "Cost for this call: 0.000217\n",
      "Accumulated tokens so far: 18386\n",
      "Accumulated cost so far: 0.06435099999999999\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  380\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 18430\n",
      "Accumulated cost so far: 0.06450499999999999\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  381\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 18475\n",
      "Accumulated cost so far: 0.0646625\n",
      "Total tokens used for this call: 64\n",
      "\n",
      "Index:  382\n",
      "Cost for this call: 0.000224\n",
      "Accumulated tokens so far: 18539\n",
      "Accumulated cost so far: 0.0648865\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  383\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 18579\n",
      "Accumulated cost so far: 0.0650265\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  384\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 18619\n",
      "Accumulated cost so far: 0.0651665\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  385\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 18664\n",
      "Accumulated cost so far: 0.06532400000000001\n",
      "Total tokens used for this call: 43\n",
      "\n",
      "Index:  386\n",
      "Cost for this call: 0.0001505\n",
      "Accumulated tokens so far: 18707\n",
      "Accumulated cost so far: 0.0654745\n",
      "Total tokens used for this call: 43\n",
      "\n",
      "Index:  387\n",
      "Cost for this call: 0.0001505\n",
      "Accumulated tokens so far: 18750\n",
      "Accumulated cost so far: 0.065625\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  388\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 18789\n",
      "Accumulated cost so far: 0.0657615\n",
      "Total tokens used for this call: 54\n",
      "\n",
      "Index:  389\n",
      "Cost for this call: 0.00018899999999999999\n",
      "Accumulated tokens so far: 18843\n",
      "Accumulated cost so far: 0.0659505\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  390\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 18883\n",
      "Accumulated cost so far: 0.0660905\n",
      "Total tokens used for this call: 55\n",
      "\n",
      "Index:  391\n",
      "Cost for this call: 0.0001925\n",
      "Accumulated tokens so far: 18938\n",
      "Accumulated cost so far: 0.066283\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  392\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 18979\n",
      "Accumulated cost so far: 0.0664265\n",
      "Total tokens used for this call: 67\n",
      "\n",
      "Index:  393\n",
      "Cost for this call: 0.0002345\n",
      "Accumulated tokens so far: 19046\n",
      "Accumulated cost so far: 0.066661\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  394\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 19088\n",
      "Accumulated cost so far: 0.06680799999999999\n",
      "Total tokens used for this call: 51\n",
      "\n",
      "Index:  395\n",
      "Cost for this call: 0.0001785\n",
      "Accumulated tokens so far: 19139\n",
      "Accumulated cost so far: 0.06698649999999999\n",
      "Total tokens used for this call: 66\n",
      "\n",
      "Index:  396\n",
      "Cost for this call: 0.000231\n",
      "Accumulated tokens so far: 19205\n",
      "Accumulated cost so far: 0.06721749999999999\n",
      "Total tokens used for this call: 70\n",
      "\n",
      "Index:  397\n",
      "Cost for this call: 0.000245\n",
      "Accumulated tokens so far: 19275\n",
      "Accumulated cost so far: 0.06746249999999998\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  398\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 19315\n",
      "Accumulated cost so far: 0.06760249999999998\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  399\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 19361\n",
      "Accumulated cost so far: 0.06776349999999998\n",
      "Total tokens used for this call: 47\n",
      "\n",
      "Index:  400\n",
      "Cost for this call: 0.0001645\n",
      "Accumulated tokens so far: 19408\n",
      "Accumulated cost so far: 0.06792799999999997\n",
      "Total tokens used for this call: 35\n",
      "\n",
      "Index:  401\n",
      "Cost for this call: 0.0001225\n",
      "Accumulated tokens so far: 19443\n",
      "Accumulated cost so far: 0.06805049999999997\n",
      "Total tokens used for this call: 53\n",
      "\n",
      "Index:  402\n",
      "Cost for this call: 0.0001855\n",
      "Accumulated tokens so far: 19496\n",
      "Accumulated cost so far: 0.06823599999999998\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  403\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 19535\n",
      "Accumulated cost so far: 0.06837249999999997\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  404\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 19575\n",
      "Accumulated cost so far: 0.06851249999999998\n",
      "Total tokens used for this call: 71\n",
      "\n",
      "Index:  405\n",
      "Cost for this call: 0.0002485\n",
      "Accumulated tokens so far: 19646\n",
      "Accumulated cost so far: 0.06876099999999997\n",
      "Total tokens used for this call: 57\n",
      "\n",
      "Index:  406\n",
      "Cost for this call: 0.0001995\n",
      "Accumulated tokens so far: 19703\n",
      "Accumulated cost so far: 0.06896049999999998\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  407\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 19743\n",
      "Accumulated cost so far: 0.06910049999999998\n",
      "Total tokens used for this call: 49\n",
      "\n",
      "Index:  408\n",
      "Cost for this call: 0.0001715\n",
      "Accumulated tokens so far: 19792\n",
      "Accumulated cost so far: 0.06927199999999999\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  409\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 19831\n",
      "Accumulated cost so far: 0.06940849999999998\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  410\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 19877\n",
      "Accumulated cost so far: 0.06956949999999998\n",
      "Total tokens used for this call: 67\n",
      "\n",
      "Index:  411\n",
      "Cost for this call: 0.0002345\n",
      "Accumulated tokens so far: 19944\n",
      "Accumulated cost so far: 0.06980399999999998\n",
      "Total tokens used for this call: 39\n",
      "\n",
      "Index:  412\n",
      "Cost for this call: 0.0001365\n",
      "Accumulated tokens so far: 19983\n",
      "Accumulated cost so far: 0.06994049999999997\n",
      "Total tokens used for this call: 65\n",
      "\n",
      "Index:  413\n",
      "Cost for this call: 0.0002275\n",
      "Accumulated tokens so far: 20048\n",
      "Accumulated cost so far: 0.07016799999999998\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  414\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 20089\n",
      "Accumulated cost so far: 0.07031149999999999\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  415\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 20129\n",
      "Accumulated cost so far: 0.07045149999999999\n",
      "Total tokens used for this call: 47\n",
      "\n",
      "Index:  416\n",
      "Cost for this call: 0.0001645\n",
      "Accumulated tokens so far: 20176\n",
      "Accumulated cost so far: 0.07061599999999998\n",
      "Total tokens used for this call: 55\n",
      "\n",
      "Index:  417\n",
      "Cost for this call: 0.0001925\n",
      "Accumulated tokens so far: 20231\n",
      "Accumulated cost so far: 0.07080849999999998\n",
      "Total tokens used for this call: 48\n",
      "\n",
      "Index:  418\n",
      "Cost for this call: 0.000168\n",
      "Accumulated tokens so far: 20279\n",
      "Accumulated cost so far: 0.07097649999999998\n",
      "Total tokens used for this call: 43\n",
      "\n",
      "Index:  419\n",
      "Cost for this call: 0.0001505\n",
      "Accumulated tokens so far: 20322\n",
      "Accumulated cost so far: 0.07112699999999998\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  420\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 20362\n",
      "Accumulated cost so far: 0.07126699999999998\n",
      "Total tokens used for this call: 37\n",
      "\n",
      "Index:  421\n",
      "Cost for this call: 0.0001295\n",
      "Accumulated tokens so far: 20399\n",
      "Accumulated cost so far: 0.07139649999999999\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  422\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 20444\n",
      "Accumulated cost so far: 0.07155399999999999\n",
      "Total tokens used for this call: 33\n",
      "\n",
      "Index:  423\n",
      "Cost for this call: 0.0001155\n",
      "Accumulated tokens so far: 20477\n",
      "Accumulated cost so far: 0.0716695\n",
      "Total tokens used for this call: 66\n",
      "\n",
      "Index:  424\n",
      "Cost for this call: 0.000231\n",
      "Accumulated tokens so far: 20543\n",
      "Accumulated cost so far: 0.07190049999999999\n",
      "Total tokens used for this call: 36\n",
      "\n",
      "Index:  425\n",
      "Cost for this call: 0.000126\n",
      "Accumulated tokens so far: 20579\n",
      "Accumulated cost so far: 0.0720265\n",
      "Total tokens used for this call: 52\n",
      "\n",
      "Index:  426\n",
      "Cost for this call: 0.000182\n",
      "Accumulated tokens so far: 20631\n",
      "Accumulated cost so far: 0.0722085\n",
      "Total tokens used for this call: 49\n",
      "\n",
      "Index:  427\n",
      "Cost for this call: 0.0001715\n",
      "Accumulated tokens so far: 20680\n",
      "Accumulated cost so far: 0.07238\n",
      "Total tokens used for this call: 58\n",
      "\n",
      "Index:  428\n",
      "Cost for this call: 0.000203\n",
      "Accumulated tokens so far: 20738\n",
      "Accumulated cost so far: 0.072583\n",
      "Total tokens used for this call: 50\n",
      "\n",
      "Index:  429\n",
      "Cost for this call: 0.000175\n",
      "Accumulated tokens so far: 20788\n",
      "Accumulated cost so far: 0.07275799999999999\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  430\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 20833\n",
      "Accumulated cost so far: 0.0729155\n",
      "Total tokens used for this call: 38\n",
      "\n",
      "Index:  431\n",
      "Cost for this call: 0.000133\n",
      "Accumulated tokens so far: 20871\n",
      "Accumulated cost so far: 0.07304849999999999\n",
      "Total tokens used for this call: 48\n",
      "\n",
      "Index:  432\n",
      "Cost for this call: 0.000168\n",
      "Accumulated tokens so far: 20919\n",
      "Accumulated cost so far: 0.07321649999999999\n",
      "Total tokens used for this call: 69\n",
      "\n",
      "Index:  433\n",
      "Cost for this call: 0.0002415\n",
      "Accumulated tokens so far: 20988\n",
      "Accumulated cost so far: 0.073458\n",
      "Total tokens used for this call: 48\n",
      "\n",
      "Index:  434\n",
      "Cost for this call: 0.000168\n",
      "Accumulated tokens so far: 21036\n",
      "Accumulated cost so far: 0.073626\n",
      "Total tokens used for this call: 54\n",
      "\n",
      "Index:  435\n",
      "Cost for this call: 0.00018899999999999999\n",
      "Accumulated tokens so far: 21090\n",
      "Accumulated cost so far: 0.07381499999999999\n",
      "Total tokens used for this call: 47\n",
      "\n",
      "Index:  436\n",
      "Cost for this call: 0.0001645\n",
      "Accumulated tokens so far: 21137\n",
      "Accumulated cost so far: 0.07397949999999999\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  437\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 21183\n",
      "Accumulated cost so far: 0.07414049999999998\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  438\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 21223\n",
      "Accumulated cost so far: 0.07428049999999999\n",
      "Total tokens used for this call: 73\n",
      "\n",
      "Index:  439\n",
      "Cost for this call: 0.0002555\n",
      "Accumulated tokens so far: 21296\n",
      "Accumulated cost so far: 0.07453599999999999\n",
      "Total tokens used for this call: 59\n",
      "\n",
      "Index:  440\n",
      "Cost for this call: 0.0002065\n",
      "Accumulated tokens so far: 21355\n",
      "Accumulated cost so far: 0.07474249999999999\n",
      "Total tokens used for this call: 61\n",
      "\n",
      "Index:  441\n",
      "Cost for this call: 0.00021349999999999999\n",
      "Accumulated tokens so far: 21416\n",
      "Accumulated cost so far: 0.074956\n",
      "Total tokens used for this call: 60\n",
      "\n",
      "Index:  442\n",
      "Cost for this call: 0.00021\n",
      "Accumulated tokens so far: 21476\n",
      "Accumulated cost so far: 0.075166\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  443\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 21520\n",
      "Accumulated cost so far: 0.07532\n",
      "Total tokens used for this call: 38\n",
      "\n",
      "Index:  444\n",
      "Cost for this call: 0.000133\n",
      "Accumulated tokens so far: 21558\n",
      "Accumulated cost so far: 0.07545299999999999\n",
      "Total tokens used for this call: 33\n",
      "\n",
      "Index:  445\n",
      "Cost for this call: 0.0001155\n",
      "Accumulated tokens so far: 21591\n",
      "Accumulated cost so far: 0.0755685\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  446\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 21636\n",
      "Accumulated cost so far: 0.075726\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  447\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 21681\n",
      "Accumulated cost so far: 0.0758835\n",
      "Total tokens used for this call: 54\n",
      "\n",
      "Index:  448\n",
      "Cost for this call: 0.00018899999999999999\n",
      "Accumulated tokens so far: 21735\n",
      "Accumulated cost so far: 0.0760725\n",
      "Total tokens used for this call: 47\n",
      "\n",
      "Index:  449\n",
      "Cost for this call: 0.0001645\n",
      "Accumulated tokens so far: 21782\n",
      "Accumulated cost so far: 0.076237\n",
      "Total tokens used for this call: 48\n",
      "\n",
      "Index:  450\n",
      "Cost for this call: 0.000168\n",
      "Accumulated tokens so far: 21830\n",
      "Accumulated cost so far: 0.076405\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  451\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 21870\n",
      "Accumulated cost so far: 0.076545\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  452\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 21910\n",
      "Accumulated cost so far: 0.076685\n",
      "Total tokens used for this call: 38\n",
      "\n",
      "Index:  453\n",
      "Cost for this call: 0.000133\n",
      "Accumulated tokens so far: 21948\n",
      "Accumulated cost so far: 0.076818\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  454\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 21988\n",
      "Accumulated cost so far: 0.076958\n",
      "Total tokens used for this call: 38\n",
      "\n",
      "Index:  455\n",
      "Cost for this call: 0.000133\n",
      "Accumulated tokens so far: 22026\n",
      "Accumulated cost so far: 0.07709099999999999\n",
      "Total tokens used for this call: 52\n",
      "\n",
      "Index:  456\n",
      "Cost for this call: 0.000182\n",
      "Accumulated tokens so far: 22078\n",
      "Accumulated cost so far: 0.077273\n",
      "Total tokens used for this call: 56\n",
      "\n",
      "Index:  457\n",
      "Cost for this call: 0.000196\n",
      "Accumulated tokens so far: 22134\n",
      "Accumulated cost so far: 0.077469\n",
      "Total tokens used for this call: 53\n",
      "\n",
      "Index:  458\n",
      "Cost for this call: 0.0001855\n",
      "Accumulated tokens so far: 22187\n",
      "Accumulated cost so far: 0.0776545\n",
      "Total tokens used for this call: 65\n",
      "\n",
      "Index:  459\n",
      "Cost for this call: 0.0002275\n",
      "Accumulated tokens so far: 22252\n",
      "Accumulated cost so far: 0.077882\n",
      "Total tokens used for this call: 47\n",
      "\n",
      "Index:  460\n",
      "Cost for this call: 0.0001645\n",
      "Accumulated tokens so far: 22299\n",
      "Accumulated cost so far: 0.0780465\n",
      "Total tokens used for this call: 58\n",
      "\n",
      "Index:  461\n",
      "Cost for this call: 0.000203\n",
      "Accumulated tokens so far: 22357\n",
      "Accumulated cost so far: 0.0782495\n",
      "Total tokens used for this call: 67\n",
      "\n",
      "Index:  462\n",
      "Cost for this call: 0.0002345\n",
      "Accumulated tokens so far: 22424\n",
      "Accumulated cost so far: 0.078484\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  463\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 22466\n",
      "Accumulated cost so far: 0.07863099999999999\n",
      "Total tokens used for this call: 56\n",
      "\n",
      "Index:  464\n",
      "Cost for this call: 0.000196\n",
      "Accumulated tokens so far: 22522\n",
      "Accumulated cost so far: 0.078827\n",
      "Total tokens used for this call: 43\n",
      "\n",
      "Index:  465\n",
      "Cost for this call: 0.0001505\n",
      "Accumulated tokens so far: 22565\n",
      "Accumulated cost so far: 0.07897749999999999\n",
      "Total tokens used for this call: 37\n",
      "\n",
      "Index:  466\n",
      "Cost for this call: 0.0001295\n",
      "Accumulated tokens so far: 22602\n",
      "Accumulated cost so far: 0.079107\n",
      "Total tokens used for this call: 65\n",
      "\n",
      "Index:  467\n",
      "Cost for this call: 0.0002275\n",
      "Accumulated tokens so far: 22667\n",
      "Accumulated cost so far: 0.0793345\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  468\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 22707\n",
      "Accumulated cost so far: 0.0794745\n",
      "Total tokens used for this call: 54\n",
      "\n",
      "Index:  469\n",
      "Cost for this call: 0.00018899999999999999\n",
      "Accumulated tokens so far: 22761\n",
      "Accumulated cost so far: 0.0796635\n",
      "Total tokens used for this call: 49\n",
      "\n",
      "Index:  470\n",
      "Cost for this call: 0.0001715\n",
      "Accumulated tokens so far: 22810\n",
      "Accumulated cost so far: 0.079835\n",
      "Total tokens used for this call: 52\n",
      "\n",
      "Index:  471\n",
      "Cost for this call: 0.000182\n",
      "Accumulated tokens so far: 22862\n",
      "Accumulated cost so far: 0.080017\n",
      "Total tokens used for this call: 60\n",
      "\n",
      "Index:  472\n",
      "Cost for this call: 0.00021\n",
      "Accumulated tokens so far: 22922\n",
      "Accumulated cost so far: 0.080227\n",
      "Total tokens used for this call: 58\n",
      "\n",
      "Index:  473\n",
      "Cost for this call: 0.000203\n",
      "Accumulated tokens so far: 22980\n",
      "Accumulated cost so far: 0.08043\n",
      "Total tokens used for this call: 44\n",
      "\n",
      "Index:  474\n",
      "Cost for this call: 0.000154\n",
      "Accumulated tokens so far: 23024\n",
      "Accumulated cost so far: 0.080584\n",
      "Total tokens used for this call: 37\n",
      "\n",
      "Index:  475\n",
      "Cost for this call: 0.0001295\n",
      "Accumulated tokens so far: 23061\n",
      "Accumulated cost so far: 0.08071350000000001\n",
      "Total tokens used for this call: 54\n",
      "\n",
      "Index:  476\n",
      "Cost for this call: 0.00018899999999999999\n",
      "Accumulated tokens so far: 23115\n",
      "Accumulated cost so far: 0.0809025\n",
      "Total tokens used for this call: 59\n",
      "\n",
      "Index:  477\n",
      "Cost for this call: 0.0002065\n",
      "Accumulated tokens so far: 23174\n",
      "Accumulated cost so far: 0.081109\n",
      "Total tokens used for this call: 55\n",
      "\n",
      "Index:  478\n",
      "Cost for this call: 0.0001925\n",
      "Accumulated tokens so far: 23229\n",
      "Accumulated cost so far: 0.0813015\n",
      "Total tokens used for this call: 52\n",
      "\n",
      "Index:  479\n",
      "Cost for this call: 0.000182\n",
      "Accumulated tokens so far: 23281\n",
      "Accumulated cost so far: 0.0814835\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  480\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 23326\n",
      "Accumulated cost so far: 0.081641\n",
      "Total tokens used for this call: 60\n",
      "\n",
      "Index:  481\n",
      "Cost for this call: 0.00021\n",
      "Accumulated tokens so far: 23386\n",
      "Accumulated cost so far: 0.08185100000000001\n",
      "Total tokens used for this call: 60\n",
      "\n",
      "Index:  482\n",
      "Cost for this call: 0.00021\n",
      "Accumulated tokens so far: 23446\n",
      "Accumulated cost so far: 0.08206100000000001\n",
      "Total tokens used for this call: 62\n",
      "\n",
      "Index:  483\n",
      "Cost for this call: 0.000217\n",
      "Accumulated tokens so far: 23508\n",
      "Accumulated cost so far: 0.082278\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  484\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 23550\n",
      "Accumulated cost so far: 0.082425\n",
      "Total tokens used for this call: 33\n",
      "\n",
      "Index:  485\n",
      "Cost for this call: 0.0001155\n",
      "Accumulated tokens so far: 23583\n",
      "Accumulated cost so far: 0.0825405\n",
      "Total tokens used for this call: 66\n",
      "\n",
      "Index:  486\n",
      "Cost for this call: 0.000231\n",
      "Accumulated tokens so far: 23649\n",
      "Accumulated cost so far: 0.0827715\n",
      "Total tokens used for this call: 42\n",
      "\n",
      "Index:  487\n",
      "Cost for this call: 0.000147\n",
      "Accumulated tokens so far: 23691\n",
      "Accumulated cost so far: 0.08291849999999999\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  488\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 23736\n",
      "Accumulated cost so far: 0.083076\n",
      "Total tokens used for this call: 56\n",
      "\n",
      "Index:  489\n",
      "Cost for this call: 0.000196\n",
      "Accumulated tokens so far: 23792\n",
      "Accumulated cost so far: 0.083272\n",
      "Total tokens used for this call: 32\n",
      "\n",
      "Index:  490\n",
      "Cost for this call: 0.000112\n",
      "Accumulated tokens so far: 23824\n",
      "Accumulated cost so far: 0.083384\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  491\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 23869\n",
      "Accumulated cost so far: 0.0835415\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  492\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 23909\n",
      "Accumulated cost so far: 0.0836815\n",
      "Total tokens used for this call: 41\n",
      "\n",
      "Index:  493\n",
      "Cost for this call: 0.0001435\n",
      "Accumulated tokens so far: 23950\n",
      "Accumulated cost so far: 0.08382500000000001\n",
      "Total tokens used for this call: 43\n",
      "\n",
      "Index:  494\n",
      "Cost for this call: 0.0001505\n",
      "Accumulated tokens so far: 23993\n",
      "Accumulated cost so far: 0.08397550000000001\n",
      "Total tokens used for this call: 48\n",
      "\n",
      "Index:  495\n",
      "Cost for this call: 0.000168\n",
      "Accumulated tokens so far: 24041\n",
      "Accumulated cost so far: 0.08414350000000001\n",
      "Total tokens used for this call: 46\n",
      "\n",
      "Index:  496\n",
      "Cost for this call: 0.000161\n",
      "Accumulated tokens so far: 24087\n",
      "Accumulated cost so far: 0.0843045\n",
      "Total tokens used for this call: 47\n",
      "\n",
      "Index:  497\n",
      "Cost for this call: 0.0001645\n",
      "Accumulated tokens so far: 24134\n",
      "Accumulated cost so far: 0.084469\n",
      "Total tokens used for this call: 45\n",
      "\n",
      "Index:  498\n",
      "Cost for this call: 0.0001575\n",
      "Accumulated tokens so far: 24179\n",
      "Accumulated cost so far: 0.08462650000000001\n",
      "Total tokens used for this call: 47\n",
      "\n",
      "Index:  499\n",
      "Cost for this call: 0.0001645\n",
      "Accumulated tokens so far: 24226\n",
      "Accumulated cost so far: 0.084791\n",
      "Total tokens used for this call: 40\n",
      "\n",
      "Index:  500\n",
      "Cost for this call: 0.00014\n",
      "Accumulated tokens so far: 24266\n",
      "Accumulated cost so far: 0.084931\n"
     ]
    }
   ],
   "source": [
    "#llm_annotated_data['predicted_gpt35'] = llm_annotated_data['text'].iloc[0:num_rows].apply(analyze_gpt35)\n",
    "#llm_annotated_data['predicted_label'] = llm_annotated_data['text'].iloc[0:num_rows].apply(analyze_ada)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T23:55:59.726164700Z",
     "start_time": "2023-08-07T23:53:55.331029200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7l4a5IC8NPvLQ4Hxhame0VcnFWJk1\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453381,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"neutral\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"neutral\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"neutral\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 56,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 59\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 59\n",
      "Index:  1\n",
      "Cost for this call: 0.0002065\n",
      "Accumulated tokens so far: 59\n",
      "Accumulated cost so far: 0.0002065\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4a5VPvz1pcRiuZ9xGOFqxPqTmnZ\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453381,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 59,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 62\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 62\n",
      "Index:  2\n",
      "Cost for this call: 0.000217\n",
      "Accumulated tokens so far: 121\n",
      "Accumulated cost so far: 0.0004235\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4a6B8u1n07z0YSVUEzBDaO3y0ok\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453382,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 52,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 55\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 55\n",
      "Index:  3\n",
      "Cost for this call: 0.0001925\n",
      "Accumulated tokens so far: 176\n",
      "Accumulated cost so far: 0.000616\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4a6euOHEfENZQoyVyBQiSAYabso\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453382,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 52,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 55\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 55\n",
      "Index:  4\n",
      "Cost for this call: 0.0001925\n",
      "Accumulated tokens so far: 231\n",
      "Accumulated cost so far: 0.0008085\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4a7rQfso48dmb8ILQufJsJMoj8Y\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453383,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 62,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 65\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 65\n",
      "Index:  5\n",
      "Cost for this call: 0.0002275\n",
      "Accumulated tokens so far: 296\n",
      "Accumulated cost so far: 0.001036\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4a7h2CRzS2oDrczCU86TXO0w2pa\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453383,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 69,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 72\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 72\n",
      "Index:  6\n",
      "Cost for this call: 0.000252\n",
      "Accumulated tokens so far: 368\n",
      "Accumulated cost so far: 0.001288\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4a7GuLVbUxthNVWtYx6IsASbP9a\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453383,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 63,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 66\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 66\n",
      "Index:  7\n",
      "Cost for this call: 0.000231\n",
      "Accumulated tokens so far: 434\n",
      "Accumulated cost so far: 0.0015190000000000002\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4a8LiHvyNjQwBlKyAihbMuHaSyw\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453384,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 49,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 52\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 52\n",
      "Index:  8\n",
      "Cost for this call: 0.000182\n",
      "Accumulated tokens so far: 486\n",
      "Accumulated cost so far: 0.0017010000000000003\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4a8uzXvovQBkUSUyUaHGfK5OKJg\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453384,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"neutral\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"neutral\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"neutral\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 49,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 52\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 52\n",
      "Index:  9\n",
      "Cost for this call: 0.000182\n",
      "Accumulated tokens so far: 538\n",
      "Accumulated cost so far: 0.0018830000000000003\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4a8OIeg1yGM5QIr367p3V6JouUI\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453384,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 65,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 68\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 68\n",
      "Index:  10\n",
      "Cost for this call: 0.00023799999999999998\n",
      "Accumulated tokens so far: 606\n",
      "Accumulated cost so far: 0.0021210000000000005\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4a9ndzhvckO86szUg9oWl7Z1RXG\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453385,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 73,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 76\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 76\n",
      "Index:  11\n",
      "Cost for this call: 0.000266\n",
      "Accumulated tokens so far: 682\n",
      "Accumulated cost so far: 0.0023870000000000007\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4a9WKt2zxfWrtiYZlhcTUA8cUTf\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453385,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 57,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 60\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 60\n",
      "Index:  12\n",
      "Cost for this call: 0.00021\n",
      "Accumulated tokens so far: 742\n",
      "Accumulated cost so far: 0.002597000000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4a9A71Go0JQHNrOSAanZ8L9Dbl4\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453385,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 57,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 60\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 60\n",
      "Index:  13\n",
      "Cost for this call: 0.00021\n",
      "Accumulated tokens so far: 802\n",
      "Accumulated cost so far: 0.002807000000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aAUyYlbvHRL4w5vh5ty0K0JqZZ\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453386,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 58,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 61\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 61\n",
      "Index:  14\n",
      "Cost for this call: 0.00021349999999999999\n",
      "Accumulated tokens so far: 863\n",
      "Accumulated cost so far: 0.003020500000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aANmc0QOs00aW0iGrQX5yAD8gY\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453386,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"neutral\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"neutral\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"neutral\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 54,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 57\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 57\n",
      "Index:  15\n",
      "Cost for this call: 0.0001995\n",
      "Accumulated tokens so far: 920\n",
      "Accumulated cost so far: 0.003220000000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aAaq8QyHscAK1c0AvUwUvmZne9\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453386,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 54,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 57\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 57\n",
      "Index:  16\n",
      "Cost for this call: 0.0001995\n",
      "Accumulated tokens so far: 977\n",
      "Accumulated cost so far: 0.003419500000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aBsciPkp1pea9VEUpcFq3ZRhdL\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453387,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 61,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 64\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 64\n",
      "Index:  17\n",
      "Cost for this call: 0.000224\n",
      "Accumulated tokens so far: 1041\n",
      "Accumulated cost so far: 0.003643500000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aBggqOajFGRbpY6Si5uaJUhIhF\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453387,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 88,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 91\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 91\n",
      "Index:  18\n",
      "Cost for this call: 0.0003185\n",
      "Accumulated tokens so far: 1132\n",
      "Accumulated cost so far: 0.003962000000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aBgXcZiuzmkBXFe9Iivb9lG1Mr\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453387,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 55,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 58\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 58\n",
      "Index:  19\n",
      "Cost for this call: 0.000203\n",
      "Accumulated tokens so far: 1190\n",
      "Accumulated cost so far: 0.004165000000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aCRpoGrI2nRjIS9rGEvIzvGL1w\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453388,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 53,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 56\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 56\n",
      "Index:  20\n",
      "Cost for this call: 0.000196\n",
      "Accumulated tokens so far: 1246\n",
      "Accumulated cost so far: 0.004361000000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aCEYneIg62P0OgavqI90fcUyUx\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453388,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 68,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 71\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 71\n",
      "Index:  21\n",
      "Cost for this call: 0.0002485\n",
      "Accumulated tokens so far: 1317\n",
      "Accumulated cost so far: 0.004609500000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aDfz1VSqcLyVeAQPEN3imxussu\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453389,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 77,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 80\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 80\n",
      "Index:  22\n",
      "Cost for this call: 0.00028\n",
      "Accumulated tokens so far: 1397\n",
      "Accumulated cost so far: 0.004889500000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aD4yZziKPDgexPVrtPV0SRvaK7\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453389,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 60,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 63\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 63\n",
      "Index:  23\n",
      "Cost for this call: 0.0002205\n",
      "Accumulated tokens so far: 1460\n",
      "Accumulated cost so far: 0.005110000000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aDfFgRYv7ULsH8hWxe2zjc1CaL\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453389,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 67,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 70\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 70\n",
      "Index:  24\n",
      "Cost for this call: 0.000245\n",
      "Accumulated tokens so far: 1530\n",
      "Accumulated cost so far: 0.005355\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aEmgfjhMeSmkTgn3AHN0G8xHtz\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453390,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 86,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 89\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 89\n",
      "Index:  25\n",
      "Cost for this call: 0.0003115\n",
      "Accumulated tokens so far: 1619\n",
      "Accumulated cost so far: 0.0056665000000000005\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aEUfmsM1y2Ot8cLrNCcPvxdJeA\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453390,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 61,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 64\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 64\n",
      "Index:  26\n",
      "Cost for this call: 0.000224\n",
      "Accumulated tokens so far: 1683\n",
      "Accumulated cost so far: 0.005890500000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aEprhPg2vQK8xUBkO5dESFKEXa\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453390,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"neutral\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 51,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 54\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 54\n",
      "Index:  27\n",
      "Cost for this call: 0.00018899999999999999\n",
      "Accumulated tokens so far: 1737\n",
      "Accumulated cost so far: 0.006079500000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aFK0oSDaw5QAPd46pBQdeceFj5\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453391,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"neutral\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 58,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 61\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 61\n",
      "Index:  28\n",
      "Cost for this call: 0.00021349999999999999\n",
      "Accumulated tokens so far: 1798\n",
      "Accumulated cost so far: 0.006293000000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aFWMjsFpGfBe08FiNeDlOf9UF4\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453391,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 79,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 82\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 82\n",
      "Index:  29\n",
      "Cost for this call: 0.000287\n",
      "Accumulated tokens so far: 1880\n",
      "Accumulated cost so far: 0.006580000000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aFmmJy8cgYPOjo7c9YHGWtyZp8\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453391,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 67,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 70\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 70\n",
      "Index:  30\n",
      "Cost for this call: 0.000245\n",
      "Accumulated tokens so far: 1950\n",
      "Accumulated cost so far: 0.006825000000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aGdCKUbA3iw301HIUbgq4sLq1f\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453392,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 70,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 73\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 73\n",
      "Index:  31\n",
      "Cost for this call: 0.0002555\n",
      "Accumulated tokens so far: 2023\n",
      "Accumulated cost so far: 0.007080500000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aGqTlha75Qvvx3ggBBaqXJsT24\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453392,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 61,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 64\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 64\n",
      "Index:  32\n",
      "Cost for this call: 0.000224\n",
      "Accumulated tokens so far: 2087\n",
      "Accumulated cost so far: 0.007304500000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aGpHdfaIa1wHK5oYmHFc3nNQ87\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453392,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 77,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 80\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 80\n",
      "Index:  33\n",
      "Cost for this call: 0.00028\n",
      "Accumulated tokens so far: 2167\n",
      "Accumulated cost so far: 0.007584500000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aHI3m5jkhzScs6vkGMiEDeSY8G\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453393,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 54,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 57\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 57\n",
      "Index:  34\n",
      "Cost for this call: 0.0001995\n",
      "Accumulated tokens so far: 2224\n",
      "Accumulated cost so far: 0.007784000000000001\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aHq4iVIb968AocxU7qlShelbqt\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453393,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"neutral\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"neutral\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 73,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 76\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 76\n",
      "Index:  35\n",
      "Cost for this call: 0.000266\n",
      "Accumulated tokens so far: 2300\n",
      "Accumulated cost so far: 0.008050000000000002\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aIcEeJr5EgfxKej4cohz36MInl\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453394,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"neutral\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"neutral\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"neutral\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 75,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 78\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 78\n",
      "Index:  36\n",
      "Cost for this call: 0.000273\n",
      "Accumulated tokens so far: 2378\n",
      "Accumulated cost so far: 0.008323000000000002\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aIFaexbxiIRz6iEl4leDJ6OLui\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453394,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 67,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 70\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 70\n",
      "Index:  37\n",
      "Cost for this call: 0.000245\n",
      "Accumulated tokens so far: 2448\n",
      "Accumulated cost so far: 0.008568000000000003\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aI4xx36hW5aeD8ybj2WDB4t0PS\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453394,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 71,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 74\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 74\n",
      "Index:  38\n",
      "Cost for this call: 0.000259\n",
      "Accumulated tokens so far: 2522\n",
      "Accumulated cost so far: 0.008827000000000003\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aJZL7XLeS5YohFmDTxWAKtlaVA\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453395,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"negative\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 69,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 72\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 72\n",
      "Index:  39\n",
      "Cost for this call: 0.000252\n",
      "Accumulated tokens so far: 2594\n",
      "Accumulated cost so far: 0.009079000000000004\n",
      "{\n",
      "  \"id\": \"chatcmpl-7l4aJV9yG14hY0evtJgsVHwPeEuk2\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1691453395,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"positive\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 71,\n",
      "    \"completion_tokens\": 3,\n",
      "    \"total_tokens\": 74\n",
      "  }\n",
      "}\n",
      "Total tokens used for this call: 74\n",
      "Index:  40\n",
      "Cost for this call: 0.000259\n",
      "Accumulated tokens so far: 2668\n",
      "Accumulated cost so far: 0.009338000000000004\n"
     ]
    }
   ],
   "source": [
    "sentiments_and_scores = llm_annotated_data['text'].iloc[0:num_rows].apply(analyze_gpt35)\n",
    "llm_annotated_data.loc[llm_annotated_data.index[0:num_rows], 'predicted_labels'] = [x[0] for x in sentiments_and_scores]\n",
    "llm_annotated_data.loc[llm_annotated_data.index[0:num_rows], 'confidence_score'] = [x[1] for x in sentiments_and_scores]\n",
    "llm_annotated_data['annotation_correct'] = (llm_annotated_data['predicted_labels'] == original_dataset['sentiment']).astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T00:09:56.158032600Z",
     "start_time": "2023-08-08T00:09:41.834498600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    text predicted_labels  \\\n0                    I`d have responded, if I were going          neutral   \n1          Sooo SAD I will miss you here in San Diego!!!         negative   \n2                              my boss is bullying me...         negative   \n3                         what interview! leave me alone         negative   \n4       Sons of ****, why couldn`t they put them on t...         negative   \n...                                                  ...              ...   \n27476   wish we could come see u on Denver  husband l...              NaN   \n27477   I`ve wondered about rake to.  The client has ...              NaN   \n27478   Yay good for both of you. Enjoy the break - y...              NaN   \n27479                         But it was worth it  ****.              NaN   \n27480     All this flirting going on - The ATG smiles...              NaN   \n\n       confidence_score  annotation_correct  \n0                   1.0                   1  \n1                   1.0                   1  \n2                   1.0                   1  \n3                   1.0                   1  \n4                   1.0                   1  \n...                 ...                 ...  \n27476               NaN                   0  \n27477               NaN                   0  \n27478               NaN                   0  \n27479               NaN                   0  \n27480               NaN                   0  \n\n[27481 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>predicted_labels</th>\n      <th>confidence_score</th>\n      <th>annotation_correct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>negative</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>my boss is bullying me...</td>\n      <td>negative</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what interview! leave me alone</td>\n      <td>negative</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>negative</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27476</th>\n      <td>wish we could come see u on Denver  husband l...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27477</th>\n      <td>I`ve wondered about rake to.  The client has ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27478</th>\n      <td>Yay good for both of you. Enjoy the break - y...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27479</th>\n      <td>But it was worth it  ****.</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27480</th>\n      <td>All this flirting going on - The ATG smiles...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>27481 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_annotated_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T00:11:14.119078900Z",
     "start_time": "2023-08-08T00:11:14.055886700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "#llm_annotated_data.to_csv('data/sentiment/annotated/ada/ada_500.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T23:57:47.719165900Z",
     "start_time": "2023-08-07T23:57:47.643635200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "#original_dataset.loc[0:num_rows - 1, 'sentiment'] = original_dataset['sentiment'].iloc[0:num_rows].map(sentiments)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T00:10:25.654119100Z",
     "start_time": "2023-08-08T00:10:25.618418100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "#original_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T00:11:06.196784700Z",
     "start_time": "2023-08-08T00:11:06.175249200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 text predicted_labels  \\\n0                 I`d have responded, if I were going          neutral   \n1       Sooo SAD I will miss you here in San Diego!!!         negative   \n2                           my boss is bullying me...         negative   \n3                      what interview! leave me alone         negative   \n4    Sons of ****, why couldn`t they put them on t...         negative   \n5   http://www.dothebouncy.com/smf - some shameles...         positive   \n6   2am feedings for the baby are fun when he is a...         positive   \n7                                          Soooo high         positive   \n8                                         Both of you          neutral   \n9    Journey!? Wow... u just became cooler.  hehe....         positive   \n10   as much as i love to be hopeful, i reckon the...         negative   \n11  I really really like the song Love Story by Ta...         positive   \n12       My Sharpie is running DANGERously low on ink         negative   \n13  i want to go to music tonight but i lost my vo...         negative   \n14                         test test from the LG enV2          neutral   \n15                              Uh oh, I am sunburned         negative   \n16   S`ok, trying to plot alternatives as we speak...         negative   \n17  i`ve been sick for the past few days  and thus...         negative   \n18         is back home now      gonna miss every one         positive   \n19                         Hes just not that into you         negative   \n20   oh Marly, I`m so sorry!!  I hope you find her...         positive   \n21  Playing Ghost Online is really interesting. Th...         positive   \n22  is cleaning the house for her family who is co...         positive   \n23  gotta restart my computer .. I thought Win7 wa...         negative   \n24  SEe waT I Mean bOuT FoLL0w fRiiDaYs... It`S cA...         negative   \n25  the free fillin` app on my ipod is fun, im add...         positive   \n26                                         I`m sorry.         negative   \n27  On the way to Malaysia...no internet access to...         negative   \n28  juss came backk from Berkeleyy ; omg its madd ...         positive   \n29  Went to sleep and there is a power cut in Noid...         negative   \n30  I`m going home now. Have you seen my new twitt...         positive   \n31  i hope unni will make the audition . fighting ...         positive   \n32   If it is any consolation I got my BMI tested ...         negative   \n33                     That`s very funny.  Cute kids.         positive   \n34   Ahhh, I slept through the game.  I`m gonna tr...          neutral   \n35  Thats it, its the end. Tears for Fears vs Eric...          neutral   \n36  Born and raised in NYC and living in Texas for...         negative   \n37  just in case you wonder, we are really busy to...         positive   \n38  i`m soooooo sleeeeepy!!! the last day o` schoo...         negative   \n39  A little happy for the wine jeje ok it`sm my f...         positive   \n\n    confidence_score  annotation_correct  \n0           1.000000                   1  \n1           1.000000                   1  \n2           1.000000                   1  \n3           1.000000                   1  \n4           1.000000                   1  \n5           1.000000                   0  \n6           1.000000                   1  \n7           1.000000                   0  \n8           1.000000                   1  \n9           1.000000                   1  \n10          1.000000                   0  \n11          1.000000                   1  \n12          1.000000                   1  \n13          1.000000                   1  \n14          1.000000                   1  \n15          1.000000                   1  \n16          1.000000                   1  \n17          1.000000                   1  \n18          1.000000                   0  \n19          1.000000                   0  \n20          1.000000                   0  \n21          1.000000                   1  \n22          1.000000                   0  \n23          1.000000                   0  \n24          1.000000                   0  \n25          1.000000                   1  \n26          0.666667                   1  \n27          0.666667                   1  \n28          1.000000                   1  \n29          1.000000                   1  \n30          1.000000                   1  \n31          1.000000                   1  \n32          1.000000                   1  \n33          1.000000                   1  \n34          0.666667                   1  \n35          1.000000                   1  \n36          1.000000                   1  \n37          1.000000                   0  \n38          1.000000                   1  \n39          1.000000                   1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>predicted_labels</th>\n      <th>confidence_score</th>\n      <th>annotation_correct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>my boss is bullying me...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what interview! leave me alone</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2am feedings for the baby are fun when he is a...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Soooo high</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Both of you</td>\n      <td>neutral</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>as much as i love to be hopeful, i reckon the...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>I really really like the song Love Story by Ta...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>My Sharpie is running DANGERously low on ink</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>i want to go to music tonight but i lost my vo...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>test test from the LG enV2</td>\n      <td>neutral</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Uh oh, I am sunburned</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>S`ok, trying to plot alternatives as we speak...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>i`ve been sick for the past few days  and thus...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>is back home now      gonna miss every one</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Hes just not that into you</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>oh Marly, I`m so sorry!!  I hope you find her...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Playing Ghost Online is really interesting. Th...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>is cleaning the house for her family who is co...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>gotta restart my computer .. I thought Win7 wa...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>SEe waT I Mean bOuT FoLL0w fRiiDaYs... It`S cA...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>the free fillin` app on my ipod is fun, im add...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>I`m sorry.</td>\n      <td>negative</td>\n      <td>0.666667</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>On the way to Malaysia...no internet access to...</td>\n      <td>negative</td>\n      <td>0.666667</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>juss came backk from Berkeleyy ; omg its madd ...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Went to sleep and there is a power cut in Noid...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>I`m going home now. Have you seen my new twitt...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>i hope unni will make the audition . fighting ...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>If it is any consolation I got my BMI tested ...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>That`s very funny.  Cute kids.</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Ahhh, I slept through the game.  I`m gonna tr...</td>\n      <td>neutral</td>\n      <td>0.666667</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Thats it, its the end. Tears for Fears vs Eric...</td>\n      <td>neutral</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Born and raised in NYC and living in Texas for...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>just in case you wonder, we are really busy to...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>i`m soooooo sleeeeepy!!! the last day o` schoo...</td>\n      <td>negative</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>A little happy for the wine jeje ok it`sm my f...</td>\n      <td>positive</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_annotated_data.iloc[0:num_rows]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T00:10:37.639809300Z",
     "start_time": "2023-08-08T00:10:37.602948400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'neutral'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[59], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#llm_annotated_data['annotation_correct'] = (llm_annotated_data['predicted_gpt35'].iloc[0:num_rows] == original_dataset['sentiment'].iloc[0:num_rows]).astype(int)\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m llm_annotated_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mannotation_correct\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m (\u001B[43mllm_annotated_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpredicted_labels\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43mnum_rows\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;241m==\u001B[39m original_dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msentiment\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m:num_rows]\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m))\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m)\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\core\\generic.py:6324\u001B[0m, in \u001B[0;36mNDFrame.astype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m   6317\u001B[0m     results \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m   6318\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miloc[:, i]\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[0;32m   6319\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns))\n\u001B[0;32m   6320\u001B[0m     ]\n\u001B[0;32m   6322\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6323\u001B[0m     \u001B[38;5;66;03m# else, only a single dtype is given\u001B[39;00m\n\u001B[1;32m-> 6324\u001B[0m     new_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mgr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6325\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor(new_data)\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mastype\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6327\u001B[0m \u001B[38;5;66;03m# GH 33113: handle empty frame or series\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:451\u001B[0m, in \u001B[0;36mBaseBlockManager.astype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    448\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m using_copy_on_write():\n\u001B[0;32m    449\u001B[0m     copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m--> 451\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    452\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mastype\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    453\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    454\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    455\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    456\u001B[0m \u001B[43m    \u001B[49m\u001B[43musing_cow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43musing_copy_on_write\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001B[0m, in \u001B[0;36mBaseBlockManager.apply\u001B[1;34m(self, f, align_keys, **kwargs)\u001B[0m\n\u001B[0;32m    350\u001B[0m         applied \u001B[38;5;241m=\u001B[39m b\u001B[38;5;241m.\u001B[39mapply(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    351\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 352\u001B[0m         applied \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(b, f)(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    353\u001B[0m     result_blocks \u001B[38;5;241m=\u001B[39m extend_blocks(applied, result_blocks)\n\u001B[0;32m    355\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mfrom_blocks(result_blocks, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes)\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:511\u001B[0m, in \u001B[0;36mBlock.astype\u001B[1;34m(self, dtype, copy, errors, using_cow)\u001B[0m\n\u001B[0;32m    491\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    492\u001B[0m \u001B[38;5;124;03mCoerce to the new dtype.\u001B[39;00m\n\u001B[0;32m    493\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    507\u001B[0m \u001B[38;5;124;03mBlock\u001B[39;00m\n\u001B[0;32m    508\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    509\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m--> 511\u001B[0m new_values \u001B[38;5;241m=\u001B[39m \u001B[43mastype_array_safe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    513\u001B[0m new_values \u001B[38;5;241m=\u001B[39m maybe_coerce_values(new_values)\n\u001B[0;32m    515\u001B[0m refs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:242\u001B[0m, in \u001B[0;36mastype_array_safe\u001B[1;34m(values, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    239\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtype\u001B[38;5;241m.\u001B[39mnumpy_dtype\n\u001B[0;32m    241\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 242\u001B[0m     new_values \u001B[38;5;241m=\u001B[39m \u001B[43mastype_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    243\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mValueError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m):\n\u001B[0;32m    244\u001B[0m     \u001B[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001B[39;00m\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;66;03m#  trying to convert to float\u001B[39;00m\n\u001B[0;32m    246\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:187\u001B[0m, in \u001B[0;36mastype_array\u001B[1;34m(values, dtype, copy)\u001B[0m\n\u001B[0;32m    184\u001B[0m     values \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 187\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[43m_astype_nansafe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001B[39;00m\n\u001B[0;32m    190\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dtype, np\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(values\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mtype, \u001B[38;5;28mstr\u001B[39m):\n",
      "File \u001B[1;32m~\\Desktop\\LLM Seminar\\Apps Phase\\LLM_Data_Annotation\\venv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138\u001B[0m, in \u001B[0;36m_astype_nansafe\u001B[1;34m(arr, dtype, copy, skipna)\u001B[0m\n\u001B[0;32m    134\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copy \u001B[38;5;129;01mor\u001B[39;00m is_object_dtype(arr\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mor\u001B[39;00m is_object_dtype(dtype):\n\u001B[0;32m    137\u001B[0m     \u001B[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001B[39;00m\n\u001B[1;32m--> 138\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n",
      "\u001B[1;31mValueError\u001B[0m: invalid literal for int() with base 10: 'neutral'"
     ]
    }
   ],
   "source": [
    "#llm_annotated_data['annotation_correct'] = (llm_annotated_data['predicted_gpt35'].iloc[0:num_rows] == original_dataset['sentiment'].iloc[0:num_rows]).astype(int)\n",
    "\n",
    "llm_annotated_data['annotation_correct'] = (llm_annotated_data['predicted_labels'].iloc[0:num_rows].astype(int) == original_dataset['sentiment'].iloc[0:num_rows].astype(int)).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T00:10:45.721592900Z",
     "start_time": "2023-08-08T00:10:45.240680800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm_annotated_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm_annotated_data.iloc[0:num_rows].to_csv('data/sentiment/gpt35_annotated.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#llm_annotated_data['predicted_gpt35'] = llm_annotated_data['text'].iloc[0:num_rows].apply(analyze_gpt35)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print(f\"Accuracy of GPT3.5's annotations: {accuracy_score(original_dataset['sentiment'].iloc[0:num_rows].astype('str').values, llm_annotated_data['predicted_gpt35'].iloc[0:num_rows].astype('str').values)}\")\n",
    "\n",
    "print(f\"Accuracy of Davinci 003's annotations: {accuracy_score(original_dataset['sentiment'].iloc[0:num_rows].astype('str').values, llm_annotated_data['predicted_davinci'].iloc[0:num_rows].astype('str').values)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#llm_annotated_data.iloc[0:num_rows].to_csv('data/sentiment/gpt35_annotated.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/sentiment/davinci003_annotated_300.csv', index_col=[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset['predicted_davinci'] = dataset['predicted_davinci'].apply(lambda x: x.replace('.', ''))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset['predicted_davinci'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MODEL_NAME = 'bert-base-uncased'\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = dataset.copy()\n",
    "sentiments = {'positive': 0, 'neutral': 1, 'negative': 2}\n",
    "data['predicted_davinci'] = data['predicted_davinci'].map(sentiments)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['predicted_davinci']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, targets, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_targets, val_targets = train_test_split(data['text'], data['predicted_davinci'], test_size=0.1)\n",
    "\n",
    "train_texts = train_texts.reset_index(drop=True)\n",
    "val_texts = val_texts.reset_index(drop=True)\n",
    "train_targets = train_targets.reset_index(drop=True)\n",
    "val_targets = val_targets.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "\n",
    "train_data = SentimentDataset(train_texts, train_targets, tokenizer, max_len=128)\n",
    "val_data = SentimentDataset(val_texts, val_targets, tokenizer, max_len=128)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(sentiments)).to(DEVICE)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, device, scheduler=None):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for d in tqdm(data_loader):\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=targets)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "\n",
    "    correct_predictions = 0\n",
    "    predictions = []\n",
    "    real_values = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in tqdm(data_loader):\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=targets)\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            real_values.extend(targets)\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "\n",
    "    predictions = torch.stack(predictions).cpu()\n",
    "    real_values = torch.stack(real_values).cpu()\n",
    "    return correct_predictions.double() / len(data_loader.dataset), classification_report(real_values, predictions, target_names=sentiments.keys())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(model, train_loader, optimizer, DEVICE)\n",
    "    print(f'Train loss: {train_loss}, accuracy: {train_acc}')\n",
    "\n",
    "    val_acc, val_report = eval_model(model, val_loader, DEVICE)\n",
    "    print(f'Val accuracy: {val_acc}\\n')\n",
    "    print(val_report)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/davinci/bert_sentiment_davinci003_300_model.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/sentiment/test.csv', encoding= 'unicode_escape')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test.drop(columns=[x for x in test.columns if x != 'text' and x != 'sentiment'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test.dropna(subset=['sentiment'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test.sentiment.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in test.columns:\n",
    "    test[i] = test[i].astype('str')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_texts = test['text'].reset_index(drop=True)\n",
    "test_targets = test['sentiment'].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if isinstance(test_targets[0], str):\n",
    "    label_encoder = LabelEncoder()\n",
    "    test_targets = label_encoder.fit_transform(test_targets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data = SentimentDataset(test_texts, test_targets, tokenizer, max_len=128)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_acc, test_report = eval_model(model, test_loader, DEVICE)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "print(test_report)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
